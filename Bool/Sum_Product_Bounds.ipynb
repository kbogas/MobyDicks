{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Optimal bounded variable value estimation in sum-product networks\n",
    "### Date: 29/10/2024\n",
    "### Status: Works! Interesting that we iterate over the terminals and the constraints with different ways to optimize.\n",
    "### Idea: \n",
    "The task is, given a multi-linear function in the form of a product of terminal nodes and specific bounds on (probability) variables, find the optimal value of the variables that maximize the function.\n",
    "\n",
    "\n",
    "Spefically, we want $$ \\mathop{argmax}_{a,b,c}{F(a,b,c)} = \\mathop{argmax}_{a,b,c}{\\prod_{i}^{N}T_{i}(a,b,c)}  $$ where $ a \\in [l_a, u_a], b \\in [l_b, u_b], ... $.\n",
    "The idea is that we can try to maximize this function by maximizing each terminal separately but as a linear system altogether.\n",
    "\n",
    "We want to maximize  the system $$ T_1 = 1, T_2 = 1, ..., T_N = 1 $$\n",
    "\n",
    "Let's take for example the case where $$ F = T_1 * T_2 = (a) * (1-a)*b $$ This would become:  $$ a = 1, (1-a) * b = 1 $$ in which case it is a multi-linear system.\n",
    "\n",
    "We introduce the variable $ a' = 1-a $ alongside the constraint $a' + a = 1$.\n",
    "\n",
    "Now we have a set of linear equations and linear constraints.\n",
    "\n",
    "We use a solver that iteratevly search for the bounded solution of this function by calculating the weighted residuals best fit on this system. We make it so, that the terminal functions are resolved by taking the product of the values, while the introduced constraints by taking the same of the values of the variables. We also, greatly outweight the constraints (1000:1 the constraints:terminal weight ratio), to make sure the solutions are in constraints.\n",
    "\n",
    "\n",
    "### Results:\n",
    "It works!\n",
    "Not sure if it usable anywhere. Could have done the same with gradient descent and constraints for sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]] [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "import numpy as np\n",
    "\n",
    "A, B, C, D, E, F, G, H, I, J, K, L, M, N, O = sympy.symbols('A, B, C, D, E, F, G, H, I, J, K, L, M, N, O')\n",
    "expression = eval(\"((A & B & C & D) | (A & B))\")\n",
    "truth_table = list(sympy.logic.boolalg.truth_table(expression, [A, B, C, D])) \n",
    "X = np.array([x[0] for x in truth_table])\n",
    "y = np.array([bool(x[-1]) for x in truth_table]).astype(int)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X,y)\n",
    "dt.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- A <= 0.50\n",
      "|   |--- class: 0\n",
      "|--- A >  0.50\n",
      "|   |--- B <= 0.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- B >  0.50\n",
      "|   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(dt, feature_names=['A', 'B', 'C', 'D']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.4, 0.4, 0.4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import lsq_linear\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# TRIVIAL CASE WITH MONOTONICITY\n",
    "# correct would be all max\n",
    "\n",
    "# t1 = (a * b * c * d), t2 =(a * d)\n",
    "T = np.array([[1,1,1, 1], [1,0,0,1]])\n",
    "y = np.array([1,1])\n",
    "\n",
    "lb = [0.3, 0.3, 0.3, 0.3]\n",
    "ub = [0.4, 0.4, 0.4, 0.4]\n",
    "\n",
    "res = lsq_linear(T, y, bounds=(np.log(lb), np.log(ub)), lsmr_tol='auto', verbose=0)\n",
    "np.exp(res.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best res: [0.4 0.4]\n",
      "Func(0.3 - 0.3) = 1.822119\n",
      "Func(0.3 - 0.4) = 1.822119\n",
      "Func(0.4 - 0.3) = 2.225541\n",
      "Func(0.4 - 0.4) = 2.225541\n"
     ]
    }
   ],
   "source": [
    "# NON trivial CASE WITH b and not b\n",
    "# This would depend on the bounds of a.\n",
    "# With t1 = a*b and t2 = a*(1-b) we have sum(t1, t2) = ab + a(1-b) = ab + a -ab = a\n",
    "# So we just need any point with max bound in a\n",
    "\n",
    "# t1 = a*b, t2 = a*(1-b)\n",
    "T = np.array([[1,1], [1,-1]])\n",
    "y = np.array([1,1])\n",
    "from scipy.optimize import lsq_linear\n",
    "lb = [0.3, 0.3]\n",
    "ub = [0.4, 0.4]\n",
    "\n",
    "bounds = np.vstack((lb, ub)).T\n",
    "\n",
    "res = lsq_linear(T, y, bounds=(np.log(lb), np.log(ub)), lsmr_tol='auto', verbose=0)\n",
    "print(f\"Best res: {np.exp(res.x)}\")\n",
    "\n",
    "\n",
    "for x1 in bounds[0]:\n",
    "    for x2 in bounds[1]:\n",
    "        y = np.exp((T@np.array([x1,x2])).sum())\n",
    "        print(f\"Func({x1} - {x2}) = {y:0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_terminals 2 [[0 0 0 1 0 1]\n",
      " [1 1 0 0 0 1]]\n",
      "     a    b    c    val\n",
      "1  0.7  0.2  0.4  0.084\n",
      "5  0.8  0.2  0.4  0.096\n",
      "0  0.7  0.2  0.3  0.098\n",
      "4  0.8  0.2  0.3  0.112\n",
      "3  0.7  0.6  0.4  0.252\n",
      "7  0.8  0.6  0.4  0.288\n",
      "2  0.7  0.6  0.3  0.294\n",
      "6  0.8  0.6  0.3  0.336\n",
      "a      0.800\n",
      "b      0.600\n",
      "c      0.300\n",
      "val    0.336\n",
      "Name: 6, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def evaluate_function(terminals:np.ndarray, values:np.ndarray):\n",
    "    values_augmented = np.concatenate((values, 1-values))\n",
    "    total = 0\n",
    "    for t in terminals:\n",
    "        indices = np.where(t>0)[0]\n",
    "        prod = values_augmented[indices].prod()\n",
    "        total = prod\n",
    "    return total\n",
    "\n",
    "def get_optimal_value_from_edge_cases(T, bounds):\n",
    "    res_all = []\n",
    "    num_true_vars = len(bounds)\n",
    "    num_terminals = T.shape[0] - num_true_vars\n",
    "    print(\"num_terminals\", num_terminals, T[:num_terminals])\n",
    "    for a in bounds[0]:\n",
    "        for b in bounds[1]:\n",
    "            for c in bounds[2]:\n",
    "                cur_val = np.array([a,b,c])\n",
    "                res = evaluate_function(T[:num_terminals], cur_val)\n",
    "                res_all.append(cur_val.tolist() + [res])\n",
    "                \n",
    "    import pandas as pd\n",
    "    res_all = pd.DataFrame(res_all, columns=['a', 'b', 'c', 'val'])\n",
    "    print(res_all.sort_values('val'))\n",
    "    return res_all.sort_values('val').iloc[-1]\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "def weighted_func(x, T, focus='function', weight_important=100):\n",
    "    num_actual_vars = int(x.shape[0]/2)\n",
    "    num_terminals = T.shape[0] - num_actual_vars\n",
    "    \n",
    "    y = np.ones_like(T.shape[0])\n",
    "    \n",
    "    y_pred = []\n",
    "    for t_index, t in enumerate(T):\n",
    "      indices = np.where(t>0)[0]\n",
    "      if t_index < num_terminals:\n",
    "        y_ = x[indices].prod()\n",
    "      else:\n",
    "        y_ = x[indices].sum()\n",
    "      y_pred.append(y_)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    if focus == 'balanced':\n",
    "      weights = np.ones_like(y)\n",
    "    elif focus == 'constraints':\n",
    "      weights = np.array([1 for _ in range(num_terminals)] + [weight_important for _ in range(num_actual_vars)])\n",
    "    elif focus == 'function':\n",
    "      weights = np.array([weight_important for _ in range(num_terminals)] + [1 for _ in range(num_actual_vars)])\n",
    "    else:\n",
    "      raise NotImplementedError(f'{focus} not understood')\n",
    "    \n",
    "  \n",
    "    weighted_residuals = weights*residuals\n",
    "    return weighted_residuals\n",
    "  \n",
    "  \n",
    "\n",
    "T = np.array([ \n",
    "              [0,0,0,1,0,1], # t1 = (1-a)*(1-c) \n",
    "              [1,1,0,0,0,1], # t2 = a*b*(1-c)\n",
    "              [1,0,0,1,0,0], # c1: a + (1-a) = 1\n",
    "              [0,1,0,0,1,0], # c2: b + (1-b) = 1\n",
    "              [0,0,1,0,0,1],# c3: c + (1-c) = 1\n",
    "            ])\n",
    "\n",
    "lb = [0.7, 0.2, 0.3]\n",
    "ub = [0.8, 0.6, 0.4]\n",
    "bounds = np.vstack((lb, ub)).T\n",
    "\n",
    "print(get_optimal_value_from_edge_cases(T, bounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bounds: [0.7, 0.2, 0.3]\n",
      "Upper bounds: [0.8, 0.6, 0.4]\n",
      "Optimal result:\n",
      "num_terminals 2 [[1 0 0 0 0 0]\n",
      " [0 1 1 1 0 0]]\n",
      "     a    b    c    val\n",
      "4  0.8  0.2  0.3  0.012\n",
      "5  0.8  0.2  0.4  0.016\n",
      "0  0.7  0.2  0.3  0.018\n",
      "1  0.7  0.2  0.4  0.024\n",
      "6  0.8  0.6  0.3  0.036\n",
      "7  0.8  0.6  0.4  0.048\n",
      "2  0.7  0.6  0.3  0.054\n",
      "3  0.7  0.6  0.4  0.072\n",
      "[0.7, 0.6, 0.4, 0.07200000000000001]\n",
      "NE result:\n",
      "[0.7 0.6 0.4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def weighted_func(x, T, focus='function', weight_important=100):\n",
    "    num_actual_vars = int(x.shape[0]/2)\n",
    "    num_terminals = T.shape[0] - num_actual_vars\n",
    "    y = np.ones_like(T.shape[0])\n",
    "\n",
    "    y_pred = []\n",
    "    for t_index, t in enumerate(T):\n",
    "      indices = np.where(t>0)[0]\n",
    "      if t_index < num_terminals:\n",
    "        y_ = x[indices].prod()\n",
    "      else:\n",
    "        y_ = x[indices].sum()\n",
    "      y_pred.append(y_)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    if focus == 'balanced':\n",
    "      weights = np.ones_like(y)\n",
    "    elif focus == 'constraints':\n",
    "      weights = np.array([1 for _ in range(num_terminals)] + [weight_important for _ in range(num_actual_vars)])\n",
    "    elif focus == 'function':\n",
    "      weights = np.array([weight_important for _ in range(num_terminals)] + [1 for _ in range(num_actual_vars)])\n",
    "    # make sure we focuson constraints\n",
    "    else:\n",
    "      raise NotImplementedError(f'{focus} not understood')\n",
    "    \n",
    "    \n",
    "    # make sure we focus on maximizing the target\n",
    "    \n",
    "    \n",
    "    \n",
    "    weighted_residuals = weights*residuals\n",
    "    return weighted_residuals\n",
    "  \n",
    "  \n",
    "from scipy.optimize import  least_squares\n",
    "\n",
    "\n",
    "\n",
    "T = np.array([ \n",
    "              [1,0,0,0,0,0], # t1 = a\n",
    "              [0,1,1,1,0,0], # t2 = (1-a)*b*c\n",
    "              [1,0,0,1,0,0], # c1: a + (1-a) = 1\n",
    "              [0,1,0,0,1,0], # c2: b + (1-b) = 1\n",
    "              [0,0,1,0,0,1],# c3: c + (1-c) = 1\n",
    "            ])\n",
    "\n",
    "lb = [0.7, 0.2, 0.3]\n",
    "ub = [0.8, 0.6, 0.4]\n",
    "\n",
    "bounds = np.vstack((lb, ub)).T\n",
    "\n",
    "print(f'Lower bounds: {lb[:3]}')\n",
    "print(f'Upper bounds: {ub[:3]}')\n",
    "\n",
    "print('Optimal result:')\n",
    "print(get_optimal_value_from_edge_cases(T, bounds).tolist())\n",
    "\n",
    "\n",
    "lb = lb + [1 - ub_ for ub_ in ub]\n",
    "ub = ub + [1 - lb_ for lb_ in lb[:int(len(lb)/2)]]\n",
    "\n",
    "x0 = np.array([item for item in lb[:3]] + [1-item for item in lb[:3]])\n",
    "# print('x0', x0)\n",
    "\n",
    "res = least_squares(weighted_func, x0=x0, bounds=(lb, ub), verbose=0, kwargs={'T':T, \"focus\":'constraints',  \"weight_important\":1000})\n",
    "print('NE result:')\n",
    "print(np.round(res.x[:3], decimals=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
