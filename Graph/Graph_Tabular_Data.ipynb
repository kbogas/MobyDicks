{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Tabular to graph with PAMs\n",
    "### Date: 15/5/2024\n",
    "### Status: Seems to work. Need more experimentation\n",
    "### Idea: \n",
    "Following ideas on the discretization of features, I thought of calculating the similarity matrix of tabular data with their similarity based on their discretized bins.\n",
    "So the steps are:\n",
    "1. Feature Binning (using C4.5 i.e. a DT on each feature column separately, practically)\n",
    "2. Triple generation (sample1- has_same_feature_bin_for_feature_1-sample2)\n",
    "3. PAMs for fast creation of the NxN similarity matrix\n",
    "   1. Interesting to check whether hihger-order could be useful?\n",
    "   2. Other baseline to check the effect of PAMs\n",
    "      1. Simply triples_df.groupby(['head', 'tail'])['rel].agg(list).apply(len) -> (will give (sample1, sample2)->num_of_similar_feauture_bins). It is the same as taking the NxNxR binary tensor and summing across R -> NxN\n",
    "         1. We did that it is the **graph** model and it's the best one.\n",
    "4. SVM on top of the pre-computed similarity matrix.\n",
    "\n",
    "\n",
    "\n",
    "### Results:\n",
    "\n",
    "1. Created **C45_Tr** as a feature transformer. It simply bins the features using a C4.5 strategy.\n",
    "   1. Specifically, it does a label encoding of the features, transforming the feature value to the related ordinal bin number (e.g. 15.3->3), retaining the number of features in the dataset.\n",
    "2. **generate_triples** is a simple helper function to create \"edges\" of the form \"sample1 - has_same_feature_1 - sample2\" across the dataset (where \"has_same_feature_1\" denotes their feature_1 value is in the same bin).\n",
    "3. The next step is to pass them through PAMs for fast modelling creating an NxN matrix. We make it symmetric and then use this as the similarity matrix between them (higher value is more similar).\n",
    "4. And an svm on-top\n",
    "\n",
    "We experimented over 63 datasets, vs a DT/svm/knn on the original features and a DT/knn on the transformed features.\n",
    "\n",
    "!The pam model heads-up is better to the DT!\n",
    "\n",
    "Interestingly knn with transformed features is better than knn on the original features, but the same is not true for the DT (makes sense probably for DT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model      rank\n",
    "2   graph  3.193548\n",
    "6  svm_TR  3.209677\n",
    "3   pam_1  3.354839\n",
    "0      DT  3.596774\n",
    "1   DT_TR  4.000000\n",
    "5     svm  4.677419\n",
    "4   pam_2  5.967742\n",
    "\n",
    "[[ 4 14  1  1]\n",
    " [ 2  9  1  1]\n",
    " [ 1 11  1  1]\n",
    " [ 1 10  1  1]\n",
    " [ 3 15  1  1]\n",
    " [ 6 18  1  1]\n",
    " [ 1 13  1  1]\n",
    " [ 3 13  1  1]\n",
    " [ 1  8  1  1]\n",
    " [ 2 10  1  1]]\n",
    "(150, 4)\n",
    "Output exceeds the size limit. Open the full output data in a text editor\n",
    "[(0, 2, 1),\n",
    " (0, 2, 2),\n",
    " (0, 2, 3),\n",
    " (0, 2, 4),\n",
    " (0, 2, 5),\n",
    " (0, 2, 6),\n",
    " (0, 2, 7),\n",
    " (0, 2, 8),\n",
    " (0, 2, 9),\n",
    " (0, 2, 10),\n",
    " (0, 2, 11),\n",
    " (0, 2, 12),\n",
    " (0, 2, 13),\n",
    " (0, 2, 14),\n",
    " (0, 2, 15),\n",
    " (0, 2, 16),\n",
    " (0, 2, 17),\n",
    " (0, 2, 18),\n",
    " (0, 2, 19),\n",
    " (0, 2, 20),\n",
    " (0, 2, 21),\n",
    " (0, 2, 22),\n",
    " (0, 2, 23),\n",
    " (0, 2, 24),\n",
    " (0, 2, 25),\n",
    "...\n",
    " (28, 2, 31),\n",
    " (28, 2, 32),\n",
    " (28, 2, 33),\n",
    " (28, 2, 34),\n",
    " ...]\n",
    "<150x150 sparse array of type '<class 'numpy.int64'>'\n",
    "\twith 3477 stored elements in Compressed Sparse Row format>\n",
    "63\n",
    "wdbc (1/64)\n",
    "vote (2/64)\n",
    "tokyo1 (3/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "tic_tac_toe (4/64)\n",
    "threeOf9 (5/64)\n",
    "spectf (6/64)\n",
    "spect (7/64)\n",
    "sonar (8/64)\n",
    "saheart (9/64)\n",
    "profb (10/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "prnn_synth (11/64)\n",
    "prnn_crabs (12/64)\n",
    "postoperative_patient_data (13/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "pima (14/64)\n",
    "parity5 (15/64)\n",
    "mux6 (16/64)\n",
    "monk3 (17/64)\n",
    "monk2 (18/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "monk1 (19/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "molecular_biology_promoters (20/64)\n",
    "lupus (21/64)\n",
    "labor (22/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "irish (23/64)\n",
    "ionosphere (24/64)\n",
    "hungarian (25/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "house_votes_84 (26/64)\n",
    "horse_colic (27/64)\n",
    "hepatitis (28/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "heart_statlog (29/64)\n",
    "heart_h (30/64)\n",
    "heart_c (31/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "haberman (32/64)\n",
    "glass2 (33/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "german (34/64)\n",
    "diabetes (35/64)\n",
    "crx (36/64)\n",
    "credit_g (37/64)\n",
    "credit_a (38/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "corral (39/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "colic (40/64)\n",
    "cleve (41/64)\n",
    "bupa (42/64)\n",
    "buggyCrx (43/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "breast_w (44/64)\n",
    "breast_cancer_wisconsin (45/64)\n",
    "breast_cancer (46/64)\n",
    "breast (47/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "biomed (48/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "backache (49/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "australian (50/64)\n",
    "appendicitis (51/64)\n",
    "analcatdata_lawsuit (52/64)\n",
    "analcatdata_japansolvent (53/64)\n",
    "analcatdata_fraud (54/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "analcatdata_cyyoung9302 (55/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "analcatdata_cyyoung8092 (56/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "analcatdata_creditscore (57/64)\n",
    "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "analcatdata_boxing2 (58/64)\n",
    "analcatdata_boxing1 (59/64)\n",
    "analcatdata_bankruptcy (60/64)\n",
    "analcatdata_asbestos (61/64)\n",
    "analcatdata_aids (62/64)\n",
    "    model      rank\n",
    "2   graph  3.193548\n",
    "6  svm_TR  3.209677\n",
    "3   pam_1  3.354839\n",
    "0      DT  3.596774\n",
    "1   DT_TR  4.000000\n",
    "5     svm  4.677419\n",
    "4   pam_2  5.967742\n",
    "/tmp/ipykernel_1710513/2773563811.py:159: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
    "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "WINS\n",
    "        graph  svm_TR  pam_1    DT  DT_TR   svm  pam_2\n",
    "graph     0.0    28.0   35.0  39.0   40.0  40.0   54.0\n",
    "svm_TR   32.0     0.0   31.0  36.0   37.0  44.0   51.0\n",
    "pam_1    22.0    30.0    0.0  36.0   41.0  41.0   51.0\n",
    "DT       22.0    25.0   25.0   0.0   26.0  42.0   54.0\n",
    "DT_TR    21.0    24.0   20.0  23.0    0.0  40.0   54.0\n",
    "svm      18.0     7.0   19.0  19.0   21.0   0.0   41.0\n",
    "pam_2     8.0    10.0   11.0   8.0    8.0  19.0    0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results (before adding relation importance ordering for pam, and without simple graph and svm_tr results.)\n",
    "\n",
    "    model      rank\n",
    "0      DT  2.951613\n",
    "4     pam  2.967742\n",
    "1   DT_TR  3.451613\n",
    "3  kNN_TR  3.596774\n",
    "2     kNN  3.903226\n",
    "5     svm  4.129032\n",
    "\n",
    "WINS (times the row model wins the column models. With 63 datasets, wins >= 63/2=32 denotes that the row model is better)\n",
    "          DT  DT_TR   kNN  kNN_TR   svm   pam\n",
    "DT       0.0   26.0  42.0    37.0  42.0  25.0\n",
    "DT_TR   23.0    0.0  38.0    33.0  40.0  20.0\n",
    "kNN     19.0   23.0   0.0    19.0  34.0  25.0\n",
    "kNN_TR  24.0   28.0  34.0     0.0  35.0  28.0\n",
    "svm     19.0   21.0  28.0    27.0   0.0  19.0\n",
    "pam     36.0   41.0  36.0    34.0  41.0   0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer, load_digits, load_iris\n",
    "from pmlb import fetch_data\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 14  1  1]\n",
      " [ 2  9  1  1]\n",
      " [ 1 11  1  1]\n",
      " [ 1 10  1  1]\n",
      " [ 3 15  1  1]\n",
      " [ 6 18  1  1]\n",
      " [ 1 13  1  1]\n",
      " [ 3 13  1  1]\n",
      " [ 1  8  1  1]\n",
      " [ 2 10  1  1]]\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class C45_Tr(TransformerMixin):\n",
    "    def __init__(self, min_samples_leaf=4, max_leaf_nodes=126, random_state = 42):\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.random_state = random_state\n",
    "        self.bins = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        ## https://github.com/jyansir/tp-berta/blob/main/lib/feature_encoder.py\n",
    "        for col in range(X.shape[1]):\n",
    "            cur_X = X[:, col].reshape(-1,1)\n",
    "            tree = DecisionTreeClassifier(min_samples_leaf=self.min_samples_leaf, max_leaf_nodes=self.max_leaf_nodes, \\\n",
    "                                          random_state=self.random_state).fit(cur_X, y).tree_\n",
    "            tree_thresholds = []\n",
    "            for node_id in range(tree.node_count):\n",
    "                if tree.children_left[node_id] != tree.children_right[node_id]:\n",
    "                    tree_thresholds.append(tree.threshold[node_id])\n",
    "            tree_thresholds.append(cur_X.max())\n",
    "            tree_thresholds.append(cur_X.min())\n",
    "            self.bins.append(np.array(sorted(set(tree_thresholds))))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tr = []\n",
    "        for col in range(X.shape[1]):\n",
    "            cur_tr = np.digitize(\n",
    "                            X[:, col],\n",
    "                            np.r_[-np.inf, self.bins[col][1:-1], np.inf],\n",
    "                        ).astype(np.int64)\n",
    "            tr.append(cur_tr)\n",
    "        \n",
    "        final = np.vstack(tr).T\n",
    "        return final\n",
    "tr = C45_Tr(min_samples_leaf=2)\n",
    "X_tr = tr.fit_transform(X,y)\n",
    "print(X_tr[:10,:])\n",
    "print(X_tr.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "def generate_triples(X_tr, order_of_cols=[], order_of_indices=[], print_=False):\n",
    "    \n",
    "    \" MAYBE WE COULD ALSO HAVE MORE DETAIL AS an edge of the form has_same_feature1_bin_1 instead of the current has_same_feature1\" \n",
    "    from itertools import combinations\n",
    "    triples = []\n",
    "    if len(order_of_cols) == 0:\n",
    "        order_of_cols = range(X_tr.shape[1])\n",
    "    for col in order_of_cols:\n",
    "        values =  X_tr[:, col]\n",
    "        #print('val', values)\n",
    "        for unq in np.unique(values):\n",
    "            indices = np.argwhere(values == unq).flatten()\n",
    "            #print(unq, indices.shape, indices)\n",
    "            if len(order_of_indices) > 0:\n",
    "                indices = [order_of_indices[index] for index in indices]\n",
    "            if len(indices) > 1:\n",
    "                for comb in combinations(indices, 2):\n",
    "                    triples.append((comb[0], col, comb[1]))\n",
    "    if print_:\n",
    "        print(f'Transformed into {len(triples)}') \n",
    "    return triples\n",
    "\n",
    "# Most important to the end\n",
    "order_of_cols = np.argsort(f_classif(X, y)[0])[::-1]\n",
    "triples = generate_triples(X_tr, order_of_cols)\n",
    "# triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x150 sparse array of type '<class 'numpy.int64'>'\n",
       "\twith 3477 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prime_adj.pam_creation import create_pam_matrices\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "triples_df = pd.DataFrame(triples, columns=['head', 'rel', 'tail'])\n",
    "pam_lossless, pam_1, node2id, rel2id, broke_with_sparsity = create_pam_matrices(triples_df, max_order=1)\n",
    "pam_lossless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "wdbc (1/64)\n",
      "vote (2/64)\n",
      "tokyo1 (3/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic_tac_toe (4/64)\n",
      "threeOf9 (5/64)\n",
      "spectf (6/64)\n",
      "spect (7/64)\n",
      "sonar (8/64)\n",
      "saheart (9/64)\n",
      "profb (10/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prnn_synth (11/64)\n",
      "prnn_crabs (12/64)\n",
      "postoperative_patient_data (13/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pima (14/64)\n",
      "parity5 (15/64)\n",
      "mux6 (16/64)\n",
      "monk3 (17/64)\n",
      "monk2 (18/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1 (19/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecular_biology_promoters (20/64)\n",
      "lupus (21/64)\n",
      "labor (22/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irish (23/64)\n",
      "ionosphere (24/64)\n",
      "hungarian (25/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_votes_84 (26/64)\n",
      "horse_colic (27/64)\n",
      "hepatitis (28/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_statlog (29/64)\n",
      "heart_h (30/64)\n",
      "heart_c (31/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haberman (32/64)\n",
      "glass2 (33/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german (34/64)\n",
      "diabetes (35/64)\n",
      "crx (36/64)\n",
      "credit_g (37/64)\n",
      "credit_a (38/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corral (39/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colic (40/64)\n",
      "cleve (41/64)\n",
      "bupa (42/64)\n",
      "buggyCrx (43/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast_w (44/64)\n",
      "breast_cancer_wisconsin (45/64)\n",
      "breast_cancer (46/64)\n",
      "breast (47/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomed (48/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backache (49/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "australian (50/64)\n",
      "appendicitis (51/64)\n",
      "analcatdata_lawsuit (52/64)\n",
      "analcatdata_japansolvent (53/64)\n",
      "analcatdata_fraud (54/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung9302 (55/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung8092 (56/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_creditscore (57/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_boxing2 (58/64)\n",
      "analcatdata_boxing1 (59/64)\n",
      "analcatdata_bankruptcy (60/64)\n",
      "analcatdata_asbestos (61/64)\n",
      "analcatdata_aids (62/64)\n",
      "    model      rank\n",
      "2   graph  3.193548\n",
      "6  svm_TR  3.209677\n",
      "3   pam_1  3.354839\n",
      "0      DT  3.596774\n",
      "1   DT_TR  4.000000\n",
      "5     svm  4.677419\n",
      "4   pam_2  5.967742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1710513/2773563811.py:159: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import re\n",
    "from torch import rand\n",
    "import cached_path\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "min_samples_leaf = 10\n",
    "model_names = [\n",
    "    \n",
    "    \n",
    "    \"DT\",\n",
    "    \"DT_TR\",\n",
    "    #\"kNN\",\n",
    "    #\"kNN_TR\",\n",
    "    'svm',\n",
    "    'svm_TR',\n",
    "    'pam_1',\n",
    "    'pam_2',\n",
    "    'graph',\n",
    " \n",
    "    # \"DT_Free\",\n",
    "    #\"DiffProp\",\n",
    "    # \"DiffProp_Free\",\n",
    "    # \"PHCRegressor\",\n",
    "]\n",
    "\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "set_seeds(random_state)\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][1:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "\n",
    "    \n",
    "        # train_X, test_X, train_y, test_y = train_test_split(\n",
    "        #     X, y, stratify=y, test_size=0.2, random_state=random_state\n",
    "        # )\n",
    "    for model_name in model_names:\n",
    "        #print(model_name)\n",
    "        if \"DT\" in model_name:\n",
    "            clf = DecisionTreeClassifier(\n",
    "                random_state=random_state\n",
    "            )\n",
    "        elif 'kNN' in model_name:\n",
    "            clf = KNeighborsClassifier(n_neighbors=3)\n",
    "        elif 'svm' in model_name:\n",
    "            clf = SVC()\n",
    "        elif 'pam' in model_name:\n",
    "            pass\n",
    "        elif 'graph' in model_name:\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # model = clf\n",
    "        if 'TR' in model_name:\n",
    "            model = Pipeline([\n",
    "                ('tr', C45_Tr(min_samples_leaf=min_samples_leaf)),\n",
    "                ('clf', clf)\n",
    "            ])\n",
    "        else:\n",
    "            model = clf\n",
    "        time_s = time.time()\n",
    "        if 'pam' in model_name or 'graph' in model_name:\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            for train_indices, test_indices in cv.split(X,y):\n",
    "                X_train, y_train = X[train_indices], y[train_indices]\n",
    "                X_test, y_test = X[test_indices], y[test_indices]\n",
    "                \n",
    "                fi_clf = DecisionTreeClassifier(random_state=42)\n",
    "                fi_clf.fit(X_train, y_train)\n",
    "                order_of_cols = np.argsort(fi_clf.feature_importances_)[::-1] #np.arange(X.shape[1])#np.argsort(f_classif(X_train, y_train)[0])[::-1] \n",
    "                \n",
    "                tr = C45_Tr(min_samples_leaf=min_samples_leaf)\n",
    "                \n",
    "                X_train = tr.fit_transform(X_train, y_train)\n",
    "                X_test = tr.transform(X_test)\n",
    "                \n",
    "                \n",
    "                \n",
    "                  \n",
    "                \n",
    "                triples = generate_triples(np.vstack((X_train, X_test)), order_of_cols=order_of_cols, order_of_indices=np.concatenate((train_indices, test_indices)))\n",
    "\n",
    "                triples_df = pd.DataFrame(triples, columns=['head', 'rel', 'tail'])\n",
    "                if 'pam' in model_name:\n",
    "                    pam_lossless, pam_1, node2id, rel2id, broke_with_sparsity = create_pam_matrices(triples_df, max_order=2, use_log=True)\n",
    "                    hop = int(model_name.split('_')[1]) - 1\n",
    "                    sim_matrix = pam_1[hop].todense()\n",
    "                elif 'graph' in model_name:\n",
    "                    from scipy.sparse import csr_array\n",
    "                    counts_dict = triples_df.groupby(['head', 'tail'])['rel'].agg(list).apply(len).to_dict()\n",
    "                    (rows, cols) = zip(*list(counts_dict.keys()))\n",
    "                    vals = list(counts_dict.values())\n",
    "                    sim_matrix = csr_array((vals, (rows, cols)), shape=(X.shape[0], X.shape[0])).todense()\n",
    "                sim_matrix = np.maximum(sim_matrix, sim_matrix.T)\n",
    "                clf = SVC(kernel='precomputed')\n",
    "                clf.fit(sim_matrix[train_indices][:, train_indices], y_train)\n",
    "                cur_pred = clf.predict(sim_matrix[test_indices][:, train_indices])\n",
    "                y_pred.append(cur_pred)\n",
    "                y_true.append(y_test)\n",
    "            y_pred = np.concatenate(y_pred)\n",
    "            y_true = np.concatenate(y_true)\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "                y_true, y_pred, average=\"binary\"\n",
    "            )\n",
    "        else:\n",
    "            y_pred = cross_val_predict(model, X, y, cv=cv).astype(int)\n",
    "            acc = accuracy_score(y, y_pred)\n",
    "            (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "                y, y_pred, average=\"binary\"\n",
    "            )\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, model_name, time_end, acc, prec, rec, f1, sup))\n",
    "        #print(res[-1])\n",
    "\n",
    "res = pd.DataFrame(res, columns=['dataset', 'model', 'time', 'acc', 'pr', 'rec', 'f1', 'sup'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model      rank\n",
      "2   graph  3.193548\n",
      "6  svm_TR  3.209677\n",
      "3   pam_1  3.354839\n",
      "0      DT  3.596774\n",
      "1   DT_TR  4.000000\n",
      "5     svm  4.677419\n",
      "4   pam_2  5.967742\n"
     ]
    }
   ],
   "source": [
    "print(mean_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "        graph  svm_TR  pam_1    DT  DT_TR   svm  pam_2\n",
      "graph     0.0    28.0   35.0  39.0   40.0  40.0   54.0\n",
      "svm_TR   32.0     0.0   31.0  36.0   37.0  44.0   51.0\n",
      "pam_1    22.0    30.0    0.0  36.0   41.0  41.0   51.0\n",
      "DT       22.0    25.0   25.0   0.0   26.0  42.0   54.0\n",
      "DT_TR    21.0    24.0   20.0  23.0    0.0  40.0   54.0\n",
      "svm      18.0     7.0   19.0  19.0   21.0   0.0   41.0\n",
      "pam_2     8.0    10.0   11.0   8.0    8.0  19.0    0.0\n"
     ]
    }
   ],
   "source": [
    "#  res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False))\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df['f1']\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1]['f1'] > cur_df.loc[m2]['f1']:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1]['f1'] < cur_df.loc[m2]['f1']:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = np.array(model_names)[order_of_models], index=np.array(model_names)[order_of_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "prime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
