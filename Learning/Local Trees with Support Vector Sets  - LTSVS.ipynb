{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Local Trees with Support Vector Sets\n",
    "### Date: 20/05/2025\n",
    "### Status: Pending results\n",
    "### Idea: \n",
    "The idea is the following given the data set for it's training sample find S different balanced subsets of the training data of containing M training samples from each class, which when fitting a decision tree classifier on each one of them the dt correctly predicts the sample at hand. This process is repeated for all the training samples in the data and the idea is to keep track of the possible good-subsets per sample, lets call them Support vector sets (SVSs). Then at inference time for the query  sample we find it's most closest K training samples and we retrieve the corresponding SVS's. Then we fit K*S different decision trees on these different SVSs and and the final decision is made through voting (probably weighted). \n",
    "\n",
    "Implementation wise I think of two strategies finding the support Vector set for it s training sample completely at random or by sampling based on the distance of it's training sample to each other in the data set. \n",
    "\n",
    "### Details:\n",
    "\n",
    "\n",
    "### Results:\n",
    " Works a bit. Best one is better on 25/93, worse 16/93, equal on the rest against a standardized LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# class LTSVS(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, S=2, M=2, K=2, sampling_strategy='random', random_state=None):\n",
    "#         self.S = S\n",
    "#         self.M = M\n",
    "#         self.K = K\n",
    "#         self.sampling_strategy = sampling_strategy\n",
    "#         self.random_state = random_state\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         X, y = check_X_y(X, y)\n",
    "#         self.X_train_ = X\n",
    "#         self.y_train_ = y\n",
    "#         self.classes_ = np.unique(y)\n",
    "#         rng = np.random.RandomState(self.random_state)\n",
    "#         self.svs_dict_ = {}  # Support vector sets per sample index\n",
    "\n",
    "#         for idx in range(len(X)):\n",
    "#             x_i, y_i = X[idx], y[idx]\n",
    "#             sv_sets = []\n",
    "\n",
    "#             attempts = 0\n",
    "#             while len(sv_sets) < self.S and attempts < self.S * 10:\n",
    "#                 if self.sampling_strategy == 'random':\n",
    "#                     # Balanced subset\n",
    "#                     pos_idx = np.where(y == self.classes_[0])[0]\n",
    "#                     neg_idx = np.where(y == self.classes_[1])[0]\n",
    "\n",
    "#                     pos_sample = rng.choice(pos_idx, min(self.M, len(pos_idx)), replace=False)\n",
    "#                     neg_sample = rng.choice(neg_idx, min(self.M, len(neg_idx)), replace=False)\n",
    "#                     subset_idx = np.concatenate([pos_sample, neg_sample])\n",
    "#                 else:  # distance-based\n",
    "#                     dists = np.linalg.norm(X - x_i, axis=1)\n",
    "#                     nearest_idx = np.argsort(dists)[1:2*self.M+1]\n",
    "#                     class_0 = [i for i in nearest_idx if y[i] == self.classes_[0]]\n",
    "#                     class_1 = [i for i in nearest_idx if y[i] == self.classes_[1]]\n",
    "#                     if len(class_0) < self.M or len(class_1) < self.M:\n",
    "#                         attempts += 1\n",
    "#                         continue\n",
    "#                     subset_idx = np.array(class_0[:self.M] + class_1[:self.M])\n",
    "\n",
    "#                 clf = DecisionTreeClassifier(random_state=self.random_state)\n",
    "#                 clf.fit(X[subset_idx], y[subset_idx])\n",
    "#                 if clf.predict(x_i.reshape(1, -1))[0] == y_i:\n",
    "#                     sv_sets.append(subset_idx)\n",
    "#                 attempts += 1\n",
    "\n",
    "#             self.svs_dict_[idx] = sv_sets\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         check_is_fitted(self)\n",
    "#         X = check_array(X)\n",
    "#         preds = []\n",
    "\n",
    "#         nbrs = NearestNeighbors(n_neighbors=self.K).fit(self.X_train_)\n",
    "#         _, indices = nbrs.kneighbors(X)\n",
    "\n",
    "#         for i in range(len(X)):\n",
    "#             trees = []\n",
    "#             for neighbor in indices[i]:\n",
    "#                 sv_sets = self.svs_dict_.get(neighbor, [])\n",
    "#                 for sv in sv_sets:\n",
    "#                     clf = DecisionTreeClassifier(random_state=self.random_state)\n",
    "#                     clf.fit(self.X_train_[sv], self.y_train_[sv])\n",
    "#                     trees.append(clf)\n",
    "\n",
    "#             if not trees:\n",
    "#                 print(f\"SHOULD NOT BE HERE?\")\n",
    "#                 preds.append(random.choice(self.classes_))  # fallback\n",
    "#             else:\n",
    "#                 votes = [tree.predict(X[i].reshape(1, -1))[0] for tree in trees]\n",
    "#                 preds.append(max(set(votes), key=votes.count))\n",
    "\n",
    "#         return np.array(preds)\n",
    "    \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances \n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "eps = 1e-3\n",
    "\n",
    "def argsmallest_n(a, n):\n",
    "    ret = np.argpartition(a, n)[:n]\n",
    "    b = np.take(a, ret)\n",
    "    return np.take(ret, np.argsort(b))\n",
    "\n",
    "class LPSVS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, num_neigh=5, num_sets_per_sample=10, random_state=42, project=100):\n",
    "        self.num_sets_per_sample = num_sets_per_sample\n",
    "        self.num_neigh = num_neigh\n",
    "        self.random_state = random_state\n",
    "        self.project = project\n",
    "            \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        if self.project > 0:\n",
    "            n_components = min(self.project, X.shape[1])\n",
    "            self.projector = PCA(n_components=n_components, random_state=self.random_state)\n",
    "            X = self.projector.fit_transform(X)\n",
    "        self.normalize = StandardScaler()\n",
    "        X= self.normalize.fit_transform(X)\n",
    "        self.X_train_ = X\n",
    "        self.y_train_ = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.svs_dict_ = {}\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        dists = pairwise_distances(X) + eps\n",
    "        np.fill_diagonal(dists, np.max(dists))\n",
    "\n",
    "        for idx, x_i in enumerate(X):\n",
    "            y_i = y[idx]\n",
    "            sv_sets = []\n",
    "            attempts = 0\n",
    "            cur_dist = dists[idx,:]\n",
    "            # cur_proba = (1/cur_dist) / cur_dist.sum()\n",
    "\n",
    "            while len(sv_sets) < self.num_sets_per_sample and attempts < self.num_sets_per_sample * 10:\n",
    "                idx_0 = np.where(y != y_i)[0]\n",
    "                idx_1 = np.where(y == y_i)[0]\n",
    "\n",
    "                if len(idx_0) < self.num_neigh or len(idx_1) < self.num_neigh:\n",
    "                    break\n",
    "\n",
    "                sample_0 = rng.choice(idx_0, min(self.num_neigh,softmax(1/cur_dist[idx_0]).nonzero()[0].shape[0]), replace=False, p=softmax(1/cur_dist[idx_0]))\n",
    "                sample_1 = rng.choice(idx_1, min(self.num_neigh,softmax(1/cur_dist[idx_1]).nonzero()[0].shape[0]), replace=True, p=softmax(1/cur_dist[idx_1]))\n",
    "                subset_idx = np.concatenate([sample_0, sample_1])\n",
    "\n",
    "                X_subset = X[subset_idx]\n",
    "                y_subset = y[subset_idx]\n",
    "\n",
    "                class0 = X_subset[y_subset != y_i]\n",
    "                class1 = X_subset[y_subset == y_i]\n",
    "\n",
    "                centroid_0 = np.mean(class0, axis=0)\n",
    "                centroid_1 = np.mean(class1, axis=0)\n",
    "                w = centroid_1 - centroid_0\n",
    "\n",
    "                if np.dot(x_i - (centroid_0 + centroid_1) / 2, w) > 0:\n",
    "                    sv_sets.append((centroid_0, centroid_1, y_i))\n",
    "\n",
    "                attempts += 1\n",
    "\n",
    "            self.svs_dict_[idx] = sv_sets\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        if self.project > 0:\n",
    "            X = self.projector.transform(X)\n",
    "        X = self.normalize.transform(X)\n",
    "        preds = []\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=self.num_neigh).fit(self.X_train_)\n",
    "        dists, indices = nbrs.kneighbors(X)\n",
    "        dists += eps\n",
    "        weights = (1/dists) / ((1/dists).sum(axis=1).reshape(-1,1))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            cur_pred = np.zeros_like(self.classes_, dtype=float)\n",
    "            for neighbor_index, neighbor in enumerate(indices[i]):\n",
    "                cur_weight = weights[i, neighbor_index]\n",
    "                sv_sets = self.svs_dict_.get(neighbor, [])\n",
    "                #print(f'test index {i} \\t neig indeex {neighbor_index} \\t neigh sample index/label {neighbor},{self.y_train_[neighbor]} \\t neigh dist {cur_weight}')\n",
    "                for svs_index, (centroid_0, centroid_1, y_i) in enumerate(sv_sets):\n",
    "                    w = centroid_1 - centroid_0\n",
    "                    dist = np.dot(X[i] - (centroid_0 + centroid_1) / 2, w)\n",
    "                    sign = int(dist > 0)\n",
    "                    same_sign_and_label = int(sign == y_i )\n",
    "                    #print(f'svs index {svs_index} \\t dist {dist} \\t sign {sign} \\t will add to {same_sign_and_label} \\t proba {cur_weight}')\n",
    "                    cur_pred[same_sign_and_label] += 1*cur_weight\n",
    "                    #print(f'Updated cur pred {cur_pred}')\n",
    "            #print(cur_pred)\n",
    "            preds.append(cur_pred.argmax())\n",
    "\n",
    "        # print(f'PRED', np.array(preds))\n",
    "        return np.array(preds)\n",
    "    \n",
    "clf = LPSVS(num_neigh=5, num_sets_per_sample=1, project=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "xd6 (1/74)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       651\n",
      "           1       0.79      0.60      0.68       322\n",
      "\n",
      "    accuracy                           0.81       973\n",
      "   macro avg       0.80      0.76      0.78       973\n",
      "weighted avg       0.81      0.81      0.81       973\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       0.99      0.99      0.99       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       651\n",
      "           1       0.94      0.95      0.95       322\n",
      "\n",
      "    accuracy                           0.96       973\n",
      "   macro avg       0.96      0.96      0.96       973\n",
      "weighted avg       0.96      0.96      0.96       973\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       651\n",
      "           1       0.97      0.94      0.96       322\n",
      "\n",
      "    accuracy                           0.97       973\n",
      "   macro avg       0.97      0.97      0.97       973\n",
      "weighted avg       0.97      0.97      0.97       973\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       651\n",
      "           1       0.98      0.98      0.98       322\n",
      "\n",
      "    accuracy                           0.99       973\n",
      "   macro avg       0.98      0.98      0.98       973\n",
      "weighted avg       0.99      0.99      0.99       973\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       651\n",
      "           1       0.98      0.98      0.98       322\n",
      "\n",
      "    accuracy                           0.99       973\n",
      "   macro avg       0.99      0.98      0.98       973\n",
      "weighted avg       0.99      0.99      0.99       973\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       651\n",
      "           1       0.98      0.96      0.97       322\n",
      "\n",
      "    accuracy                           0.98       973\n",
      "   macro avg       0.98      0.97      0.98       973\n",
      "weighted avg       0.98      0.98      0.98       973\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       651\n",
      "           1       0.98      0.95      0.97       322\n",
      "\n",
      "    accuracy                           0.98       973\n",
      "   macro avg       0.98      0.97      0.98       973\n",
      "weighted avg       0.98      0.98      0.98       973\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       651\n",
      "           1       0.99      0.97      0.98       322\n",
      "\n",
      "    accuracy                           0.99       973\n",
      "   macro avg       0.99      0.98      0.98       973\n",
      "weighted avg       0.99      0.99      0.99       973\n",
      "\n",
      "tokyo1 (2/74)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       346\n",
      "           1       0.93      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.92      0.91      0.91       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       346\n",
      "           1       0.93      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.93       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.93      0.93      0.93       959\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       346\n",
      "           1       0.93      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.93       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.93      0.93      0.93       959\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       346\n",
      "           1       0.93      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.92      0.91      0.92       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       346\n",
      "           1       0.93      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.92      0.91      0.91       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80       346\n",
      "           1       0.85      0.97      0.91       613\n",
      "\n",
      "    accuracy                           0.87       959\n",
      "   macro avg       0.89      0.83      0.85       959\n",
      "weighted avg       0.88      0.87      0.87       959\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79       346\n",
      "           1       0.85      0.95      0.90       613\n",
      "\n",
      "    accuracy                           0.86       959\n",
      "   macro avg       0.87      0.83      0.84       959\n",
      "weighted avg       0.87      0.86      0.86       959\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       346\n",
      "           1       0.88      0.96      0.92       613\n",
      "\n",
      "    accuracy                           0.89       959\n",
      "   macro avg       0.90      0.87      0.88       959\n",
      "weighted avg       0.90      0.89      0.89       959\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85       346\n",
      "           1       0.89      0.96      0.93       613\n",
      "\n",
      "    accuracy                           0.90       959\n",
      "   macro avg       0.91      0.88      0.89       959\n",
      "weighted avg       0.90      0.90      0.90       959\n",
      "\n",
      "tic_tac_toe (3/74)\n",
      "(958, 9) with ratio : 1.8855\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.33       332\n",
      "           1       0.69      0.93      0.79       626\n",
      "\n",
      "    accuracy                           0.68       958\n",
      "   macro avg       0.66      0.58      0.56       958\n",
      "weighted avg       0.67      0.68      0.63       958\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.49      0.58       332\n",
      "           1       0.77      0.89      0.82       626\n",
      "\n",
      "    accuracy                           0.75       958\n",
      "   macro avg       0.73      0.69      0.70       958\n",
      "weighted avg       0.74      0.75      0.74       958\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.58      0.66       332\n",
      "           1       0.80      0.91      0.85       626\n",
      "\n",
      "    accuracy                           0.79       958\n",
      "   macro avg       0.79      0.74      0.76       958\n",
      "weighted avg       0.79      0.79      0.79       958\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.59      0.71       332\n",
      "           1       0.82      0.95      0.88       626\n",
      "\n",
      "    accuracy                           0.83       958\n",
      "   macro avg       0.84      0.77      0.79       958\n",
      "weighted avg       0.84      0.83      0.82       958\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.54      0.65       332\n",
      "           1       0.79      0.93      0.86       626\n",
      "\n",
      "    accuracy                           0.79       958\n",
      "   macro avg       0.80      0.74      0.75       958\n",
      "weighted avg       0.80      0.79      0.78       958\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       332\n",
      "           1       0.78      0.82      0.80       626\n",
      "\n",
      "    accuracy                           0.73       958\n",
      "   macro avg       0.70      0.69      0.70       958\n",
      "weighted avg       0.73      0.73      0.73       958\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70       332\n",
      "           1       0.82      0.94      0.87       626\n",
      "\n",
      "    accuracy                           0.82       958\n",
      "   macro avg       0.83      0.77      0.79       958\n",
      "weighted avg       0.82      0.82      0.81       958\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.57      0.71       332\n",
      "           1       0.81      0.98      0.89       626\n",
      "\n",
      "    accuracy                           0.84       958\n",
      "   macro avg       0.87      0.77      0.80       958\n",
      "weighted avg       0.85      0.84      0.82       958\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.56      0.63       332\n",
      "           1       0.79      0.89      0.84       626\n",
      "\n",
      "    accuracy                           0.77       958\n",
      "   macro avg       0.76      0.72      0.73       958\n",
      "weighted avg       0.77      0.77      0.77       958\n",
      "\n",
      "threeOf9 (4/74)\n",
      "(512, 9) with ratio : 1.1513\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       274\n",
      "           1       0.80      0.80      0.80       238\n",
      "\n",
      "    accuracy                           0.81       512\n",
      "   macro avg       0.81      0.81      0.81       512\n",
      "weighted avg       0.81      0.81      0.81       512\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       274\n",
      "           1       0.81      0.86      0.83       238\n",
      "\n",
      "    accuracy                           0.84       512\n",
      "   macro avg       0.84      0.84      0.84       512\n",
      "weighted avg       0.84      0.84      0.84       512\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       274\n",
      "           1       0.84      0.86      0.85       238\n",
      "\n",
      "    accuracy                           0.86       512\n",
      "   macro avg       0.86      0.86      0.86       512\n",
      "weighted avg       0.86      0.86      0.86       512\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       274\n",
      "           1       0.91      0.92      0.92       238\n",
      "\n",
      "    accuracy                           0.92       512\n",
      "   macro avg       0.92      0.92      0.92       512\n",
      "weighted avg       0.92      0.92      0.92       512\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       274\n",
      "           1       0.87      0.89      0.88       238\n",
      "\n",
      "    accuracy                           0.89       512\n",
      "   macro avg       0.89      0.89      0.89       512\n",
      "weighted avg       0.89      0.89      0.89       512\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       274\n",
      "           1       0.85      0.84      0.85       238\n",
      "\n",
      "    accuracy                           0.86       512\n",
      "   macro avg       0.86      0.86      0.86       512\n",
      "weighted avg       0.86      0.86      0.86       512\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       274\n",
      "           1       0.86      0.85      0.86       238\n",
      "\n",
      "    accuracy                           0.87       512\n",
      "   macro avg       0.87      0.87      0.87       512\n",
      "weighted avg       0.87      0.87      0.87       512\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       274\n",
      "           1       0.88      0.89      0.89       238\n",
      "\n",
      "    accuracy                           0.89       512\n",
      "   macro avg       0.89      0.89      0.89       512\n",
      "weighted avg       0.89      0.89      0.89       512\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       274\n",
      "           1       0.86      0.89      0.87       238\n",
      "\n",
      "    accuracy                           0.88       512\n",
      "   macro avg       0.88      0.88      0.88       512\n",
      "weighted avg       0.88      0.88      0.88       512\n",
      "\n",
      "spectf (5/74)\n",
      "(349, 44) with ratio : 2.6737\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66        95\n",
      "           1       0.87      0.89      0.88       254\n",
      "\n",
      "    accuracy                           0.82       349\n",
      "   macro avg       0.77      0.76      0.77       349\n",
      "weighted avg       0.82      0.82      0.82       349\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70        95\n",
      "           1       0.98      0.71      0.82       254\n",
      "\n",
      "    accuracy                           0.78       349\n",
      "   macro avg       0.77      0.84      0.76       349\n",
      "weighted avg       0.86      0.78      0.79       349\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70        95\n",
      "           1       0.96      0.73      0.83       254\n",
      "\n",
      "    accuracy                           0.78       349\n",
      "   macro avg       0.76      0.83      0.76       349\n",
      "weighted avg       0.85      0.78      0.79       349\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.93      0.73        95\n",
      "           1       0.97      0.77      0.86       254\n",
      "\n",
      "    accuracy                           0.81       349\n",
      "   macro avg       0.78      0.85      0.79       349\n",
      "weighted avg       0.87      0.81      0.82       349\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.73        95\n",
      "           1       0.99      0.72      0.84       254\n",
      "\n",
      "    accuracy                           0.80       349\n",
      "   macro avg       0.78      0.86      0.78       349\n",
      "weighted avg       0.88      0.80      0.81       349\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.66        95\n",
      "           1       0.95      0.69      0.80       254\n",
      "\n",
      "    accuracy                           0.75       349\n",
      "   macro avg       0.73      0.79      0.73       349\n",
      "weighted avg       0.83      0.75      0.76       349\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63        95\n",
      "           1       0.97      0.60      0.74       254\n",
      "\n",
      "    accuracy                           0.70       349\n",
      "   macro avg       0.72      0.78      0.69       349\n",
      "weighted avg       0.84      0.70      0.71       349\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.97      0.63        95\n",
      "           1       0.98      0.59      0.74       254\n",
      "\n",
      "    accuracy                           0.70       349\n",
      "   macro avg       0.73      0.78      0.69       349\n",
      "weighted avg       0.84      0.70      0.71       349\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.92      0.68        95\n",
      "           1       0.96      0.71      0.81       254\n",
      "\n",
      "    accuracy                           0.77       349\n",
      "   macro avg       0.75      0.81      0.75       349\n",
      "weighted avg       0.84      0.77      0.78       349\n",
      "\n",
      "spect (6/74)\n",
      "(267, 22) with ratio : 3.8545\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52        55\n",
      "           1       0.87      0.90      0.89       212\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.72      0.70      0.71       267\n",
      "weighted avg       0.81      0.82      0.81       267\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.35      0.33        55\n",
      "           1       0.83      0.80      0.81       212\n",
      "\n",
      "    accuracy                           0.71       267\n",
      "   macro avg       0.57      0.57      0.57       267\n",
      "weighted avg       0.72      0.71      0.71       267\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45        55\n",
      "           1       0.86      0.81      0.83       212\n",
      "\n",
      "    accuracy                           0.75       267\n",
      "   macro avg       0.63      0.66      0.64       267\n",
      "weighted avg       0.77      0.75      0.76       267\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.49      0.45        55\n",
      "           1       0.86      0.82      0.84       212\n",
      "\n",
      "    accuracy                           0.75       267\n",
      "   macro avg       0.63      0.65      0.64       267\n",
      "weighted avg       0.77      0.75      0.76       267\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35        55\n",
      "           1       0.83      0.83      0.83       212\n",
      "\n",
      "    accuracy                           0.73       267\n",
      "   macro avg       0.59      0.59      0.59       267\n",
      "weighted avg       0.73      0.73      0.73       267\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.51      0.40        55\n",
      "           1       0.85      0.74      0.79       212\n",
      "\n",
      "    accuracy                           0.69       267\n",
      "   macro avg       0.59      0.62      0.60       267\n",
      "weighted avg       0.75      0.69      0.71       267\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.40      0.31        55\n",
      "           1       0.82      0.70      0.76       212\n",
      "\n",
      "    accuracy                           0.64       267\n",
      "   macro avg       0.54      0.55      0.54       267\n",
      "weighted avg       0.70      0.64      0.67       267\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.34        55\n",
      "           1       0.83      0.75      0.79       212\n",
      "\n",
      "    accuracy                           0.68       267\n",
      "   macro avg       0.56      0.57      0.56       267\n",
      "weighted avg       0.72      0.68      0.69       267\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.49      0.42        55\n",
      "           1       0.85      0.78      0.81       212\n",
      "\n",
      "    accuracy                           0.72       267\n",
      "   macro avg       0.61      0.63      0.62       267\n",
      "weighted avg       0.75      0.72      0.73       267\n",
      "\n",
      "sonar (7/74)\n",
      "(208, 60) with ratio : 1.1443\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       111\n",
      "           1       0.73      0.75      0.74        97\n",
      "\n",
      "    accuracy                           0.75       208\n",
      "   macro avg       0.75      0.75      0.75       208\n",
      "weighted avg       0.76      0.75      0.75       208\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       111\n",
      "           1       0.78      0.80      0.79        97\n",
      "\n",
      "    accuracy                           0.80       208\n",
      "   macro avg       0.80      0.80      0.80       208\n",
      "weighted avg       0.80      0.80      0.80       208\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       111\n",
      "           1       0.83      0.76      0.80        97\n",
      "\n",
      "    accuracy                           0.82       208\n",
      "   macro avg       0.82      0.81      0.82       208\n",
      "weighted avg       0.82      0.82      0.82       208\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       111\n",
      "           1       0.85      0.76      0.80        97\n",
      "\n",
      "    accuracy                           0.83       208\n",
      "   macro avg       0.83      0.82      0.82       208\n",
      "weighted avg       0.83      0.83      0.83       208\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       111\n",
      "           1       0.83      0.75      0.79        97\n",
      "\n",
      "    accuracy                           0.81       208\n",
      "   macro avg       0.81      0.81      0.81       208\n",
      "weighted avg       0.81      0.81      0.81       208\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       111\n",
      "           1       0.69      0.68      0.68        97\n",
      "\n",
      "    accuracy                           0.71       208\n",
      "   macro avg       0.71      0.71      0.71       208\n",
      "weighted avg       0.71      0.71      0.71       208\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.70       111\n",
      "           1       0.65      0.60      0.62        97\n",
      "\n",
      "    accuracy                           0.66       208\n",
      "   macro avg       0.66      0.66      0.66       208\n",
      "weighted avg       0.66      0.66      0.66       208\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       111\n",
      "           1       0.75      0.73      0.74        97\n",
      "\n",
      "    accuracy                           0.76       208\n",
      "   macro avg       0.76      0.76      0.76       208\n",
      "weighted avg       0.76      0.76      0.76       208\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       111\n",
      "           1       0.75      0.68      0.71        97\n",
      "\n",
      "    accuracy                           0.75       208\n",
      "   macro avg       0.75      0.74      0.74       208\n",
      "weighted avg       0.75      0.75      0.74       208\n",
      "\n",
      "saheart (8/74)\n",
      "(462, 9) with ratio : 1.8875\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       302\n",
      "           1       0.62      0.50      0.55       160\n",
      "\n",
      "    accuracy                           0.72       462\n",
      "   macro avg       0.69      0.67      0.68       462\n",
      "weighted avg       0.71      0.72      0.71       462\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       302\n",
      "           1       0.54      0.61      0.57       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.66      0.67      0.66       462\n",
      "weighted avg       0.70      0.69      0.69       462\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       302\n",
      "           1       0.54      0.55      0.55       160\n",
      "\n",
      "    accuracy                           0.68       462\n",
      "   macro avg       0.65      0.65      0.65       462\n",
      "weighted avg       0.68      0.68      0.68       462\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       302\n",
      "           1       0.53      0.58      0.56       160\n",
      "\n",
      "    accuracy                           0.68       462\n",
      "   macro avg       0.65      0.65      0.65       462\n",
      "weighted avg       0.69      0.68      0.68       462\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       302\n",
      "           1       0.57      0.65      0.61       160\n",
      "\n",
      "    accuracy                           0.71       462\n",
      "   macro avg       0.68      0.69      0.69       462\n",
      "weighted avg       0.72      0.71      0.71       462\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       302\n",
      "           1       0.55      0.56      0.55       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.66      0.66      0.66       462\n",
      "weighted avg       0.69      0.69      0.69       462\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       302\n",
      "           1       0.54      0.47      0.50       160\n",
      "\n",
      "    accuracy                           0.68       462\n",
      "   macro avg       0.64      0.63      0.63       462\n",
      "weighted avg       0.67      0.68      0.67       462\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       302\n",
      "           1       0.54      0.49      0.52       160\n",
      "\n",
      "    accuracy                           0.68       462\n",
      "   macro avg       0.64      0.64      0.64       462\n",
      "weighted avg       0.67      0.68      0.68       462\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       302\n",
      "           1       0.55      0.56      0.55       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.65      0.66      0.65       462\n",
      "weighted avg       0.69      0.69      0.69       462\n",
      "\n",
      "profb (9/74)\n",
      "(672, 9) with ratio : 2.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       448\n",
      "           1       0.51      0.19      0.27       224\n",
      "\n",
      "    accuracy                           0.67       672\n",
      "   macro avg       0.60      0.55      0.53       672\n",
      "weighted avg       0.63      0.67      0.61       672\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       448\n",
      "           1       0.42      0.41      0.41       224\n",
      "\n",
      "    accuracy                           0.61       672\n",
      "   macro avg       0.56      0.56      0.56       672\n",
      "weighted avg       0.61      0.61      0.61       672\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       448\n",
      "           1       0.42      0.42      0.42       224\n",
      "\n",
      "    accuracy                           0.62       672\n",
      "   macro avg       0.57      0.57      0.57       672\n",
      "weighted avg       0.61      0.62      0.62       672\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       448\n",
      "           1       0.42      0.38      0.40       224\n",
      "\n",
      "    accuracy                           0.62       672\n",
      "   macro avg       0.56      0.56      0.56       672\n",
      "weighted avg       0.61      0.62      0.62       672\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       448\n",
      "           1       0.45      0.42      0.44       224\n",
      "\n",
      "    accuracy                           0.64       672\n",
      "   macro avg       0.59      0.58      0.58       672\n",
      "weighted avg       0.63      0.64      0.63       672\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       448\n",
      "           1       0.43      0.44      0.43       224\n",
      "\n",
      "    accuracy                           0.62       672\n",
      "   macro avg       0.57      0.57      0.57       672\n",
      "weighted avg       0.62      0.62      0.62       672\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       448\n",
      "           1       0.39      0.41      0.40       224\n",
      "\n",
      "    accuracy                           0.59       672\n",
      "   macro avg       0.54      0.55      0.55       672\n",
      "weighted avg       0.60      0.59      0.59       672\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       448\n",
      "           1       0.41      0.39      0.40       224\n",
      "\n",
      "    accuracy                           0.61       672\n",
      "   macro avg       0.56      0.55      0.56       672\n",
      "weighted avg       0.60      0.61      0.61       672\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72       448\n",
      "           1       0.45      0.46      0.45       224\n",
      "\n",
      "    accuracy                           0.63       672\n",
      "   macro avg       0.59      0.59      0.59       672\n",
      "weighted avg       0.63      0.63      0.63       672\n",
      "\n",
      "prnn_synth (10/74)\n",
      "(250, 2) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       125\n",
      "           1       0.84      0.87      0.85       125\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.85      0.85      0.85       250\n",
      "weighted avg       0.85      0.85      0.85       250\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       125\n",
      "           1       0.86      0.88      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       125\n",
      "           1       0.88      0.87      0.88       125\n",
      "\n",
      "    accuracy                           0.88       250\n",
      "   macro avg       0.88      0.88      0.88       250\n",
      "weighted avg       0.88      0.88      0.88       250\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       125\n",
      "           1       0.86      0.88      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       125\n",
      "           1       0.87      0.87      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       125\n",
      "           1       0.85      0.86      0.86       125\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.86      0.86      0.86       250\n",
      "weighted avg       0.86      0.86      0.86       250\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       125\n",
      "           1       0.87      0.88      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       125\n",
      "           1       0.87      0.87      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       125\n",
      "           1       0.87      0.87      0.87       125\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.87      0.87      0.87       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "prnn_crabs (11/74)\n",
      "(200, 7) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       100\n",
      "           1       1.00      0.97      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.98       200\n",
      "weighted avg       0.99      0.98      0.98       200\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       100\n",
      "           1       0.91      0.88      0.89       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.89       200\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       100\n",
      "           1       0.95      0.92      0.93       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.93       200\n",
      "weighted avg       0.94      0.94      0.93       200\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       100\n",
      "           1       0.95      0.95      0.95       100\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.95       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       100\n",
      "           1       0.93      0.91      0.92       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       100\n",
      "           1       1.00      0.98      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      0.99      0.99       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       1.00      0.99      0.99       200\n",
      "weighted avg       1.00      0.99      0.99       200\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       1.00      0.99      0.99       200\n",
      "weighted avg       1.00      0.99      0.99       200\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "postoperative_patient_data (12/74)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82        64\n",
      "           1       0.25      0.04      0.07        24\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.49      0.50      0.45        88\n",
      "weighted avg       0.60      0.70      0.62        88\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70        64\n",
      "           1       0.17      0.17      0.17        24\n",
      "\n",
      "    accuracy                           0.56        88\n",
      "   macro avg       0.43      0.43      0.43        88\n",
      "weighted avg       0.55      0.56      0.55        88\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73        64\n",
      "           1       0.12      0.08      0.10        24\n",
      "\n",
      "    accuracy                           0.58        88\n",
      "   macro avg       0.40      0.42      0.41        88\n",
      "weighted avg       0.53      0.58      0.55        88\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73        64\n",
      "           1       0.17      0.12      0.14        24\n",
      "\n",
      "    accuracy                           0.59        88\n",
      "   macro avg       0.43      0.45      0.44        88\n",
      "weighted avg       0.55      0.59      0.57        88\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71        64\n",
      "           1       0.15      0.12      0.14        24\n",
      "\n",
      "    accuracy                           0.57        88\n",
      "   macro avg       0.42      0.43      0.42        88\n",
      "weighted avg       0.54      0.57      0.56        88\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70        64\n",
      "           1       0.23      0.25      0.24        24\n",
      "\n",
      "    accuracy                           0.57        88\n",
      "   macro avg       0.47      0.47      0.47        88\n",
      "weighted avg       0.58      0.57      0.57        88\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        64\n",
      "           1       0.17      0.17      0.17        24\n",
      "\n",
      "    accuracy                           0.55        88\n",
      "   macro avg       0.43      0.43      0.43        88\n",
      "weighted avg       0.55      0.55      0.55        88\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76        64\n",
      "           1       0.24      0.17      0.20        24\n",
      "\n",
      "    accuracy                           0.62        88\n",
      "   macro avg       0.48      0.48      0.48        88\n",
      "weighted avg       0.59      0.62      0.60        88\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        64\n",
      "           1       0.17      0.17      0.17        24\n",
      "\n",
      "    accuracy                           0.55        88\n",
      "   macro avg       0.43      0.43      0.43        88\n",
      "weighted avg       0.55      0.55      0.55        88\n",
      "\n",
      "parity5 (13/74)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.25      0.23        16\n",
      "           1       0.08      0.06      0.07        16\n",
      "\n",
      "    accuracy                           0.16        32\n",
      "   macro avg       0.14      0.16      0.15        32\n",
      "weighted avg       0.14      0.16      0.15        32\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.19      0.18        16\n",
      "           1       0.13      0.12      0.13        16\n",
      "\n",
      "    accuracy                           0.16        32\n",
      "   macro avg       0.15      0.16      0.16        32\n",
      "weighted avg       0.15      0.16      0.16        32\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12        16\n",
      "           1       0.07      0.06      0.06        16\n",
      "\n",
      "    accuracy                           0.09        32\n",
      "   macro avg       0.09      0.09      0.09        32\n",
      "weighted avg       0.09      0.09      0.09        32\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        16\n",
      "           1       0.06      0.06      0.06        16\n",
      "\n",
      "    accuracy                           0.06        32\n",
      "   macro avg       0.06      0.06      0.06        32\n",
      "weighted avg       0.06      0.06      0.06        32\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.25      0.23        16\n",
      "           1       0.08      0.06      0.07        16\n",
      "\n",
      "    accuracy                           0.16        32\n",
      "   macro avg       0.14      0.16      0.15        32\n",
      "weighted avg       0.14      0.16      0.15        32\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12        16\n",
      "           1       0.12      0.12      0.12        16\n",
      "\n",
      "    accuracy                           0.12        32\n",
      "   macro avg       0.12      0.12      0.12        32\n",
      "weighted avg       0.12      0.12      0.12        32\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12        16\n",
      "           1       0.07      0.06      0.06        16\n",
      "\n",
      "    accuracy                           0.09        32\n",
      "   macro avg       0.09      0.09      0.09        32\n",
      "weighted avg       0.09      0.09      0.09        32\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.06      0.06      0.06        16\n",
      "\n",
      "    accuracy                           0.03        32\n",
      "   macro avg       0.03      0.03      0.03        32\n",
      "weighted avg       0.03      0.03      0.03        32\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.19      0.18        16\n",
      "           1       0.07      0.06      0.07        16\n",
      "\n",
      "    accuracy                           0.12        32\n",
      "   macro avg       0.12      0.12      0.12        32\n",
      "weighted avg       0.12      0.12      0.12        32\n",
      "\n",
      "mux6 (14/74)\n",
      "(128, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63        64\n",
      "           1       0.62      0.59      0.61        64\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.62      0.62      0.62       128\n",
      "weighted avg       0.62      0.62      0.62       128\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94        64\n",
      "           1       0.95      0.92      0.94        64\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.94      0.94      0.94       128\n",
      "weighted avg       0.94      0.94      0.94       128\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        64\n",
      "           1       0.96      0.84      0.90        64\n",
      "\n",
      "    accuracy                           0.91       128\n",
      "   macro avg       0.91      0.91      0.91       128\n",
      "weighted avg       0.91      0.91      0.91       128\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        64\n",
      "           1       0.97      0.88      0.92        64\n",
      "\n",
      "    accuracy                           0.92       128\n",
      "   macro avg       0.93      0.92      0.92       128\n",
      "weighted avg       0.93      0.92      0.92       128\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        64\n",
      "           1       0.97      0.94      0.95        64\n",
      "\n",
      "    accuracy                           0.95       128\n",
      "   macro avg       0.95      0.95      0.95       128\n",
      "weighted avg       0.95      0.95      0.95       128\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        64\n",
      "           1       0.93      0.89      0.91        64\n",
      "\n",
      "    accuracy                           0.91       128\n",
      "   macro avg       0.91      0.91      0.91       128\n",
      "weighted avg       0.91      0.91      0.91       128\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        64\n",
      "           1       0.97      0.94      0.95        64\n",
      "\n",
      "    accuracy                           0.95       128\n",
      "   macro avg       0.95      0.95      0.95       128\n",
      "weighted avg       0.95      0.95      0.95       128\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        64\n",
      "           1       0.97      0.91      0.94        64\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.94      0.94      0.94       128\n",
      "weighted avg       0.94      0.94      0.94       128\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        64\n",
      "           1       0.97      0.94      0.95        64\n",
      "\n",
      "    accuracy                           0.95       128\n",
      "   macro avg       0.95      0.95      0.95       128\n",
      "weighted avg       0.95      0.95      0.95       128\n",
      "\n",
      "monk3 (15/74)\n",
      "(554, 6) with ratio : 1.0827\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       266\n",
      "           1       0.77      0.81      0.79       288\n",
      "\n",
      "    accuracy                           0.78       554\n",
      "   macro avg       0.78      0.78      0.78       554\n",
      "weighted avg       0.78      0.78      0.78       554\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       266\n",
      "           1       0.91      0.89      0.90       288\n",
      "\n",
      "    accuracy                           0.90       554\n",
      "   macro avg       0.90      0.90      0.90       554\n",
      "weighted avg       0.90      0.90      0.90       554\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       266\n",
      "           1       0.91      0.89      0.90       288\n",
      "\n",
      "    accuracy                           0.90       554\n",
      "   macro avg       0.90      0.90      0.90       554\n",
      "weighted avg       0.90      0.90      0.90       554\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       266\n",
      "           1       0.95      0.90      0.92       288\n",
      "\n",
      "    accuracy                           0.92       554\n",
      "   macro avg       0.92      0.92      0.92       554\n",
      "weighted avg       0.92      0.92      0.92       554\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       266\n",
      "           1       0.91      0.89      0.90       288\n",
      "\n",
      "    accuracy                           0.90       554\n",
      "   macro avg       0.90      0.90      0.90       554\n",
      "weighted avg       0.90      0.90      0.90       554\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       266\n",
      "           1       0.90      0.89      0.90       288\n",
      "\n",
      "    accuracy                           0.89       554\n",
      "   macro avg       0.89      0.89      0.89       554\n",
      "weighted avg       0.89      0.89      0.89       554\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       266\n",
      "           1       0.88      0.89      0.89       288\n",
      "\n",
      "    accuracy                           0.88       554\n",
      "   macro avg       0.88      0.88      0.88       554\n",
      "weighted avg       0.88      0.88      0.88       554\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       266\n",
      "           1       0.93      0.90      0.92       288\n",
      "\n",
      "    accuracy                           0.91       554\n",
      "   macro avg       0.91      0.91      0.91       554\n",
      "weighted avg       0.91      0.91      0.91       554\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       266\n",
      "           1       0.92      0.88      0.90       288\n",
      "\n",
      "    accuracy                           0.90       554\n",
      "   macro avg       0.90      0.90      0.90       554\n",
      "weighted avg       0.90      0.90      0.90       554\n",
      "\n",
      "monk2 (16/74)\n",
      "(601, 6) with ratio : 1.9175\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       395\n",
      "           1       0.00      0.00      0.00       206\n",
      "\n",
      "    accuracy                           0.64       601\n",
      "   macro avg       0.33      0.49      0.39       601\n",
      "weighted avg       0.43      0.64      0.51       601\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       395\n",
      "           1       0.83      0.79      0.81       206\n",
      "\n",
      "    accuracy                           0.87       601\n",
      "   macro avg       0.86      0.85      0.86       601\n",
      "weighted avg       0.87      0.87      0.87       601\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       395\n",
      "           1       0.83      0.82      0.82       206\n",
      "\n",
      "    accuracy                           0.88       601\n",
      "   macro avg       0.87      0.86      0.87       601\n",
      "weighted avg       0.88      0.88      0.88       601\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       395\n",
      "           1       0.86      0.86      0.86       206\n",
      "\n",
      "    accuracy                           0.90       601\n",
      "   macro avg       0.89      0.89      0.89       601\n",
      "weighted avg       0.90      0.90      0.90       601\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       395\n",
      "           1       0.86      0.80      0.83       206\n",
      "\n",
      "    accuracy                           0.89       601\n",
      "   macro avg       0.88      0.87      0.87       601\n",
      "weighted avg       0.89      0.89      0.89       601\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       395\n",
      "           1       0.81      0.80      0.80       206\n",
      "\n",
      "    accuracy                           0.87       601\n",
      "   macro avg       0.85      0.85      0.85       601\n",
      "weighted avg       0.86      0.87      0.86       601\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       395\n",
      "           1       0.81      0.84      0.83       206\n",
      "\n",
      "    accuracy                           0.88       601\n",
      "   macro avg       0.86      0.87      0.87       601\n",
      "weighted avg       0.88      0.88      0.88       601\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       395\n",
      "           1       0.87      0.86      0.87       206\n",
      "\n",
      "    accuracy                           0.91       601\n",
      "   macro avg       0.90      0.90      0.90       601\n",
      "weighted avg       0.91      0.91      0.91       601\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       395\n",
      "           1       0.85      0.80      0.83       206\n",
      "\n",
      "    accuracy                           0.89       601\n",
      "   macro avg       0.88      0.87      0.87       601\n",
      "weighted avg       0.88      0.89      0.88       601\n",
      "\n",
      "monk1 (17/74)\n",
      "(556, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59       278\n",
      "           1       0.59      0.59      0.59       278\n",
      "\n",
      "    accuracy                           0.59       556\n",
      "   macro avg       0.59      0.59      0.59       556\n",
      "weighted avg       0.59      0.59      0.59       556\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       278\n",
      "           1       0.69      0.74      0.72       278\n",
      "\n",
      "    accuracy                           0.71       556\n",
      "   macro avg       0.71      0.71      0.70       556\n",
      "weighted avg       0.71      0.71      0.70       556\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       278\n",
      "           1       0.75      0.74      0.75       278\n",
      "\n",
      "    accuracy                           0.75       556\n",
      "   macro avg       0.75      0.75      0.75       556\n",
      "weighted avg       0.75      0.75      0.75       556\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       278\n",
      "           1       0.75      0.74      0.75       278\n",
      "\n",
      "    accuracy                           0.75       556\n",
      "   macro avg       0.75      0.75      0.75       556\n",
      "weighted avg       0.75      0.75      0.75       556\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       278\n",
      "           1       0.73      0.75      0.74       278\n",
      "\n",
      "    accuracy                           0.74       556\n",
      "   macro avg       0.74      0.74      0.74       556\n",
      "weighted avg       0.74      0.74      0.74       556\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       278\n",
      "           1       0.70      0.76      0.72       278\n",
      "\n",
      "    accuracy                           0.71       556\n",
      "   macro avg       0.71      0.71      0.71       556\n",
      "weighted avg       0.71      0.71      0.71       556\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76       278\n",
      "           1       0.76      0.73      0.75       278\n",
      "\n",
      "    accuracy                           0.75       556\n",
      "   macro avg       0.75      0.75      0.75       556\n",
      "weighted avg       0.75      0.75      0.75       556\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74       278\n",
      "           1       0.74      0.75      0.74       278\n",
      "\n",
      "    accuracy                           0.74       556\n",
      "   macro avg       0.74      0.74      0.74       556\n",
      "weighted avg       0.74      0.74      0.74       556\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       278\n",
      "           1       0.71      0.75      0.73       278\n",
      "\n",
      "    accuracy                           0.72       556\n",
      "   macro avg       0.73      0.72      0.72       556\n",
      "weighted avg       0.73      0.72      0.72       556\n",
      "\n",
      "molecular_biology_promoters (18/74)\n",
      "(106, 57) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        53\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.77       106\n",
      "   macro avg       0.77      0.77      0.77       106\n",
      "weighted avg       0.77      0.77      0.77       106\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76        53\n",
      "           1       0.76      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.76       106\n",
      "   macro avg       0.76      0.76      0.76       106\n",
      "weighted avg       0.76      0.76      0.76       106\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75        53\n",
      "           1       0.75      0.74      0.74        53\n",
      "\n",
      "    accuracy                           0.75       106\n",
      "   macro avg       0.75      0.75      0.75       106\n",
      "weighted avg       0.75      0.75      0.75       106\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85        53\n",
      "           1       0.86      0.83      0.85        53\n",
      "\n",
      "    accuracy                           0.85       106\n",
      "   macro avg       0.85      0.85      0.85       106\n",
      "weighted avg       0.85      0.85      0.85       106\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        53\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.77       106\n",
      "   macro avg       0.77      0.77      0.77       106\n",
      "weighted avg       0.77      0.77      0.77       106\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        53\n",
      "           1       0.70      0.70      0.70        53\n",
      "\n",
      "    accuracy                           0.70       106\n",
      "   macro avg       0.70      0.70      0.70       106\n",
      "weighted avg       0.70      0.70      0.70       106\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61        53\n",
      "           1       0.62      0.68      0.65        53\n",
      "\n",
      "    accuracy                           0.63       106\n",
      "   macro avg       0.63      0.63      0.63       106\n",
      "weighted avg       0.63      0.63      0.63       106\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        53\n",
      "           1       0.71      0.75      0.73        53\n",
      "\n",
      "    accuracy                           0.73       106\n",
      "   macro avg       0.73      0.73      0.73       106\n",
      "weighted avg       0.73      0.73      0.73       106\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75        53\n",
      "           1       0.75      0.77      0.76        53\n",
      "\n",
      "    accuracy                           0.75       106\n",
      "   macro avg       0.76      0.75      0.75       106\n",
      "weighted avg       0.76      0.75      0.75       106\n",
      "\n",
      "lupus (19/74)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        52\n",
      "           1       0.75      0.69      0.72        35\n",
      "\n",
      "    accuracy                           0.78        87\n",
      "   macro avg       0.78      0.77      0.77        87\n",
      "weighted avg       0.78      0.78      0.78        87\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        52\n",
      "           1       0.66      0.66      0.66        35\n",
      "\n",
      "    accuracy                           0.72        87\n",
      "   macro avg       0.71      0.71      0.71        87\n",
      "weighted avg       0.72      0.72      0.72        87\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        52\n",
      "           1       0.70      0.66      0.68        35\n",
      "\n",
      "    accuracy                           0.75        87\n",
      "   macro avg       0.74      0.73      0.73        87\n",
      "weighted avg       0.75      0.75      0.75        87\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        52\n",
      "           1       0.69      0.63      0.66        35\n",
      "\n",
      "    accuracy                           0.74        87\n",
      "   macro avg       0.73      0.72      0.72        87\n",
      "weighted avg       0.73      0.74      0.73        87\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        52\n",
      "           1       0.69      0.63      0.66        35\n",
      "\n",
      "    accuracy                           0.74        87\n",
      "   macro avg       0.73      0.72      0.72        87\n",
      "weighted avg       0.73      0.74      0.73        87\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78        52\n",
      "           1       0.69      0.57      0.62        35\n",
      "\n",
      "    accuracy                           0.72        87\n",
      "   macro avg       0.72      0.70      0.70        87\n",
      "weighted avg       0.72      0.72      0.72        87\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75        52\n",
      "           1       0.64      0.60      0.62        35\n",
      "\n",
      "    accuracy                           0.70        87\n",
      "   macro avg       0.69      0.68      0.69        87\n",
      "weighted avg       0.70      0.70      0.70        87\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        52\n",
      "           1       0.63      0.63      0.63        35\n",
      "\n",
      "    accuracy                           0.70        87\n",
      "   macro avg       0.69      0.69      0.69        87\n",
      "weighted avg       0.70      0.70      0.70        87\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80        52\n",
      "           1       0.72      0.66      0.69        35\n",
      "\n",
      "    accuracy                           0.76        87\n",
      "   macro avg       0.75      0.74      0.75        87\n",
      "weighted avg       0.76      0.76      0.76        87\n",
      "\n",
      "labor (20/74)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77        20\n",
      "           1       0.87      0.89      0.88        37\n",
      "\n",
      "    accuracy                           0.84        57\n",
      "   macro avg       0.83      0.82      0.82        57\n",
      "weighted avg       0.84      0.84      0.84        57\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        20\n",
      "           1       0.91      0.86      0.89        37\n",
      "\n",
      "    accuracy                           0.86        57\n",
      "   macro avg       0.84      0.86      0.85        57\n",
      "weighted avg       0.86      0.86      0.86        57\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        20\n",
      "           1       0.97      0.92      0.94        37\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.93      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        20\n",
      "           1       0.97      0.86      0.91        37\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.88      0.91      0.89        57\n",
      "weighted avg       0.91      0.89      0.90        57\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        20\n",
      "           1       0.94      0.84      0.89        37\n",
      "\n",
      "    accuracy                           0.86        57\n",
      "   macro avg       0.84      0.87      0.85        57\n",
      "weighted avg       0.87      0.86      0.86        57\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        20\n",
      "           1       0.88      0.78      0.83        37\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.77      0.79      0.78        57\n",
      "weighted avg       0.80      0.79      0.79        57\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.84      0.86      0.85        37\n",
      "\n",
      "    accuracy                           0.81        57\n",
      "   macro avg       0.79      0.78      0.79        57\n",
      "weighted avg       0.81      0.81      0.81        57\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        20\n",
      "           1       0.88      0.81      0.85        37\n",
      "\n",
      "    accuracy                           0.81        57\n",
      "   macro avg       0.79      0.81      0.79        57\n",
      "weighted avg       0.82      0.81      0.81        57\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        20\n",
      "           1       0.88      0.78      0.83        37\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.77      0.79      0.78        57\n",
      "weighted avg       0.80      0.79      0.79        57\n",
      "\n",
      "irish (21/74)\n",
      "(500, 5) with ratio : 1.2523\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       278\n",
      "           1       0.73      0.71      0.72       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       278\n",
      "           1       0.90      0.95      0.92       222\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.93      0.93      0.93       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       278\n",
      "           1       0.92      0.96      0.94       222\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       278\n",
      "           1       0.93      0.95      0.94       222\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.95      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       278\n",
      "           1       0.91      0.95      0.93       222\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.93      0.94      0.94       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       278\n",
      "           1       0.91      0.95      0.93       222\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.94      0.94      0.94       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       278\n",
      "           1       0.94      0.95      0.94       222\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.95      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       278\n",
      "           1       0.93      0.95      0.94       222\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.95      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       278\n",
      "           1       0.90      0.95      0.92       222\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.93      0.93      0.93       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "ionosphere (22/74)\n",
      "(351, 34) with ratio : 1.7857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.82       126\n",
      "           1       0.87      0.96      0.92       225\n",
      "\n",
      "    accuracy                           0.89       351\n",
      "   macro avg       0.90      0.86      0.87       351\n",
      "weighted avg       0.89      0.89      0.88       351\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77       126\n",
      "           1       0.84      0.97      0.90       225\n",
      "\n",
      "    accuracy                           0.86       351\n",
      "   macro avg       0.88      0.82      0.84       351\n",
      "weighted avg       0.87      0.86      0.85       351\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73       126\n",
      "           1       0.81      0.98      0.89       225\n",
      "\n",
      "    accuracy                           0.84       351\n",
      "   macro avg       0.88      0.78      0.81       351\n",
      "weighted avg       0.86      0.84      0.83       351\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.63      0.76       126\n",
      "           1       0.83      0.98      0.90       225\n",
      "\n",
      "    accuracy                           0.86       351\n",
      "   macro avg       0.89      0.81      0.83       351\n",
      "weighted avg       0.87      0.86      0.85       351\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77       126\n",
      "           1       0.84      0.97      0.90       225\n",
      "\n",
      "    accuracy                           0.86       351\n",
      "   macro avg       0.88      0.82      0.84       351\n",
      "weighted avg       0.87      0.86      0.85       351\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.41      0.58       126\n",
      "           1       0.75      1.00      0.86       225\n",
      "\n",
      "    accuracy                           0.79       351\n",
      "   macro avg       0.87      0.70      0.72       351\n",
      "weighted avg       0.83      0.79      0.76       351\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.36      0.52       126\n",
      "           1       0.73      1.00      0.85       225\n",
      "\n",
      "    accuracy                           0.77       351\n",
      "   macro avg       0.86      0.68      0.68       351\n",
      "weighted avg       0.82      0.77      0.73       351\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.40      0.57       126\n",
      "           1       0.75      1.00      0.85       225\n",
      "\n",
      "    accuracy                           0.78       351\n",
      "   macro avg       0.86      0.70      0.71       351\n",
      "weighted avg       0.83      0.78      0.75       351\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.44      0.60       126\n",
      "           1       0.76      1.00      0.86       225\n",
      "\n",
      "    accuracy                           0.79       351\n",
      "   macro avg       0.87      0.72      0.73       351\n",
      "weighted avg       0.84      0.79      0.77       351\n",
      "\n",
      "horse_colic_surgery (23/74)\n",
      "Probably not found dataset horse_colic_surgery in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "hepatitis (24/74)\n",
      "(155, 19) with ratio : 3.8438\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56        32\n",
      "           1       0.89      0.89      0.89       123\n",
      "\n",
      "    accuracy                           0.82       155\n",
      "   macro avg       0.72      0.72      0.72       155\n",
      "weighted avg       0.82      0.82      0.82       155\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.75      0.65        32\n",
      "           1       0.93      0.85      0.89       123\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.75      0.80      0.77       155\n",
      "weighted avg       0.86      0.83      0.84       155\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68        32\n",
      "           1       0.94      0.86      0.90       123\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.77      0.82      0.79       155\n",
      "weighted avg       0.87      0.85      0.85       155\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        32\n",
      "           1       0.91      0.86      0.89       123\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.74      0.77      0.75       155\n",
      "weighted avg       0.84      0.83      0.83       155\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.64        32\n",
      "           1       0.92      0.86      0.89       123\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.75      0.79      0.76       155\n",
      "weighted avg       0.85      0.83      0.84       155\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.66      0.55        32\n",
      "           1       0.90      0.80      0.85       123\n",
      "\n",
      "    accuracy                           0.77       155\n",
      "   macro avg       0.68      0.73      0.70       155\n",
      "weighted avg       0.81      0.77      0.79       155\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56        32\n",
      "           1       0.89      0.89      0.89       123\n",
      "\n",
      "    accuracy                           0.82       155\n",
      "   macro avg       0.72      0.72      0.72       155\n",
      "weighted avg       0.82      0.82      0.82       155\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58        32\n",
      "           1       0.89      0.90      0.90       123\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.74      0.73      0.74       155\n",
      "weighted avg       0.83      0.83      0.83       155\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.72      0.62        32\n",
      "           1       0.92      0.85      0.88       123\n",
      "\n",
      "    accuracy                           0.82       155\n",
      "   macro avg       0.73      0.78      0.75       155\n",
      "weighted avg       0.84      0.82      0.83       155\n",
      "\n",
      "heart_disease_zurich (25/74)\n",
      "Probably not found dataset heart_disease_zurich in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_va_long_beach (26/74)\n",
      "Probably not found dataset heart_disease_va_long_beach in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_hungarian (27/74)\n",
      "Probably not found dataset heart_disease_hungarian in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_cleveland (28/74)\n",
      "Probably not found dataset heart_disease_cleveland in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "haberman (29/74)\n",
      "(306, 3) with ratio : 2.7778\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.84       225\n",
      "           1       0.55      0.15      0.23        81\n",
      "\n",
      "    accuracy                           0.74       306\n",
      "   macro avg       0.65      0.55      0.54       306\n",
      "weighted avg       0.70      0.74      0.68       306\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       225\n",
      "           1       0.48      0.42      0.45        81\n",
      "\n",
      "    accuracy                           0.73       306\n",
      "   macro avg       0.64      0.63      0.63       306\n",
      "weighted avg       0.71      0.73      0.72       306\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       225\n",
      "           1       0.40      0.33      0.36        81\n",
      "\n",
      "    accuracy                           0.69       306\n",
      "   macro avg       0.59      0.58      0.58       306\n",
      "weighted avg       0.67      0.69      0.68       306\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80       225\n",
      "           1       0.41      0.35      0.38        81\n",
      "\n",
      "    accuracy                           0.70       306\n",
      "   macro avg       0.59      0.58      0.59       306\n",
      "weighted avg       0.68      0.70      0.69       306\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81       225\n",
      "           1       0.45      0.41      0.43        81\n",
      "\n",
      "    accuracy                           0.71       306\n",
      "   macro avg       0.62      0.61      0.62       306\n",
      "weighted avg       0.70      0.71      0.70       306\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       225\n",
      "           1       0.45      0.40      0.42        81\n",
      "\n",
      "    accuracy                           0.71       306\n",
      "   macro avg       0.62      0.61      0.61       306\n",
      "weighted avg       0.70      0.71      0.71       306\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       225\n",
      "           1       0.36      0.32      0.34        81\n",
      "\n",
      "    accuracy                           0.67       306\n",
      "   macro avg       0.56      0.56      0.56       306\n",
      "weighted avg       0.66      0.67      0.66       306\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79       225\n",
      "           1       0.38      0.33      0.36        81\n",
      "\n",
      "    accuracy                           0.68       306\n",
      "   macro avg       0.58      0.57      0.57       306\n",
      "weighted avg       0.67      0.68      0.67       306\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       225\n",
      "           1       0.44      0.40      0.42        81\n",
      "\n",
      "    accuracy                           0.71       306\n",
      "   macro avg       0.61      0.61      0.61       306\n",
      "weighted avg       0.70      0.71      0.70       306\n",
      "\n",
      "glass2 (30/74)\n",
      "(163, 9) with ratio : 1.1447\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73        87\n",
      "           1       0.70      0.62      0.66        76\n",
      "\n",
      "    accuracy                           0.70       163\n",
      "   macro avg       0.70      0.69      0.69       163\n",
      "weighted avg       0.70      0.70      0.70       163\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78        87\n",
      "           1       0.77      0.66      0.71        76\n",
      "\n",
      "    accuracy                           0.75       163\n",
      "   macro avg       0.75      0.74      0.74       163\n",
      "weighted avg       0.75      0.75      0.75       163\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        87\n",
      "           1       0.79      0.70      0.74        76\n",
      "\n",
      "    accuracy                           0.77       163\n",
      "   macro avg       0.78      0.77      0.77       163\n",
      "weighted avg       0.77      0.77      0.77       163\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        87\n",
      "           1       0.80      0.64      0.72        76\n",
      "\n",
      "    accuracy                           0.76       163\n",
      "   macro avg       0.77      0.75      0.75       163\n",
      "weighted avg       0.77      0.76      0.76       163\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77        87\n",
      "           1       0.75      0.68      0.72        76\n",
      "\n",
      "    accuracy                           0.75       163\n",
      "   macro avg       0.75      0.74      0.75       163\n",
      "weighted avg       0.75      0.75      0.75       163\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        87\n",
      "           1       0.73      0.71      0.72        76\n",
      "\n",
      "    accuracy                           0.74       163\n",
      "   macro avg       0.74      0.74      0.74       163\n",
      "weighted avg       0.74      0.74      0.74       163\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        87\n",
      "           1       0.77      0.75      0.76        76\n",
      "\n",
      "    accuracy                           0.78       163\n",
      "   macro avg       0.78      0.78      0.78       163\n",
      "weighted avg       0.78      0.78      0.78       163\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        87\n",
      "           1       0.76      0.71      0.73        76\n",
      "\n",
      "    accuracy                           0.76       163\n",
      "   macro avg       0.76      0.76      0.76       163\n",
      "weighted avg       0.76      0.76      0.76       163\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73        87\n",
      "           1       0.69      0.70      0.69        76\n",
      "\n",
      "    accuracy                           0.71       163\n",
      "   macro avg       0.71      0.71      0.71       163\n",
      "weighted avg       0.71      0.71      0.71       163\n",
      "\n",
      "credit_approval_germany (31/74)\n",
      "Probably not found dataset credit_approval_germany in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "credit_approval_australia (32/74)\n",
      "Probably not found dataset credit_approval_australia in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "corral (33/74)\n",
      "(160, 6) with ratio : 1.2857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        90\n",
      "           1       0.87      0.84      0.86        70\n",
      "\n",
      "    accuracy                           0.88       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.87      0.88      0.87       160\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        90\n",
      "           1       0.89      0.84      0.87        70\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.89      0.88      0.88       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88        90\n",
      "           1       0.84      0.87      0.85        70\n",
      "\n",
      "    accuracy                           0.87       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88        90\n",
      "           1       0.84      0.87      0.85        70\n",
      "\n",
      "    accuracy                           0.87       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        90\n",
      "           1       0.89      0.84      0.87        70\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.89      0.88      0.88       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92        90\n",
      "           1       0.91      0.87      0.89        70\n",
      "\n",
      "    accuracy                           0.91       160\n",
      "   macro avg       0.91      0.90      0.90       160\n",
      "weighted avg       0.91      0.91      0.91       160\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89        90\n",
      "           1       0.84      0.89      0.86        70\n",
      "\n",
      "    accuracy                           0.88       160\n",
      "   macro avg       0.87      0.88      0.87       160\n",
      "weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88        90\n",
      "           1       0.83      0.86      0.85        70\n",
      "\n",
      "    accuracy                           0.86       160\n",
      "   macro avg       0.86      0.86      0.86       160\n",
      "weighted avg       0.86      0.86      0.86       160\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91        90\n",
      "           1       0.91      0.84      0.87        70\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.90      0.89      0.89       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "congressional_voting_records (34/74)\n",
      "Probably not found dataset congressional_voting_records in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "bupa (35/74)\n",
      "(345, 5) with ratio : 1.0414\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       169\n",
      "           1       0.65      0.58      0.61       176\n",
      "\n",
      "    accuracy                           0.63       345\n",
      "   macro avg       0.63      0.63      0.63       345\n",
      "weighted avg       0.63      0.63      0.63       345\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60       169\n",
      "           1       0.61      0.56      0.58       176\n",
      "\n",
      "    accuracy                           0.59       345\n",
      "   macro avg       0.60      0.59      0.59       345\n",
      "weighted avg       0.60      0.59      0.59       345\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56       169\n",
      "           1       0.58      0.56      0.57       176\n",
      "\n",
      "    accuracy                           0.57       345\n",
      "   macro avg       0.57      0.57      0.57       345\n",
      "weighted avg       0.57      0.57      0.57       345\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       169\n",
      "           1       0.58      0.57      0.58       176\n",
      "\n",
      "    accuracy                           0.57       345\n",
      "   macro avg       0.57      0.57      0.57       345\n",
      "weighted avg       0.57      0.57      0.57       345\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       169\n",
      "           1       0.60      0.53      0.57       176\n",
      "\n",
      "    accuracy                           0.58       345\n",
      "   macro avg       0.58      0.58      0.58       345\n",
      "weighted avg       0.58      0.58      0.58       345\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.60       169\n",
      "           1       0.61      0.58      0.59       176\n",
      "\n",
      "    accuracy                           0.59       345\n",
      "   macro avg       0.59      0.59      0.59       345\n",
      "weighted avg       0.59      0.59      0.59       345\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       169\n",
      "           1       0.60      0.56      0.58       176\n",
      "\n",
      "    accuracy                           0.59       345\n",
      "   macro avg       0.59      0.59      0.59       345\n",
      "weighted avg       0.59      0.59      0.59       345\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54       169\n",
      "           1       0.56      0.57      0.57       176\n",
      "\n",
      "    accuracy                           0.55       345\n",
      "   macro avg       0.55      0.55      0.55       345\n",
      "weighted avg       0.55      0.55      0.55       345\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64       169\n",
      "           1       0.65      0.56      0.60       176\n",
      "\n",
      "    accuracy                           0.62       345\n",
      "   macro avg       0.63      0.62      0.62       345\n",
      "weighted avg       0.63      0.62      0.62       345\n",
      "\n",
      "breast_cancer_wisconsin_original (36/74)\n",
      "Probably not found dataset breast_cancer_wisconsin_original in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "breast_cancer_wisconsin_diagnostic (37/74)\n",
      "Probably not found dataset breast_cancer_wisconsin_diagnostic in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "breast_cancer (38/74)\n",
      "(286, 9) with ratio : 2.3647\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       201\n",
      "           1       0.56      0.32      0.41        85\n",
      "\n",
      "    accuracy                           0.72       286\n",
      "   macro avg       0.66      0.61      0.61       286\n",
      "weighted avg       0.70      0.72      0.70       286\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       201\n",
      "           1       0.48      0.51      0.49        85\n",
      "\n",
      "    accuracy                           0.69       286\n",
      "   macro avg       0.63      0.64      0.63       286\n",
      "weighted avg       0.69      0.69      0.69       286\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       201\n",
      "           1       0.53      0.49      0.51        85\n",
      "\n",
      "    accuracy                           0.72       286\n",
      "   macro avg       0.66      0.66      0.66       286\n",
      "weighted avg       0.71      0.72      0.72       286\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       201\n",
      "           1       0.53      0.47      0.50        85\n",
      "\n",
      "    accuracy                           0.72       286\n",
      "   macro avg       0.66      0.65      0.65       286\n",
      "weighted avg       0.71      0.72      0.71       286\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       201\n",
      "           1       0.49      0.58      0.53        85\n",
      "\n",
      "    accuracy                           0.70       286\n",
      "   macro avg       0.65      0.66      0.66       286\n",
      "weighted avg       0.71      0.70      0.71       286\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       201\n",
      "           1       0.51      0.51      0.51        85\n",
      "\n",
      "    accuracy                           0.71       286\n",
      "   macro avg       0.65      0.65      0.65       286\n",
      "weighted avg       0.71      0.71      0.71       286\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       201\n",
      "           1       0.45      0.51      0.48        85\n",
      "\n",
      "    accuracy                           0.67       286\n",
      "   macro avg       0.62      0.62      0.62       286\n",
      "weighted avg       0.68      0.67      0.68       286\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       201\n",
      "           1       0.49      0.42      0.45        85\n",
      "\n",
      "    accuracy                           0.70       286\n",
      "   macro avg       0.63      0.62      0.62       286\n",
      "weighted avg       0.68      0.70      0.69       286\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       201\n",
      "           1       0.53      0.53      0.53        85\n",
      "\n",
      "    accuracy                           0.72       286\n",
      "   macro avg       0.67      0.67      0.67       286\n",
      "weighted avg       0.72      0.72      0.72       286\n",
      "\n",
      "biomed (39/74)\n",
      "(209, 8) with ratio : 1.7867\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80        75\n",
      "           1       0.87      0.93      0.90       134\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.86      0.84      0.85       209\n",
      "weighted avg       0.87      0.87      0.86       209\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79        75\n",
      "           1       0.86      0.94      0.90       134\n",
      "\n",
      "    accuracy                           0.86       209\n",
      "   macro avg       0.86      0.83      0.84       209\n",
      "weighted avg       0.86      0.86      0.86       209\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        75\n",
      "           1       0.87      0.94      0.90       134\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.87      0.84      0.85       209\n",
      "weighted avg       0.87      0.87      0.87       209\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82        75\n",
      "           1       0.88      0.95      0.91       134\n",
      "\n",
      "    accuracy                           0.88       209\n",
      "   macro avg       0.88      0.85      0.87       209\n",
      "weighted avg       0.88      0.88      0.88       209\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.79        75\n",
      "           1       0.86      0.95      0.90       134\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.87      0.83      0.85       209\n",
      "weighted avg       0.87      0.87      0.86       209\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75        75\n",
      "           1       0.84      0.92      0.88       134\n",
      "\n",
      "    accuracy                           0.84       209\n",
      "   macro avg       0.83      0.81      0.82       209\n",
      "weighted avg       0.84      0.84      0.83       209\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77        75\n",
      "           1       0.86      0.90      0.88       134\n",
      "\n",
      "    accuracy                           0.84       209\n",
      "   macro avg       0.83      0.82      0.82       209\n",
      "weighted avg       0.84      0.84      0.84       209\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78        75\n",
      "           1       0.85      0.95      0.89       134\n",
      "\n",
      "    accuracy                           0.86       209\n",
      "   macro avg       0.86      0.82      0.84       209\n",
      "weighted avg       0.86      0.86      0.85       209\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        75\n",
      "           1       0.85      0.95      0.90       134\n",
      "\n",
      "    accuracy                           0.86       209\n",
      "   macro avg       0.87      0.83      0.84       209\n",
      "weighted avg       0.86      0.86      0.86       209\n",
      "\n",
      "backache (40/74)\n",
      "(180, 32) with ratio : 6.2000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       155\n",
      "           1       0.18      0.16      0.17        25\n",
      "\n",
      "    accuracy                           0.78       180\n",
      "   macro avg       0.52      0.52      0.52       180\n",
      "weighted avg       0.77      0.78      0.78       180\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78       155\n",
      "           1       0.20      0.48      0.29        25\n",
      "\n",
      "    accuracy                           0.67       180\n",
      "   macro avg       0.55      0.59      0.53       180\n",
      "weighted avg       0.80      0.67      0.71       180\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       155\n",
      "           1       0.18      0.36      0.24        25\n",
      "\n",
      "    accuracy                           0.68       180\n",
      "   macro avg       0.53      0.54      0.52       180\n",
      "weighted avg       0.78      0.68      0.72       180\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.83       155\n",
      "           1       0.24      0.48      0.32        25\n",
      "\n",
      "    accuracy                           0.72       180\n",
      "   macro avg       0.57      0.62      0.57       180\n",
      "weighted avg       0.81      0.72      0.76       180\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80       155\n",
      "           1       0.26      0.64      0.37        25\n",
      "\n",
      "    accuracy                           0.69       180\n",
      "   macro avg       0.59      0.67      0.58       180\n",
      "weighted avg       0.83      0.69      0.74       180\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       155\n",
      "           1       0.23      0.52      0.32        25\n",
      "\n",
      "    accuracy                           0.69       180\n",
      "   macro avg       0.57      0.62      0.56       180\n",
      "weighted avg       0.81      0.69      0.73       180\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       155\n",
      "           1       0.24      0.40      0.30        25\n",
      "\n",
      "    accuracy                           0.74       180\n",
      "   macro avg       0.56      0.60      0.57       180\n",
      "weighted avg       0.80      0.74      0.76       180\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       155\n",
      "           1       0.28      0.44      0.34        25\n",
      "\n",
      "    accuracy                           0.76       180\n",
      "   macro avg       0.59      0.63      0.60       180\n",
      "weighted avg       0.81      0.76      0.78       180\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       155\n",
      "           1       0.22      0.44      0.29        25\n",
      "\n",
      "    accuracy                           0.70       180\n",
      "   macro avg       0.55      0.59      0.55       180\n",
      "weighted avg       0.80      0.70      0.74       180\n",
      "\n",
      "appendicitis (41/74)\n",
      "(106, 7) with ratio : 4.0476\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        85\n",
      "           1       0.67      0.48      0.56        21\n",
      "\n",
      "    accuracy                           0.85       106\n",
      "   macro avg       0.77      0.71      0.73       106\n",
      "weighted avg       0.84      0.85      0.84       106\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        85\n",
      "           1       0.56      0.71      0.62        21\n",
      "\n",
      "    accuracy                           0.83       106\n",
      "   macro avg       0.74      0.79      0.76       106\n",
      "weighted avg       0.85      0.83      0.84       106\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        85\n",
      "           1       0.62      0.71      0.67        21\n",
      "\n",
      "    accuracy                           0.86       106\n",
      "   macro avg       0.78      0.80      0.79       106\n",
      "weighted avg       0.87      0.86      0.86       106\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89        85\n",
      "           1       0.56      0.67      0.61        21\n",
      "\n",
      "    accuracy                           0.83       106\n",
      "   macro avg       0.74      0.77      0.75       106\n",
      "weighted avg       0.84      0.83      0.84       106\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88        85\n",
      "           1       0.52      0.71      0.60        21\n",
      "\n",
      "    accuracy                           0.81       106\n",
      "   macro avg       0.72      0.77      0.74       106\n",
      "weighted avg       0.84      0.81      0.82       106\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        85\n",
      "           1       0.67      0.67      0.67        21\n",
      "\n",
      "    accuracy                           0.87       106\n",
      "   macro avg       0.79      0.79      0.79       106\n",
      "weighted avg       0.87      0.87      0.87       106\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90        85\n",
      "           1       0.61      0.52      0.56        21\n",
      "\n",
      "    accuracy                           0.84       106\n",
      "   macro avg       0.75      0.72      0.73       106\n",
      "weighted avg       0.83      0.84      0.83       106\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        85\n",
      "           1       0.75      0.57      0.65        21\n",
      "\n",
      "    accuracy                           0.88       106\n",
      "   macro avg       0.82      0.76      0.79       106\n",
      "weighted avg       0.87      0.88      0.87       106\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        85\n",
      "           1       0.63      0.57      0.60        21\n",
      "\n",
      "    accuracy                           0.85       106\n",
      "   macro avg       0.76      0.74      0.75       106\n",
      "weighted avg       0.84      0.85      0.85       106\n",
      "\n",
      "analcatdata_lawsuit (42/74)\n",
      "(264, 4) with ratio : 12.8947\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       245\n",
      "           1       0.83      0.53      0.65        19\n",
      "\n",
      "    accuracy                           0.96       264\n",
      "   macro avg       0.90      0.76      0.81       264\n",
      "weighted avg       0.95      0.96      0.95       264\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       245\n",
      "           1       0.62      0.84      0.71        19\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.80      0.90      0.84       264\n",
      "weighted avg       0.96      0.95      0.95       264\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       245\n",
      "           1       0.61      0.89      0.72        19\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.80      0.92      0.85       264\n",
      "weighted avg       0.96      0.95      0.96       264\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       245\n",
      "           1       0.64      0.84      0.73        19\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.81      0.90      0.85       264\n",
      "weighted avg       0.96      0.95      0.96       264\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       245\n",
      "           1       0.59      0.89      0.71        19\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.79      0.92      0.84       264\n",
      "weighted avg       0.96      0.95      0.95       264\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       245\n",
      "           1       0.55      0.84      0.67        19\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.77      0.89      0.82       264\n",
      "weighted avg       0.96      0.94      0.95       264\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       245\n",
      "           1       0.58      0.74      0.65        19\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.78      0.85      0.81       264\n",
      "weighted avg       0.95      0.94      0.95       264\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       245\n",
      "           1       0.62      0.84      0.71        19\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.80      0.90      0.84       264\n",
      "weighted avg       0.96      0.95      0.95       264\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       245\n",
      "           1       0.55      0.84      0.67        19\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.77      0.89      0.82       264\n",
      "weighted avg       0.96      0.94      0.95       264\n",
      "\n",
      "analcatdata_japansolvent (43/74)\n",
      "(52, 9) with ratio : 1.0800\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.83      0.89      0.86        27\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.85      0.84      0.85        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78        25\n",
      "           1       0.77      0.89      0.83        27\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.82      0.80      0.81        52\n",
      "weighted avg       0.81      0.81      0.81        52\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.56      0.67        25\n",
      "           1       0.69      0.89      0.77        27\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.75      0.72      0.72        52\n",
      "weighted avg       0.75      0.73      0.72        52\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.64      0.73        25\n",
      "           1       0.73      0.89      0.80        27\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.78      0.76      0.76        52\n",
      "weighted avg       0.78      0.77      0.77        52\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70        25\n",
      "           1       0.71      0.89      0.79        27\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.77      0.74      0.74        52\n",
      "weighted avg       0.77      0.75      0.74        52\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78        25\n",
      "           1       0.77      0.89      0.83        27\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.82      0.80      0.81        52\n",
      "weighted avg       0.81      0.81      0.81        52\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81        25\n",
      "           1       0.77      1.00      0.87        27\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.89      0.84      0.84        52\n",
      "weighted avg       0.88      0.85      0.84        52\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81        25\n",
      "           1       0.80      0.89      0.84        27\n",
      "\n",
      "    accuracy                           0.83        52\n",
      "   macro avg       0.83      0.82      0.83        52\n",
      "weighted avg       0.83      0.83      0.83        52\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.83      0.89      0.86        27\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.85      0.84      0.85        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n",
      "analcatdata_fraud (44/74)\n",
      "(42, 11) with ratio : 2.2308\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        29\n",
      "           1       0.54      0.54      0.54        13\n",
      "\n",
      "    accuracy                           0.71        42\n",
      "   macro avg       0.67      0.67      0.67        42\n",
      "weighted avg       0.71      0.71      0.71        42\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77        29\n",
      "           1       0.33      0.15      0.21        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.51      0.51      0.49        42\n",
      "weighted avg       0.58      0.64      0.60        42\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.66      0.75        29\n",
      "           1       0.50      0.77      0.61        13\n",
      "\n",
      "    accuracy                           0.69        42\n",
      "   macro avg       0.68      0.71      0.68        42\n",
      "weighted avg       0.75      0.69      0.70        42\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        29\n",
      "           1       0.50      0.62      0.55        13\n",
      "\n",
      "    accuracy                           0.69        42\n",
      "   macro avg       0.65      0.67      0.66        42\n",
      "weighted avg       0.71      0.69      0.70        42\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79        29\n",
      "           1       0.40      0.15      0.22        13\n",
      "\n",
      "    accuracy                           0.67        42\n",
      "   macro avg       0.55      0.53      0.51        42\n",
      "weighted avg       0.61      0.67      0.61        42\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77        29\n",
      "           1       0.33      0.15      0.21        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.51      0.51      0.49        42\n",
      "weighted avg       0.58      0.64      0.60        42\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.70        29\n",
      "           1       0.41      0.54      0.47        13\n",
      "\n",
      "    accuracy                           0.62        42\n",
      "   macro avg       0.59      0.60      0.59        42\n",
      "weighted avg       0.65      0.62      0.63        42\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        29\n",
      "           1       0.50      0.62      0.55        13\n",
      "\n",
      "    accuracy                           0.69        42\n",
      "   macro avg       0.65      0.67      0.66        42\n",
      "weighted avg       0.71      0.69      0.70        42\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76        29\n",
      "           1       0.20      0.08      0.11        13\n",
      "\n",
      "    accuracy                           0.62        42\n",
      "   macro avg       0.44      0.47      0.43        42\n",
      "weighted avg       0.53      0.62      0.56        42\n",
      "\n",
      "analcatdata_cyyoung9302 (45/74)\n",
      "(92, 10) with ratio : 3.8421\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        73\n",
      "           1       0.83      0.53      0.65        19\n",
      "\n",
      "    accuracy                           0.88        92\n",
      "   macro avg       0.86      0.75      0.79        92\n",
      "weighted avg       0.88      0.88      0.87        92\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89        73\n",
      "           1       0.56      0.95      0.71        19\n",
      "\n",
      "    accuracy                           0.84        92\n",
      "   macro avg       0.77      0.88      0.80        92\n",
      "weighted avg       0.90      0.84      0.85        92\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91        73\n",
      "           1       0.63      0.89      0.74        19\n",
      "\n",
      "    accuracy                           0.87        92\n",
      "   macro avg       0.80      0.88      0.83        92\n",
      "weighted avg       0.90      0.87      0.88        92\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        73\n",
      "           1       0.58      0.79      0.67        19\n",
      "\n",
      "    accuracy                           0.84        92\n",
      "   macro avg       0.76      0.82      0.78        92\n",
      "weighted avg       0.86      0.84      0.85        92\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87        73\n",
      "           1       0.53      0.95      0.68        19\n",
      "\n",
      "    accuracy                           0.82        92\n",
      "   macro avg       0.76      0.86      0.77        92\n",
      "weighted avg       0.89      0.82      0.83        92\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        73\n",
      "           1       0.50      0.63      0.56        19\n",
      "\n",
      "    accuracy                           0.79        92\n",
      "   macro avg       0.70      0.73      0.71        92\n",
      "weighted avg       0.82      0.79      0.80        92\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83        73\n",
      "           1       0.43      0.63      0.51        19\n",
      "\n",
      "    accuracy                           0.75        92\n",
      "   macro avg       0.66      0.71      0.67        92\n",
      "weighted avg       0.80      0.75      0.77        92\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        73\n",
      "           1       0.65      0.58      0.61        19\n",
      "\n",
      "    accuracy                           0.85        92\n",
      "   macro avg       0.77      0.75      0.76        92\n",
      "weighted avg       0.84      0.85      0.84        92\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90        73\n",
      "           1       0.59      0.68      0.63        19\n",
      "\n",
      "    accuracy                           0.84        92\n",
      "   macro avg       0.75      0.78      0.76        92\n",
      "weighted avg       0.85      0.84      0.84        92\n",
      "\n",
      "analcatdata_cyyoung8092 (46/74)\n",
      "(97, 10) with ratio : 3.0417\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        73\n",
      "           1       0.76      0.67      0.71        24\n",
      "\n",
      "    accuracy                           0.87        97\n",
      "   macro avg       0.83      0.80      0.81        97\n",
      "weighted avg       0.86      0.87      0.86        97\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77        73\n",
      "           1       0.42      0.71      0.53        24\n",
      "\n",
      "    accuracy                           0.69        97\n",
      "   macro avg       0.65      0.70      0.65        97\n",
      "weighted avg       0.77      0.69      0.71        97\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        73\n",
      "           1       0.63      0.71      0.67        24\n",
      "\n",
      "    accuracy                           0.82        97\n",
      "   macro avg       0.76      0.79      0.77        97\n",
      "weighted avg       0.83      0.82      0.83        97\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        73\n",
      "           1       0.56      0.62      0.59        24\n",
      "\n",
      "    accuracy                           0.78        97\n",
      "   macro avg       0.71      0.73      0.72        97\n",
      "weighted avg       0.79      0.78      0.79        97\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.71      0.81        73\n",
      "           1       0.49      0.83      0.62        24\n",
      "\n",
      "    accuracy                           0.74        97\n",
      "   macro avg       0.71      0.77      0.71        97\n",
      "weighted avg       0.82      0.74      0.76        97\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88        73\n",
      "           1       0.62      0.67      0.64        24\n",
      "\n",
      "    accuracy                           0.81        97\n",
      "   macro avg       0.75      0.76      0.76        97\n",
      "weighted avg       0.82      0.81      0.82        97\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        73\n",
      "           1       0.46      0.46      0.46        24\n",
      "\n",
      "    accuracy                           0.73        97\n",
      "   macro avg       0.64      0.64      0.64        97\n",
      "weighted avg       0.73      0.73      0.73        97\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89        73\n",
      "           1       0.65      0.71      0.68        24\n",
      "\n",
      "    accuracy                           0.84        97\n",
      "   macro avg       0.78      0.79      0.78        97\n",
      "weighted avg       0.84      0.84      0.84        97\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87        73\n",
      "           1       0.60      0.75      0.67        24\n",
      "\n",
      "    accuracy                           0.81        97\n",
      "   macro avg       0.76      0.79      0.77        97\n",
      "weighted avg       0.83      0.81      0.82        97\n",
      "\n",
      "analcatdata_creditscore (47/74)\n",
      "(100, 6) with ratio : 2.7037\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64        27\n",
      "           1       0.85      0.93      0.89        73\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.80      0.74      0.76       100\n",
      "weighted avg       0.82      0.83      0.82       100\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        27\n",
      "           1       0.88      0.88      0.88        73\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.77      0.77      0.77       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57        27\n",
      "           1       0.83      0.89      0.86        73\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.73      0.70      0.72       100\n",
      "weighted avg       0.78      0.79      0.78       100\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60        27\n",
      "           1       0.85      0.86      0.86        73\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.73      0.73      0.73       100\n",
      "weighted avg       0.79      0.79      0.79       100\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        27\n",
      "           1       0.84      0.88      0.86        73\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.73      0.72      0.72       100\n",
      "weighted avg       0.78      0.79      0.79       100\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        27\n",
      "           1       0.85      0.85      0.85        73\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.72      0.72      0.72       100\n",
      "weighted avg       0.78      0.78      0.78       100\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60        27\n",
      "           1       0.85      0.86      0.86        73\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.73      0.73      0.73       100\n",
      "weighted avg       0.79      0.79      0.79       100\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.62        27\n",
      "           1       0.85      0.92      0.88        73\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.78      0.74      0.75       100\n",
      "weighted avg       0.81      0.82      0.81       100\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        27\n",
      "           1       0.84      0.85      0.84        73\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.71      0.70      0.70       100\n",
      "weighted avg       0.77      0.77      0.77       100\n",
      "\n",
      "analcatdata_boxing2 (48/74)\n",
      "(132, 3) with ratio : 1.1639\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        61\n",
      "           1       0.65      0.70      0.68        71\n",
      "\n",
      "    accuracy                           0.64       132\n",
      "   macro avg       0.63      0.63      0.63       132\n",
      "weighted avg       0.63      0.64      0.63       132\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57        61\n",
      "           1       0.64      0.66      0.65        71\n",
      "\n",
      "    accuracy                           0.61       132\n",
      "   macro avg       0.61      0.61      0.61       132\n",
      "weighted avg       0.61      0.61      0.61       132\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61        61\n",
      "           1       0.67      0.75      0.71        71\n",
      "\n",
      "    accuracy                           0.67       132\n",
      "   macro avg       0.67      0.66      0.66       132\n",
      "weighted avg       0.67      0.67      0.66       132\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.54      0.61        61\n",
      "           1       0.67      0.79      0.72        71\n",
      "\n",
      "    accuracy                           0.67       132\n",
      "   macro avg       0.68      0.66      0.66       132\n",
      "weighted avg       0.68      0.67      0.67       132\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        61\n",
      "           1       0.66      0.73      0.69        71\n",
      "\n",
      "    accuracy                           0.65       132\n",
      "   macro avg       0.65      0.64      0.64       132\n",
      "weighted avg       0.65      0.65      0.65       132\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        61\n",
      "           1       0.64      0.69      0.66        71\n",
      "\n",
      "    accuracy                           0.62       132\n",
      "   macro avg       0.62      0.62      0.62       132\n",
      "weighted avg       0.62      0.62      0.62       132\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        61\n",
      "           1       0.65      0.70      0.68        71\n",
      "\n",
      "    accuracy                           0.64       132\n",
      "   macro avg       0.63      0.63      0.63       132\n",
      "weighted avg       0.63      0.64      0.63       132\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59        61\n",
      "           1       0.65      0.72      0.68        71\n",
      "\n",
      "    accuracy                           0.64       132\n",
      "   macro avg       0.64      0.64      0.64       132\n",
      "weighted avg       0.64      0.64      0.64       132\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        61\n",
      "           1       0.65      0.70      0.68        71\n",
      "\n",
      "    accuracy                           0.64       132\n",
      "   macro avg       0.63      0.63      0.63       132\n",
      "weighted avg       0.63      0.64      0.63       132\n",
      "\n",
      "analcatdata_boxing1 (49/74)\n",
      "(120, 3) with ratio : 1.8571\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.33      0.44        42\n",
      "           1       0.71      0.90      0.80        78\n",
      "\n",
      "    accuracy                           0.70       120\n",
      "   macro avg       0.68      0.62      0.62       120\n",
      "weighted avg       0.69      0.70      0.67       120\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.43      0.44        42\n",
      "           1       0.70      0.72      0.71        78\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.57      0.57      0.57       120\n",
      "weighted avg       0.61      0.62      0.61       120\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        42\n",
      "           1       0.73      0.73      0.73        78\n",
      "\n",
      "    accuracy                           0.65       120\n",
      "   macro avg       0.62      0.62      0.62       120\n",
      "weighted avg       0.65      0.65      0.65       120\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53        42\n",
      "           1       0.75      0.79      0.77        78\n",
      "\n",
      "    accuracy                           0.69       120\n",
      "   macro avg       0.66      0.65      0.65       120\n",
      "weighted avg       0.68      0.69      0.69       120\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.51        42\n",
      "           1       0.74      0.79      0.77        78\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.65      0.64      0.64       120\n",
      "weighted avg       0.67      0.68      0.68       120\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.45      0.50        42\n",
      "           1       0.73      0.81      0.77        78\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.65      0.63      0.63       120\n",
      "weighted avg       0.67      0.68      0.67       120\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.51        42\n",
      "           1       0.74      0.79      0.77        78\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.65      0.64      0.64       120\n",
      "weighted avg       0.67      0.68      0.68       120\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.51        42\n",
      "           1       0.74      0.79      0.77        78\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.65      0.64      0.64       120\n",
      "weighted avg       0.67      0.68      0.68       120\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        42\n",
      "           1       0.75      0.82      0.79        78\n",
      "\n",
      "    accuracy                           0.71       120\n",
      "   macro avg       0.68      0.66      0.67       120\n",
      "weighted avg       0.70      0.71      0.70       120\n",
      "\n",
      "analcatdata_bankruptcy (50/74)\n",
      "(50, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        25\n",
      "           1       0.95      0.80      0.87        25\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.89      0.88      0.88        50\n",
      "weighted avg       0.89      0.88      0.88        50\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        25\n",
      "           1       1.00      0.76      0.86        25\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.90      0.88      0.88        50\n",
      "weighted avg       0.90      0.88      0.88        50\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        25\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.92      0.90      0.90        50\n",
      "weighted avg       0.92      0.90      0.90        50\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        25\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        25\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.92      0.90      0.90        50\n",
      "weighted avg       0.92      0.90      0.90        50\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        25\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80        25\n",
      "           1       0.85      0.68      0.76        25\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.79      0.78      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        25\n",
      "           1       0.86      0.76      0.81        25\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.82      0.82      0.82        50\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        25\n",
      "           1       0.91      0.84      0.88        25\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "analcatdata_asbestos (51/74)\n",
      "(83, 3) with ratio : 1.2432\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        46\n",
      "           1       0.78      0.84      0.81        37\n",
      "\n",
      "    accuracy                           0.82        83\n",
      "   macro avg       0.82      0.82      0.82        83\n",
      "weighted avg       0.82      0.82      0.82        83\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        46\n",
      "           1       0.86      0.81      0.83        37\n",
      "\n",
      "    accuracy                           0.86        83\n",
      "   macro avg       0.86      0.85      0.85        83\n",
      "weighted avg       0.86      0.86      0.85        83\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        46\n",
      "           1       0.86      0.81      0.83        37\n",
      "\n",
      "    accuracy                           0.86        83\n",
      "   macro avg       0.86      0.85      0.85        83\n",
      "weighted avg       0.86      0.86      0.85        83\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        46\n",
      "           1       0.86      0.81      0.83        37\n",
      "\n",
      "    accuracy                           0.86        83\n",
      "   macro avg       0.86      0.85      0.85        83\n",
      "weighted avg       0.86      0.86      0.85        83\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        46\n",
      "           1       0.86      0.81      0.83        37\n",
      "\n",
      "    accuracy                           0.86        83\n",
      "   macro avg       0.86      0.85      0.85        83\n",
      "weighted avg       0.86      0.86      0.85        83\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        46\n",
      "           1       0.83      0.81      0.82        37\n",
      "\n",
      "    accuracy                           0.84        83\n",
      "   macro avg       0.84      0.84      0.84        83\n",
      "weighted avg       0.84      0.84      0.84        83\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        46\n",
      "           1       0.78      0.76      0.77        37\n",
      "\n",
      "    accuracy                           0.80        83\n",
      "   macro avg       0.79      0.79      0.79        83\n",
      "weighted avg       0.79      0.80      0.79        83\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        46\n",
      "           1       0.79      0.73      0.76        37\n",
      "\n",
      "    accuracy                           0.80        83\n",
      "   macro avg       0.80      0.79      0.79        83\n",
      "weighted avg       0.80      0.80      0.79        83\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        46\n",
      "           1       0.83      0.81      0.82        37\n",
      "\n",
      "    accuracy                           0.84        83\n",
      "   macro avg       0.84      0.84      0.84        83\n",
      "weighted avg       0.84      0.84      0.84        83\n",
      "\n",
      "analcatdata_aids (52/74)\n",
      "(50, 4) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70        25\n",
      "           1       0.73      0.44      0.55        25\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.67      0.64      0.62        50\n",
      "weighted avg       0.67      0.64      0.62        50\n",
      "\n",
      "LPSVS_No_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.36      0.38        25\n",
      "           1       0.41      0.44      0.42        25\n",
      "\n",
      "    accuracy                           0.40        50\n",
      "   macro avg       0.40      0.40      0.40        50\n",
      "weighted avg       0.40      0.40      0.40        50\n",
      "\n",
      "LPSVS_No_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.40      0.39        25\n",
      "           1       0.38      0.36      0.37        25\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.38      0.38      0.38        50\n",
      "weighted avg       0.38      0.38      0.38        50\n",
      "\n",
      "LPSVS_No_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.36      0.38        25\n",
      "           1       0.41      0.44      0.42        25\n",
      "\n",
      "    accuracy                           0.40        50\n",
      "   macro avg       0.40      0.40      0.40        50\n",
      "weighted avg       0.40      0.40      0.40        50\n",
      "\n",
      "LPSVS_No_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.32      0.34        25\n",
      "           1       0.39      0.44      0.42        25\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.38      0.38      0.38        50\n",
      "weighted avg       0.38      0.38      0.38        50\n",
      "\n",
      "LPSVS_100_11_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        25\n",
      "           1       0.40      0.32      0.36        25\n",
      "\n",
      "    accuracy                           0.42        50\n",
      "   macro avg       0.42      0.42      0.41        50\n",
      "weighted avg       0.42      0.42      0.41        50\n",
      "\n",
      "LPSVS_100_5_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37        25\n",
      "           1       0.38      0.40      0.39        25\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.38      0.38      0.38        50\n",
      "weighted avg       0.38      0.38      0.38        50\n",
      "\n",
      "LPSVS_100_5_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.42        25\n",
      "           1       0.36      0.32      0.34        25\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.38      0.38      0.38        50\n",
      "weighted avg       0.38      0.38      0.38        50\n",
      "\n",
      "LPSVS_100_11_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.44      0.43        25\n",
      "           1       0.42      0.40      0.41        25\n",
      "\n",
      "    accuracy                           0.42        50\n",
      "   macro avg       0.42      0.42      0.42        50\n",
      "weighted avg       0.42      0.42      0.42        50\n",
      "\n",
      "_deprecated_wdbc (53/74)\n",
      "Skipping _deprecated_wdbc as deprecated from PMLB...\n",
      "_deprecated_vote (54/74)\n",
      "Skipping _deprecated_vote as deprecated from PMLB...\n",
      "_deprecated_pima (55/74)\n",
      "Skipping _deprecated_pima as deprecated from PMLB...\n",
      "_deprecated_hungarian (56/74)\n",
      "Skipping _deprecated_hungarian as deprecated from PMLB...\n",
      "_deprecated_house_votes_84 (57/74)\n",
      "Skipping _deprecated_house_votes_84 as deprecated from PMLB...\n",
      "_deprecated_horse_colic (58/74)\n",
      "Skipping _deprecated_horse_colic as deprecated from PMLB...\n",
      "_deprecated_heart_statlog (59/74)\n",
      "Skipping _deprecated_heart_statlog as deprecated from PMLB...\n",
      "_deprecated_heart_h (60/74)\n",
      "Skipping _deprecated_heart_h as deprecated from PMLB...\n",
      "_deprecated_heart_c (61/74)\n",
      "Skipping _deprecated_heart_c as deprecated from PMLB...\n",
      "_deprecated_german (62/74)\n",
      "Skipping _deprecated_german as deprecated from PMLB...\n",
      "_deprecated_diabetes (63/74)\n",
      "Skipping _deprecated_diabetes as deprecated from PMLB...\n",
      "_deprecated_crx (64/74)\n",
      "Skipping _deprecated_crx as deprecated from PMLB...\n",
      "_deprecated_credit_g (65/74)\n",
      "Skipping _deprecated_credit_g as deprecated from PMLB...\n",
      "_deprecated_credit_a (66/74)\n",
      "Skipping _deprecated_credit_a as deprecated from PMLB...\n",
      "_deprecated_colic (67/74)\n",
      "Skipping _deprecated_colic as deprecated from PMLB...\n",
      "_deprecated_cleve (68/74)\n",
      "Skipping _deprecated_cleve as deprecated from PMLB...\n",
      "_deprecated_buggyCrx (69/74)\n",
      "Skipping _deprecated_buggyCrx as deprecated from PMLB...\n",
      "_deprecated_breast_w (70/74)\n",
      "Skipping _deprecated_breast_w as deprecated from PMLB...\n",
      "_deprecated_breast_cancer_wisconsin (71/74)\n",
      "Skipping _deprecated_breast_cancer_wisconsin as deprecated from PMLB...\n",
      "_deprecated_breast (72/74)\n",
      "Skipping _deprecated_breast as deprecated from PMLB...\n",
      "_deprecated_australian (73/74)\n",
      "Skipping _deprecated_australian as deprecated from PMLB...\n",
      "            model      rank\n",
      "8    LPSVS_No_5_5  3.761905\n",
      "6   LPSVS_No_11_5  4.142857\n",
      "7    LPSVS_No_5_1  4.357143\n",
      "5   LPSVS_No_11_1  4.642857\n",
      "2  LPSVS_100_11_5  5.166667\n",
      "4   LPSVS_100_5_5  5.380952\n",
      "0        Baseline  5.642857\n",
      "1  LPSVS_100_11_1  5.738095\n",
      "3   LPSVS_100_5_1  6.166667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1693461/1944496001.py:119: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "from sklearn.base import clone\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "    # & (dataset_df[\"n_features\"] >= 10)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"][:]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "models = {\n",
    "    \"Baseline\": {},\n",
    "    # \"LTSVS_random\": {\"sampling_strategy\":\"random\"},\n",
    "    \"LPSVS_No_11_1\": {'project':-1, \"num_neigh\":11, \"num_sets_per_sample\":1},\n",
    "    \"LPSVS_No_5_1\": {'project':-1, \"num_neigh\":5, \"num_sets_per_sample\":1},\n",
    "    \"LPSVS_No_5_5\": {'project':-1, \"num_neigh\":5, \"num_sets_per_sample\":5},\n",
    "    \"LPSVS_No_11_5\": {'project':-1, \"num_neigh\":11, \"num_sets_per_sample\":5},\n",
    "    \"LPSVS_100_11_1\": {'project':100, \"num_neigh\":11, \"num_sets_per_sample\":1},\n",
    "    \"LPSVS_100_5_1\": {'project':100, \"num_neigh\":5, \"num_sets_per_sample\":1},\n",
    "    \"LPSVS_100_5_5\": {'project':100, \"num_neigh\":5, \"num_sets_per_sample\":5},\n",
    "    \"LPSVS_100_11_5\": {'project':100, \"num_neigh\":11, \"num_sets_per_sample\":5},\n",
    "    # \"LTSVS_random2\": {\"sampling_strategy\":\"random\", \"S\":100},\n",
    "    # \"LTSVS_random2\": {\"sampling_strategy\":\"random\", \"S\":100},\n",
    "    #\"LTSVS_distance\": {\"sampling_strategy\":\"distance\"},\n",
    "    #\"Imp_LTSVS\": {},\n",
    "    # \"CRH_pc80\":{\"top_k_to_keep\":0.8},\n",
    "    # \"CRH_pc90\":{\"top_k_to_keep\":0.9},\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "base_class = Pipeline([\n",
    "    ('st', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=42))\n",
    "    ])   #RandomForestClassifier(random_state=42)#DecisionTreeClassifier(max_depth=None, random_state=42)#\n",
    "\n",
    "res = [] \n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    if 'deprecated' in classification_dataset:\n",
    "        print(f\"Skipping {classification_dataset} as deprecated from PMLB...\")\n",
    "        continue\n",
    "    try:\n",
    "        X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    except ValueError as e:\n",
    "        print(f'Probably not found dataset {classification_dataset} in PMLB and skipping...\\n {e}')\n",
    "        continue\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "\n",
    "    for model_name, model_kwargs in models.items():\n",
    "        y_pred = np.empty_like(y)\n",
    "        sample_weights = None\n",
    "        time_s = time.time()\n",
    "        for train_indices, test_indices in cv.split(X,y):\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            X_test, y_test = X[test_indices], y[test_indices]\n",
    "            \n",
    "            X_train_filtered = X_train.copy()\n",
    "            y_train_filtered = y_train.copy()\n",
    "            if model_name.startswith(\"LPSVS\"):\n",
    "                clf = LPSVS(**model_kwargs)\n",
    "            else:\n",
    "                clf = clone(base_class)\n",
    "            #print(model_name, X_train_filtered.shape[0])\n",
    "            clf.fit(X_train_filtered , y_train_filtered)\n",
    "            y_pred_cur = clf.predict(X_test)\n",
    "\n",
    "            y_pred[test_indices] = y_pred_cur\n",
    "            #print(f'TRUE', y_test)\n",
    "            \n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.070458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LPSVS_No_5_1</td>\n",
       "      <td>0.577975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LPSVS_No_11_1</td>\n",
       "      <td>0.628548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LPSVS_100_5_1</td>\n",
       "      <td>0.728710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LPSVS_100_11_1</td>\n",
       "      <td>0.750811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LPSVS_No_5_5</td>\n",
       "      <td>2.735923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LPSVS_100_5_5</td>\n",
       "      <td>2.878917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LPSVS_100_11_5</td>\n",
       "      <td>2.985577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LPSVS_No_11_5</td>\n",
       "      <td>3.012182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model      time\n",
       "0        Baseline  0.070458\n",
       "7    LPSVS_No_5_1  0.577975\n",
       "5   LPSVS_No_11_1  0.628548\n",
       "3   LPSVS_100_5_1  0.728710\n",
       "1  LPSVS_100_11_1  0.750811\n",
       "8    LPSVS_No_5_5  2.735923\n",
       "4   LPSVS_100_5_5  2.878917\n",
       "2  LPSVS_100_11_5  2.985577\n",
       "6   LPSVS_No_11_5  3.012182"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.groupby('model')['time'].mean().reset_index().sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_class_imb</th>\n",
       "      <th>model</th>\n",
       "      <th>time</th>\n",
       "      <th>acc</th>\n",
       "      <th>pr</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analcatdata_aids</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_aids</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LPSVS_No_11_1</td>\n",
       "      <td>0.170789</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_aids</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LPSVS_No_5_5</td>\n",
       "      <td>0.629542</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analcatdata_aids</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LPSVS_No_11_5</td>\n",
       "      <td>0.656605</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analcatdata_aids</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LPSVS_100_11_5</td>\n",
       "      <td>0.697906</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>xd6</td>\n",
       "      <td>2.021739</td>\n",
       "      <td>LPSVS_100_5_1</td>\n",
       "      <td>1.492519</td>\n",
       "      <td>0.979445</td>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.959627</td>\n",
       "      <td>0.968652</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>xd6</td>\n",
       "      <td>2.021739</td>\n",
       "      <td>LPSVS_100_5_5</td>\n",
       "      <td>6.675687</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.980831</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>xd6</td>\n",
       "      <td>2.021739</td>\n",
       "      <td>LPSVS_No_5_5</td>\n",
       "      <td>6.762811</td>\n",
       "      <td>0.973279</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.958991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>xd6</td>\n",
       "      <td>2.021739</td>\n",
       "      <td>LPSVS_No_5_1</td>\n",
       "      <td>1.477298</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.944272</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>xd6</td>\n",
       "      <td>2.021739</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.040365</td>\n",
       "      <td>0.813977</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.681898</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset  dataset_class_imb  ...        f1  rank\n",
       "0    analcatdata_aids           1.000000  ...  0.550000     1\n",
       "1    analcatdata_aids           1.000000  ...  0.423077     2\n",
       "2    analcatdata_aids           1.000000  ...  0.423077     3\n",
       "3    analcatdata_aids           1.000000  ...  0.415094     4\n",
       "4    analcatdata_aids           1.000000  ...  0.408163     5\n",
       "..                ...                ...  ...       ...   ...\n",
       "373               xd6           2.021739  ...  0.968652     5\n",
       "374               xd6           2.021739  ...  0.966929     6\n",
       "375               xd6           2.021739  ...  0.958991     7\n",
       "376               xd6           2.021739  ...  0.945736     8\n",
       "377               xd6           2.021739  ...  0.681898     9\n",
       "\n",
       "[378 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "                LPSVS_No_5_5  LPSVS_No_11_5  ...  LPSVS_100_11_1  LPSVS_100_5_1\n",
      "LPSVS_No_5_5             0.0           24.0  ...            28.0           30.0\n",
      "LPSVS_No_11_5           16.0            0.0  ...            29.0           30.0\n",
      "LPSVS_No_5_1            14.0           21.0  ...            27.0           26.0\n",
      "LPSVS_No_11_1           17.0           16.0  ...            24.0           28.0\n",
      "LPSVS_100_11_5          14.0           10.0  ...            26.0           28.0\n",
      "LPSVS_100_5_5           13.0           17.0  ...            25.0           24.0\n",
      "Baseline                13.0           12.0  ...            19.0           20.0\n",
      "LPSVS_100_11_1          13.0           13.0  ...             0.0           25.0\n",
      "LPSVS_100_5_1           11.0           10.0  ...            17.0            0.0\n",
      "\n",
      "[9 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "model_names = res['model'].unique()\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "metric_to_score = 'f1'\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[metric_to_score]\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1][metric_to_score] > cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][metric_to_score] < cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "# Uncomment this for percentage wins\n",
    "# wins_score /= res['dataset'].unique().shape[0]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = model_names[order_of_models], index=model_names[order_of_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>LPSVS_No_5_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPSVS_No_5_5</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_No_11_5</th>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_No_5_1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_No_11_1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_100_11_5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_100_5_5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_100_11_1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPSVS_100_5_1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Baseline  LPSVS_No_5_5\n",
       "LPSVS_No_5_5        29.0           0.0\n",
       "LPSVS_No_11_5       28.0          16.0\n",
       "LPSVS_No_5_1        27.0          14.0\n",
       "LPSVS_No_11_1       26.0          17.0\n",
       "LPSVS_100_11_5      21.0          14.0\n",
       "LPSVS_100_5_5       21.0          13.0\n",
       "Baseline             0.0          13.0\n",
       "LPSVS_100_11_1      23.0          13.0\n",
       "LPSVS_100_5_1       20.0          11.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(wins_score, columns = model_names[order_of_models], index=model_names[order_of_models])[['Baseline', 'LPSVS_No_5_5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LPSVS_No_5_5', 'LPSVS_No_11_5', 'LPSVS_No_5_1', 'LPSVS_No_11_1',\n",
       "       'LPSVS_100_11_5', 'LPSVS_100_5_5', 'Baseline', 'LPSVS_100_11_1',\n",
       "       'LPSVS_100_5_1'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names[order_of_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            model      rank\n",
      "0    LPSVS_No_5_5  3.761905\n",
      "1   LPSVS_No_11_5  4.142857\n",
      "2    LPSVS_No_5_1  4.357143\n",
      "3   LPSVS_No_11_1  4.642857\n",
      "4  LPSVS_100_11_5  5.166667\n",
      "5   LPSVS_100_5_5  5.380952\n",
      "6        Baseline  5.642857\n",
      "7  LPSVS_100_11_1  5.738095\n",
      "8   LPSVS_100_5_1  6.166667\n"
     ]
    }
   ],
   "source": [
    "print(mean_ranks.reset_index(drop=True).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance over number of samples and imbalance ratio for baseline vs best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **No clear trend** when plotting against imbalance, number of samples or number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200728/2580015051.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_200728/2580015051.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "model=Baseline<br>dataset_class_imb=%{x}<br>f1=%{y}<extra></extra>",
         "legendgroup": "Baseline",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Baseline",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          2.0217391304347827,
          1.6839622641509433,
          1.5892857142857142,
          1.0016229375169057,
          1.7716763005780347,
          2.0822320117474304,
          1.8855421686746987,
          1.1512605042016806,
          2.6736842105263157,
          3.8545454545454545,
          1.5377826806398236,
          1.1443298969072164,
          1.8875,
          1.019650655021834,
          2,
          1,
          1,
          2.6666666666666665,
          1.8656716417910448,
          2.407313997477932,
          1.0179533213644525,
          1,
          1,
          1.0745658835546477,
          1.0827067669172932,
          1.9174757281553398,
          1,
          1,
          3.5342465753424657,
          1.8438995215311005,
          1.4857142857142858,
          1.85,
          1.0929927963326784,
          1.2522522522522523,
          1.7857142857142858,
          19.94701986754967,
          1.7735849056603774,
          1.5892857142857142,
          1.7058823529411764,
          3.84375,
          1.25,
          1.7735849056603774,
          1.1956521739130435,
          2.7777777777777777,
          1.144736842105263,
          2.3333333333333335,
          4.857142857142857,
          64.03448275862068,
          1.8656716417910448,
          1.247557003257329,
          2.3333333333333335,
          1.247557003257329,
          1.2857142857142858,
          1.7058823529411764,
          15.761092150170649,
          1.1956521739130435,
          6.072135785007072,
          1.0929927963326784,
          1.0414201183431953,
          1.247557003257329,
          1.900414937759336,
          1.6839622641509433,
          2.364705882352941,
          1.900414937759336,
          1.7866666666666666,
          1.2306397306397305,
          6.2,
          1.247557003257329,
          4.0476190476190474,
          12.894736842105264,
          1.08,
          2.230769230769231,
          3.8421052631578947,
          3.0416666666666665,
          2.7037037037037037,
          1.1639344262295082,
          1.8571428571428572,
          1,
          1.2432432432432432,
          1,
          1.0793974980852694,
          3.179173440574998,
          1.02,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          1,
          0.9383886255924171,
          0.9411764705882353,
          0.9699850604373217,
          0.942323314378554,
          0.6104746317512275,
          0.9681429681429682,
          0.9896049896049897,
          0.937984496124031,
          0.8873563218390804,
          0.9406827084499161,
          0.8111111111111111,
          0.4727272727272727,
          0.9475712123297096,
          0.35398230088495575,
          0.8353413654618473,
          0.9393939393939394,
          0.058823529411764705,
          0.6201232032854209,
          0.8453674121405751,
          0.5247079964061097,
          0,
          0.9354838709677419,
          1,
          0.9738219895287958,
          0.8947368421052632,
          0.9817518248175182,
          0.8846153846153846,
          0.9980657640232108,
          0.8182977366911062,
          0.5882352941176471,
          0.9295774647887324,
          0.9919330743949806,
          1,
          0.949671772428884,
          0.9900891972249752,
          0.7035175879396985,
          0.9501466275659824,
          0.7607843137254902,
          0.9140625,
          0.7725321888412017,
          0.8393782383419689,
          0.847953216374269,
          0.3188405797101449,
          0.8648648648648649,
          0.8384970336189849,
          0.32974910394265233,
          0.992776886035313,
          0.625,
          0.8617886178861789,
          0.8377850162866449,
          0.8813559322033898,
          0.9928057553956835,
          0.8846960167714885,
          0.08516129032258064,
          0.7794117647058824,
          0.8295003965107058,
          0.992822966507177,
          0.5511363636363636,
          0.8926701570680629,
          0.9527720739219713,
          0.9383886255924171,
          0.4583333333333333,
          0.9488752556237219,
          0.9458483754512635,
          0.8761742100768574,
          0,
          0.8491803278688524,
          0.631578947368421,
          0.8947368421052632,
          0.8727272727272727,
          0.2857142857142857,
          0.6060606060606061,
          0.4,
          0.993103448275862,
          0.6933333333333334,
          0.8242424242424242,
          0.7924528301886793,
          0.7605633802816901,
          0.5106382978723404,
          1,
          0.9086867889787598,
          0.6232114467408585,
          0.5704971475142624,
          0.6481012658227848,
          0.6288659793814433,
          0.5399239543726235,
          0.6670926517571885,
          0.5708687132593077
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "model=CRH_pc99<br>dataset_class_imb=%{x}<br>f1=%{y}<extra></extra>",
         "legendgroup": "CRH_pc99",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "CRH_pc99",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          2.0217391304347827,
          1.6839622641509433,
          1.5892857142857142,
          1.0016229375169057,
          1.7716763005780347,
          2.0822320117474304,
          1.8855421686746987,
          1.1512605042016806,
          2.6736842105263157,
          3.8545454545454545,
          1.5377826806398236,
          1.1443298969072164,
          1.8875,
          1.019650655021834,
          2,
          1,
          1,
          2.6666666666666665,
          1.8656716417910448,
          2.407313997477932,
          1.0179533213644525,
          1,
          1,
          1.0745658835546477,
          1.0827067669172932,
          1.9174757281553398,
          1,
          1,
          3.5342465753424657,
          1.8438995215311005,
          1.4857142857142858,
          1.85,
          1.0929927963326784,
          1.2522522522522523,
          1.7857142857142858,
          19.94701986754967,
          1.7735849056603774,
          1.5892857142857142,
          1.7058823529411764,
          3.84375,
          1.25,
          1.7735849056603774,
          1.1956521739130435,
          2.7777777777777777,
          1.144736842105263,
          2.3333333333333335,
          4.857142857142857,
          64.03448275862068,
          1.8656716417910448,
          1.247557003257329,
          2.3333333333333335,
          1.247557003257329,
          1.2857142857142858,
          1.7058823529411764,
          15.761092150170649,
          1.1956521739130435,
          6.072135785007072,
          1.0929927963326784,
          1.0414201183431953,
          1.247557003257329,
          1.900414937759336,
          1.6839622641509433,
          2.364705882352941,
          1.900414937759336,
          1.7866666666666666,
          1.2306397306397305,
          6.2,
          1.247557003257329,
          4.0476190476190474,
          12.894736842105264,
          1.08,
          2.230769230769231,
          3.8421052631578947,
          3.0416666666666665,
          2.7037037037037037,
          1.1639344262295082,
          1.8571428571428572,
          1,
          1.2432432432432432,
          1,
          1.0793974980852694,
          3.179173440574998,
          1.02,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          1,
          0.9349397590361446,
          0.9473684210526315,
          0.9699349945828819,
          0.942323314378554,
          0.6157635467980296,
          0.9577897160399079,
          0.9896049896049897,
          0.9382239382239382,
          0.8822170900692841,
          0.934236522720858,
          0.8064516129032258,
          0.4332129963898917,
          0.9499589827727646,
          0.36151603498542273,
          0.8353413654618473,
          0.9447236180904522,
          0.06666666666666667,
          0.6197183098591549,
          0.8407360406091371,
          0.5328467153284672,
          0,
          0.926829268292683,
          0.9939086294416244,
          0.9808695652173913,
          0.8716577540106952,
          0.9686924493554327,
          0.9019607843137255,
          0.9942196531791907,
          0.8186900958466453,
          0.6268656716417911,
          0.9041095890410958,
          0.9827846572032618,
          0.9977528089887641,
          0.9475982532751092,
          0.9881500987491771,
          0.7326732673267327,
          0.9504373177842566,
          0.8,
          0.9076923076923077,
          0.7719298245614035,
          0.8459530026109661,
          0.8372093023255814,
          0.36879432624113473,
          0.8551724137931035,
          0.8438320209973753,
          0.3106060606060606,
          0.9922522041143468,
          0.6307053941908713,
          0.8515497553017944,
          0.8385826771653543,
          0.8894668400520156,
          0.9928057553956835,
          0.8829568788501027,
          0.08356545961002786,
          0.7954545454545454,
          0.82922954725973,
          0.9833686120350771,
          0.5813953488372093,
          0.8891786179921773,
          0.9512195121951219,
          0.9425837320574163,
          0.4927536231884058,
          0.9527720739219713,
          0.9290780141843972,
          0.8759439050701187,
          0,
          0.8626817447495961,
          0.6111111111111112,
          0.9230769230769231,
          0.8888888888888888,
          0.5217391304347826,
          0.6470588235294118,
          0.43243243243243246,
          0.993103448275862,
          0.7105263157894737,
          0.8242424242424242,
          0.7843137254901961,
          0.7945205479452054,
          0.5217391304347826,
          0.995769773106012,
          0.9102064310195965,
          0.6209677419354839,
          0.580115036976171,
          0.6215538847117794,
          0.6238303181534622,
          0.5478757133798351,
          0.6603415559772297,
          0.5645994832041343
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "model"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "dataset_class_imb"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "f1"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"eab80df9-8b78-4459-bac9-a75bfbd66ebd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eab80df9-8b78-4459-bac9-a75bfbd66ebd\")) {                    Plotly.newPlot(                        \"eab80df9-8b78-4459-bac9-a75bfbd66ebd\",                        [{\"hovertemplate\":\"model=Baseline\\u003cbr\\u003edataset_class_imb=%{x}\\u003cbr\\u003ef1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Baseline\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Baseline\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.0217391304347827,1.6839622641509433,1.5892857142857142,1.0016229375169057,1.7716763005780347,2.0822320117474304,1.8855421686746987,1.1512605042016806,2.6736842105263157,3.8545454545454545,1.5377826806398236,1.1443298969072164,1.8875,1.019650655021834,2.0,1.0,1.0,2.6666666666666665,1.8656716417910448,2.407313997477932,1.0179533213644525,1.0,1.0,1.0745658835546477,1.0827067669172932,1.9174757281553398,1.0,1.0,3.5342465753424657,1.8438995215311005,1.4857142857142858,1.85,1.0929927963326784,1.2522522522522523,1.7857142857142858,19.94701986754967,1.7735849056603774,1.5892857142857142,1.7058823529411764,3.84375,1.25,1.7735849056603774,1.1956521739130435,2.7777777777777777,1.144736842105263,2.3333333333333335,4.857142857142857,64.03448275862068,1.8656716417910448,1.247557003257329,2.3333333333333335,1.247557003257329,1.2857142857142858,1.7058823529411764,15.761092150170649,1.1956521739130435,6.072135785007072,1.0929927963326784,1.0414201183431953,1.247557003257329,1.900414937759336,1.6839622641509433,2.364705882352941,1.900414937759336,1.7866666666666666,1.2306397306397305,6.2,1.247557003257329,4.0476190476190474,12.894736842105264,1.08,2.230769230769231,3.8421052631578947,3.0416666666666665,2.7037037037037037,1.1639344262295082,1.8571428571428572,1.0,1.2432432432432432,1.0,1.0793974980852694,3.179173440574998,1.02,1.0,1.0,1.0,1.0,1.0,1.0],\"xaxis\":\"x\",\"y\":[1.0,0.9383886255924171,0.9411764705882353,0.9699850604373217,0.942323314378554,0.6104746317512275,0.9681429681429682,0.9896049896049897,0.937984496124031,0.8873563218390804,0.9406827084499161,0.8111111111111111,0.4727272727272727,0.9475712123297096,0.35398230088495575,0.8353413654618473,0.9393939393939394,0.058823529411764705,0.6201232032854209,0.8453674121405751,0.5247079964061097,0.0,0.9354838709677419,1.0,0.9738219895287958,0.8947368421052632,0.9817518248175182,0.8846153846153846,0.9980657640232108,0.8182977366911062,0.5882352941176471,0.9295774647887324,0.9919330743949806,1.0,0.949671772428884,0.9900891972249752,0.7035175879396985,0.9501466275659824,0.7607843137254902,0.9140625,0.7725321888412017,0.8393782383419689,0.847953216374269,0.3188405797101449,0.8648648648648649,0.8384970336189849,0.32974910394265233,0.992776886035313,0.625,0.8617886178861789,0.8377850162866449,0.8813559322033898,0.9928057553956835,0.8846960167714885,0.08516129032258064,0.7794117647058824,0.8295003965107058,0.992822966507177,0.5511363636363636,0.8926701570680629,0.9527720739219713,0.9383886255924171,0.4583333333333333,0.9488752556237219,0.9458483754512635,0.8761742100768574,0.0,0.8491803278688524,0.631578947368421,0.8947368421052632,0.8727272727272727,0.2857142857142857,0.6060606060606061,0.4,0.993103448275862,0.6933333333333334,0.8242424242424242,0.7924528301886793,0.7605633802816901,0.5106382978723404,1.0,0.9086867889787598,0.6232114467408585,0.5704971475142624,0.6481012658227848,0.6288659793814433,0.5399239543726235,0.6670926517571885,0.5708687132593077],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"model=CRH_pc99\\u003cbr\\u003edataset_class_imb=%{x}\\u003cbr\\u003ef1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"CRH_pc99\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"CRH_pc99\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.0217391304347827,1.6839622641509433,1.5892857142857142,1.0016229375169057,1.7716763005780347,2.0822320117474304,1.8855421686746987,1.1512605042016806,2.6736842105263157,3.8545454545454545,1.5377826806398236,1.1443298969072164,1.8875,1.019650655021834,2.0,1.0,1.0,2.6666666666666665,1.8656716417910448,2.407313997477932,1.0179533213644525,1.0,1.0,1.0745658835546477,1.0827067669172932,1.9174757281553398,1.0,1.0,3.5342465753424657,1.8438995215311005,1.4857142857142858,1.85,1.0929927963326784,1.2522522522522523,1.7857142857142858,19.94701986754967,1.7735849056603774,1.5892857142857142,1.7058823529411764,3.84375,1.25,1.7735849056603774,1.1956521739130435,2.7777777777777777,1.144736842105263,2.3333333333333335,4.857142857142857,64.03448275862068,1.8656716417910448,1.247557003257329,2.3333333333333335,1.247557003257329,1.2857142857142858,1.7058823529411764,15.761092150170649,1.1956521739130435,6.072135785007072,1.0929927963326784,1.0414201183431953,1.247557003257329,1.900414937759336,1.6839622641509433,2.364705882352941,1.900414937759336,1.7866666666666666,1.2306397306397305,6.2,1.247557003257329,4.0476190476190474,12.894736842105264,1.08,2.230769230769231,3.8421052631578947,3.0416666666666665,2.7037037037037037,1.1639344262295082,1.8571428571428572,1.0,1.2432432432432432,1.0,1.0793974980852694,3.179173440574998,1.02,1.0,1.0,1.0,1.0,1.0,1.0],\"xaxis\":\"x\",\"y\":[1.0,0.9349397590361446,0.9473684210526315,0.9699349945828819,0.942323314378554,0.6157635467980296,0.9577897160399079,0.9896049896049897,0.9382239382239382,0.8822170900692841,0.934236522720858,0.8064516129032258,0.4332129963898917,0.9499589827727646,0.36151603498542273,0.8353413654618473,0.9447236180904522,0.06666666666666667,0.6197183098591549,0.8407360406091371,0.5328467153284672,0.0,0.926829268292683,0.9939086294416244,0.9808695652173913,0.8716577540106952,0.9686924493554327,0.9019607843137255,0.9942196531791907,0.8186900958466453,0.6268656716417911,0.9041095890410958,0.9827846572032618,0.9977528089887641,0.9475982532751092,0.9881500987491771,0.7326732673267327,0.9504373177842566,0.8,0.9076923076923077,0.7719298245614035,0.8459530026109661,0.8372093023255814,0.36879432624113473,0.8551724137931035,0.8438320209973753,0.3106060606060606,0.9922522041143468,0.6307053941908713,0.8515497553017944,0.8385826771653543,0.8894668400520156,0.9928057553956835,0.8829568788501027,0.08356545961002786,0.7954545454545454,0.82922954725973,0.9833686120350771,0.5813953488372093,0.8891786179921773,0.9512195121951219,0.9425837320574163,0.4927536231884058,0.9527720739219713,0.9290780141843972,0.8759439050701187,0.0,0.8626817447495961,0.6111111111111112,0.9230769230769231,0.8888888888888888,0.5217391304347826,0.6470588235294118,0.43243243243243246,0.993103448275862,0.7105263157894737,0.8242424242424242,0.7843137254901961,0.7945205479452054,0.5217391304347826,0.995769773106012,0.9102064310195965,0.6209677419354839,0.580115036976171,0.6215538847117794,0.6238303181534622,0.5478757133798351,0.6603415559772297,0.5645994832041343],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"dataset_class_imb\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"f1\"}},\"legend\":{\"title\":{\"text\":\"model\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eab80df9-8b78-4459-bac9-a75bfbd66ebd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "dataset_details = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "]\n",
    "\n",
    "\n",
    "res_to_keep = res[res['model'].isin([\"Baseline\", \"CRH_pc99\"])]\n",
    "res_to_keep['num_samples'] = res_to_keep['dataset'].map(dataset_details[['dataset', 'n_instances']].set_index('dataset')['n_instances'].to_dict().get)\n",
    "res_to_keep['num_feats'] = res_to_keep['dataset'].map(dataset_details[['dataset', 'n_features']].set_index('dataset')['n_features'].to_dict().get)\n",
    "# res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "\n",
    "fig = px.scatter(res_to_keep, x=\"dataset_class_imb\", y=\"f1\", color=\"model\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average time taken\n",
    "\n",
    "### The overhead is less than a second on average or 10 seconds at most (with 48K samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xd6 (1/90)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "wdbc (2/90)\n",
      "(569, 30) with ratio : 1.6840\n",
      "\n",
      "vote (3/90)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "twonorm (4/90)\n",
      "(7400, 20) with ratio : 1.0016\n",
      "\n",
      "tokyo1 (5/90)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "titanic (6/90)\n",
      "(2099, 8) with ratio : 2.0822\n",
      "\n",
      "tic_tac_toe (7/90)\n",
      "(958, 9) with ratio : 1.8855\n",
      "\n",
      "threeOf9 (8/90)\n",
      "(512, 9) with ratio : 1.1513\n",
      "\n",
      "spectf (9/90)\n",
      "(349, 44) with ratio : 2.6737\n",
      "\n",
      "spect (10/90)\n",
      "(267, 22) with ratio : 3.8545\n",
      "\n",
      "spambase (11/90)\n",
      "(4601, 57) with ratio : 1.5378\n",
      "\n",
      "sonar (12/90)\n",
      "(208, 60) with ratio : 1.1443\n",
      "\n",
      "saheart (13/90)\n",
      "(462, 9) with ratio : 1.8875\n",
      "\n",
      "ring (14/90)\n",
      "(7400, 20) with ratio : 1.0197\n",
      "\n",
      "profb (15/90)\n",
      "(672, 9) with ratio : 2.0000\n",
      "\n",
      "prnn_synth (16/90)\n",
      "(250, 2) with ratio : 1.0000\n",
      "\n",
      "prnn_crabs (17/90)\n",
      "(200, 7) with ratio : 1.0000\n",
      "\n",
      "postoperative_patient_data (18/90)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "pima (19/90)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "phoneme (20/90)\n",
      "(5404, 5) with ratio : 2.4073\n",
      "\n",
      "parity5+5 (21/90)\n",
      "(1124, 10) with ratio : 1.0180\n",
      "\n",
      "parity5 (22/90)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "mux6 (23/90)\n",
      "(128, 6) with ratio : 1.0000\n",
      "\n",
      "mushroom (24/90)\n",
      "(8124, 22) with ratio : 1.0746\n",
      "\n",
      "monk3 (25/90)\n",
      "(554, 6) with ratio : 1.0827\n",
      "\n",
      "monk2 (26/90)\n",
      "(601, 6) with ratio : 1.9175\n",
      "\n",
      "monk1 (27/90)\n",
      "(556, 6) with ratio : 1.0000\n",
      "\n",
      "molecular_biology_promoters (28/90)\n",
      "(106, 57) with ratio : 1.0000\n",
      "\n",
      "mofn_3_7_10 (29/90)\n",
      "(1324, 10) with ratio : 3.5342\n",
      "\n",
      "magic (30/90)\n",
      "(19020, 10) with ratio : 1.8439\n",
      "\n",
      "lupus (31/90)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "labor (32/90)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "kr_vs_kp (33/90)\n",
      "(3196, 36) with ratio : 1.0930\n",
      "\n",
      "irish (34/90)\n",
      "(500, 5) with ratio : 1.2523\n",
      "\n",
      "ionosphere (35/90)\n",
      "(351, 34) with ratio : 1.7857\n",
      "\n",
      "hypothyroid (36/90)\n",
      "(3163, 25) with ratio : 19.9470\n",
      "\n",
      "hungarian (37/90)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "house_votes_84 (38/90)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "horse_colic (39/90)\n",
      "(368, 22) with ratio : 1.7059\n",
      "\n",
      "hepatitis (40/90)\n",
      "(155, 19) with ratio : 3.8438\n",
      "\n",
      "heart_statlog (41/90)\n",
      "(270, 13) with ratio : 1.2500\n",
      "\n",
      "heart_h (42/90)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "heart_c (43/90)\n",
      "(303, 13) with ratio : 1.1957\n",
      "\n",
      "haberman (44/90)\n",
      "(306, 3) with ratio : 2.7778\n",
      "\n",
      "glass2 (45/90)\n",
      "(163, 9) with ratio : 1.1447\n",
      "\n",
      "german (46/90)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "flare (47/90)\n",
      "(1066, 10) with ratio : 4.8571\n",
      "\n",
      "dis (48/90)\n",
      "(3772, 29) with ratio : 64.0345\n",
      "\n",
      "diabetes (49/90)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "crx (50/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "credit_g (51/90)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "credit_a (52/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "corral (53/90)\n",
      "(160, 6) with ratio : 1.2857\n",
      "\n",
      "colic (54/90)\n",
      "(368, 22) with ratio : 1.7059\n",
      "\n",
      "coil2000 (55/90)\n",
      "(9822, 85) with ratio : 15.7611\n",
      "\n",
      "cleve (56/90)\n",
      "(303, 13) with ratio : 1.1957\n",
      "\n",
      "churn (57/90)\n",
      "(5000, 20) with ratio : 6.0721\n",
      "\n",
      "chess (58/90)\n",
      "(3196, 36) with ratio : 1.0930\n",
      "\n",
      "bupa (59/90)\n",
      "(345, 5) with ratio : 1.0414\n",
      "\n",
      "buggyCrx (60/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "breast_w (61/90)\n",
      "(699, 9) with ratio : 1.9004\n",
      "\n",
      "breast_cancer_wisconsin (62/90)\n",
      "(569, 30) with ratio : 1.6840\n",
      "\n",
      "breast_cancer (63/90)\n",
      "(286, 9) with ratio : 2.3647\n",
      "\n",
      "breast (64/90)\n",
      "(699, 10) with ratio : 1.9004\n",
      "\n",
      "biomed (65/90)\n",
      "(209, 8) with ratio : 1.7867\n",
      "\n",
      "banana (66/90)\n",
      "(5300, 2) with ratio : 1.2306\n",
      "\n",
      "backache (67/90)\n",
      "(180, 32) with ratio : 6.2000\n",
      "\n",
      "australian (68/90)\n",
      "(690, 14) with ratio : 1.2476\n",
      "\n",
      "appendicitis (69/90)\n",
      "(106, 7) with ratio : 4.0476\n",
      "\n",
      "analcatdata_lawsuit (70/90)\n",
      "(264, 4) with ratio : 12.8947\n",
      "\n",
      "analcatdata_japansolvent (71/90)\n",
      "(52, 9) with ratio : 1.0800\n",
      "\n",
      "analcatdata_fraud (72/90)\n",
      "(42, 11) with ratio : 2.2308\n",
      "\n",
      "analcatdata_cyyoung9302 (73/90)\n",
      "(92, 10) with ratio : 3.8421\n",
      "\n",
      "analcatdata_cyyoung8092 (74/90)\n",
      "(97, 10) with ratio : 3.0417\n",
      "\n",
      "analcatdata_creditscore (75/90)\n",
      "(100, 6) with ratio : 2.7037\n",
      "\n",
      "analcatdata_boxing2 (76/90)\n",
      "(132, 3) with ratio : 1.1639\n",
      "\n",
      "analcatdata_boxing1 (77/90)\n",
      "(120, 3) with ratio : 1.8571\n",
      "\n",
      "analcatdata_bankruptcy (78/90)\n",
      "(50, 6) with ratio : 1.0000\n",
      "\n",
      "analcatdata_asbestos (79/90)\n",
      "(83, 3) with ratio : 1.2432\n",
      "\n",
      "analcatdata_aids (80/90)\n",
      "(50, 4) with ratio : 1.0000\n",
      "\n",
      "agaricus_lepiota (81/90)\n",
      "(8145, 22) with ratio : 1.0794\n",
      "\n",
      "adult (82/90)\n",
      "(48842, 14) with ratio : 3.1792\n",
      "\n",
      "Hill_Valley_without_noise (83/90)\n",
      "(1212, 100) with ratio : 1.0200\n",
      "\n",
      "Hill_Valley_with_noise (84/90)\n",
      "(1212, 100) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001 (85/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001 (86/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1 (87/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1 (88/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1 (89/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Average time taken\n",
    "\n",
    "times = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    time_s = time.time()\n",
    "    scores_data =  np.zeros(len(X)) + max_depth + 1\n",
    "    for depth in range(1, max_depth):\n",
    "        clf = DecisionTreeClassifier(random_state=42, max_depth=depth)\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X)\n",
    "        found_flag = (y_pred == y).astype(int)*depth\n",
    "        found_flag[found_flag == 0] = max_depth + 1\n",
    "        scores_data = np.minimum(scores_data, found_flag)\n",
    "        if (scores_data >= max_depth).sum() == 0:\n",
    "            break\n",
    "    time_taken = time.time() - time_s\n",
    "    times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken (seconds): 0.64 +- 4.02 (mean +- 2*std)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean time taken (seconds): {np.mean(times):.2f} +- {2*np.std(times):.2f} (mean +- 2*std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
