{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Tensor decomposition for classifcaiton\n",
    "### Date: 29/10/2024\n",
    "### Status: Works out of the box! Interesting idea, as it is a likelihood-based model.\n",
    "### Idea: \n",
    "Fit a PCA on the concat(X, Y) matrix, that is the feature matrix augmented with the class label per sample, generating a matrix of shape: $(Samples \\times Features + 1)$.\n",
    "\n",
    "Then, at test time create two matrices $Y_1 = concat(X_{test}, Ones)$, and $Y_0 = concat(X_{test}, Zeros)$ and score the log-likelihood of each sample, given the PCA-fitted model.\n",
    "\n",
    "The resulting label is $1$ if $Y_1 > Y_0$ else $0$. (i.e. we keep the label of the most-probable configuration for each sample).\n",
    "\n",
    "### Results:\n",
    "34/64 (53%) wins over generic Decision Tree. Not bad.\n",
    "\n",
    "Details:\n",
    "- We keep 90% of the features as projection dimension for PCA\n",
    "- Also experimented to find the optimal number of components by:\n",
    "  - First fitting a PCA with components equal to features and finding the number of components with 90% cummulative variance, and then re-fitting the PCA. Worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class PCA_descr(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "xd6 (1/74)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       0.99      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "tokyo1 (2/74)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       346\n",
      "           1       0.93      0.94      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.91      0.91      0.91       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "  model  rank\n",
      "0    DT   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1030986/3490557178.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "# models = ['TD', 'DT']\n",
    "models = [\n",
    "    \"DT\"\n",
    "]\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:2]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state)\n",
    "    \n",
    "    for model_name in models:\n",
    "        time_s = time.time()\n",
    "        if model_name == 'DT':\n",
    "            clf = DecisionTreeClassifier(random_state=random_state)\n",
    "            # clf.fit(X_train, y_train)\n",
    "            # y_probas = clf.predict_proba(X_test)\n",
    "            # y_pred = np.argmax(y_probas, axis=1)\n",
    "            y_pred = cross_val_predict(clf, X, y, cv=cv).astype(int)\n",
    "        \n",
    "        \n",
    "        elif model_name == 'TD':\n",
    "            from sklearn.decomposition import PCA\n",
    "            y_pred = np.empty_like(y)\n",
    "            for train_indices, test_indices in cv.split(X,y):\n",
    "                X_train, y_train = X[train_indices], y[train_indices]\n",
    "                X_test, y_test = X[test_indices], y[test_indices]\n",
    "                \n",
    "                ext = np.hstack((X_train, y_train.reshape(-1,1)))\n",
    "                ext_zeros = np.hstack((X_test, np.zeros_like(y_test).reshape(-1,1)))\n",
    "                ext_ones = np.hstack((X_test, np.ones_like(y_test).reshape(-1,1)))\n",
    "                \n",
    "                tr = PCA(n_components=int(0.9*X_train.shape[1])) # PCA(n_components='mle', svd_solver='full')#\n",
    "                # tr = PCA(n_components=X_train.shape[1])\n",
    "                \n",
    "                # tr.fit(ext)\n",
    "                \n",
    "                # num_important = np.argwhere(tr.explained_variance_ratio_.cumsum() >= 0.8)[0][0] + 1\n",
    "\n",
    "                # tr = PCA(n_components=num_important)\n",
    "                tr.fit(ext)\n",
    "                \n",
    "                print(f\"Will fit on {tr.n_components_}/{X_train.shape[1]} (reduction: {100*(X_train.shape[1] - tr.n_components_)/X_train.shape[1]:.2f} %)\")\n",
    "                \n",
    "                zeros_tr = tr.score_samples(ext_zeros)\n",
    "                ones_tr = tr.score_samples(ext_ones)\n",
    "                exp_ll = np.exp(np.vstack((zeros_tr, ones_tr)))\n",
    "                y_pred_cur = (exp_ll[1,:] > exp_ll[0,:]).astype(int)\n",
    "                y_pred[test_indices] = y_pred_cur\n",
    "            #y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1 = StandardScaler().fit_transform(X)\n",
    "X2 = StandardScaler().fit_transform(X1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import linalg\n",
    "\n",
    "U, s, Vh = linalg.svd(X2)\n",
    "importance = s**2/(s**2).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for class_ in np.unique(y):\n",
    "    idx = np.where(y==class_)[0]\n",
    "    models[class_] = {}\n",
    "    cur_x = X[idx]\n",
    "    sc1 = StandardScaler()\n",
    "    sc2 = StandardScaler()\n",
    "    X1 = sc1.fit_transform(cur_x)\n",
    "    X2 = sc2.fit_transform(X1.T)\n",
    "    U, s, Vh = linalg.svd(X2)\n",
    "    importance = s**2/(s**2).sum()\n",
    "    models[class_] = {\"sc1\": sc1, \"sc2\":sc2, \"ev\":Vh, \"es\":s, \"imp\":importance}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44, 613), (44, 44), (613, 613))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape, U.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 44 while Y.shape[1] == 346",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(to_keep)\n\u001b[1;32m     11\u001b[0m to_compare \u001b[38;5;241m=\u001b[39m U[:to_keep]\u001b[38;5;66;03m#np.einsum('fs, s->fs', U,s)#U[:to_keep]\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_compare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m preds[class_] \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#@ imp[:to_keep]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#break\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2480\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   2478\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 2480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1973\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1970\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:360\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03mCompute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m       [1.41421356]])\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X, Y)\n\u001b[0;32m--> 360\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_norm_squared \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     X_norm_squared \u001b[38;5;241m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:229\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed metric requires shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_queries, n_indexed). Got (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m indexed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Only check the number of features if 2d arrays are enforced. Otherwise,\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# validation is left to the user for custom metrics.\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m while Y.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 44 while Y.shape[1] == 346"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "preds = {}\n",
    "for class_ in np.unique(y):\n",
    "    sc1 = models[class_]['sc1']\n",
    "    sc2 = models[class_]['sc2']\n",
    "    X1 = sc1.transform(X)\n",
    "    X2 = sc2.fit_transform(X1.T).T\n",
    "    U, s, imp = models[class_]['ev'], models[class_]['es'], models[class_]['imp']\n",
    "    to_keep = (importance.cumsum() < 1).argmin() + 1\n",
    "    print(to_keep)\n",
    "    to_compare = U[:to_keep]#np.einsum('fs, s->fs', U,s)#U[:to_keep]\n",
    "    dist = pairwise_distances(X2, to_compare)\n",
    "    preds[class_] = dist.sum(axis=1) #@ imp[:to_keep]\n",
    "    #break\n",
    "\n",
    "pred = (preds[1] < preds[0]).astype(int)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       346\n",
      "           1       0.77      0.84      0.81       613\n",
      "\n",
      "    accuracy                           0.74       959\n",
      "   macro avg       0.72      0.70      0.71       959\n",
      "weighted avg       0.74      0.74      0.74       959\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.65102202],\n",
       "       [6.89315608],\n",
       "       [6.47431396],\n",
       "       [6.76731544],\n",
       "       [6.91685306],\n",
       "       [6.57210795],\n",
       "       [6.63010742],\n",
       "       [6.6652523 ],\n",
       "       [6.40048881],\n",
       "       [6.9094485 ],\n",
       "       [6.49748468],\n",
       "       [6.87598555],\n",
       "       [6.622994  ],\n",
       "       [6.61486528],\n",
       "       [6.68373443],\n",
       "       [6.43904091],\n",
       "       [6.77810433],\n",
       "       [6.54798165],\n",
       "       [6.60009298],\n",
       "       [6.62830516],\n",
       "       [6.5015003 ],\n",
       "       [6.91984518],\n",
       "       [6.37454525],\n",
       "       [6.50771597],\n",
       "       [6.85519495],\n",
       "       [6.58081571],\n",
       "       [6.60119479],\n",
       "       [6.46388776],\n",
       "       [6.89753648],\n",
       "       [6.37799495],\n",
       "       [6.43594595],\n",
       "       [6.76320572],\n",
       "       [6.90321933],\n",
       "       [6.61179044],\n",
       "       [6.59294093],\n",
       "       [6.62732746],\n",
       "       [6.50294648],\n",
       "       [6.74019926],\n",
       "       [6.91926066],\n",
       "       [6.59009413],\n",
       "       [6.90284014],\n",
       "       [6.71477494],\n",
       "       [6.60888769],\n",
       "       [6.64638771],\n",
       "       [6.92087238],\n",
       "       [6.37903552],\n",
       "       [6.52804435],\n",
       "       [6.76395739],\n",
       "       [6.63033887],\n",
       "       [6.69337798],\n",
       "       [6.56075689],\n",
       "       [6.58017581],\n",
       "       [6.61098597],\n",
       "       [6.72873518],\n",
       "       [6.82098827],\n",
       "       [6.59910522],\n",
       "       [6.72166103],\n",
       "       [6.58644278],\n",
       "       [6.81799165],\n",
       "       [6.52585335],\n",
       "       [6.5884035 ],\n",
       "       [6.61434738],\n",
       "       [6.89764552],\n",
       "       [6.57762328],\n",
       "       [6.77847548],\n",
       "       [6.73966813],\n",
       "       [6.79653911],\n",
       "       [6.47079235],\n",
       "       [6.89065876],\n",
       "       [6.52627652],\n",
       "       [6.56225751],\n",
       "       [6.9008319 ],\n",
       "       [6.53824688],\n",
       "       [6.84941551],\n",
       "       [6.90252476],\n",
       "       [6.74433165],\n",
       "       [6.59683375],\n",
       "       [6.76862215],\n",
       "       [6.72954103],\n",
       "       [6.65592624],\n",
       "       [6.6692496 ],\n",
       "       [6.62660008],\n",
       "       [6.90951192],\n",
       "       [6.53796927],\n",
       "       [6.73701457],\n",
       "       [6.57787565],\n",
       "       [6.67194219],\n",
       "       [6.58000012],\n",
       "       [6.58091718],\n",
       "       [6.91554044],\n",
       "       [6.73573804],\n",
       "       [6.60937526],\n",
       "       [6.97434742],\n",
       "       [6.77611355],\n",
       "       [6.58656491],\n",
       "       [6.88273473],\n",
       "       [6.89318369],\n",
       "       [6.58094364],\n",
       "       [6.78484781],\n",
       "       [6.67312222],\n",
       "       [6.53304935],\n",
       "       [6.53018013],\n",
       "       [6.55021864],\n",
       "       [6.82998625],\n",
       "       [6.56547358],\n",
       "       [7.03643473],\n",
       "       [6.64087792],\n",
       "       [6.6878041 ],\n",
       "       [6.9061256 ],\n",
       "       [6.68594806],\n",
       "       [6.7198324 ],\n",
       "       [6.96762945],\n",
       "       [6.63723214],\n",
       "       [6.91957885],\n",
       "       [6.88711402],\n",
       "       [6.61419231],\n",
       "       [6.6659048 ],\n",
       "       [6.61775203],\n",
       "       [6.90249112],\n",
       "       [6.52737248],\n",
       "       [6.64975192],\n",
       "       [6.42044666],\n",
       "       [6.88305273],\n",
       "       [6.6912963 ],\n",
       "       [6.57582596],\n",
       "       [6.90021019],\n",
       "       [6.59204751],\n",
       "       [6.98370306],\n",
       "       [6.57963197],\n",
       "       [6.54395158],\n",
       "       [6.90914611],\n",
       "       [6.70195716],\n",
       "       [6.62088688],\n",
       "       [6.64105053],\n",
       "       [6.66135713],\n",
       "       [6.93775309],\n",
       "       [6.96159487],\n",
       "       [6.48208053],\n",
       "       [6.64599272],\n",
       "       [6.51355614],\n",
       "       [6.49527248],\n",
       "       [6.53114388],\n",
       "       [6.69206909],\n",
       "       [6.90160658],\n",
       "       [6.5522517 ],\n",
       "       [6.73038936],\n",
       "       [6.92513491],\n",
       "       [6.67792485],\n",
       "       [6.80865974],\n",
       "       [6.5606015 ],\n",
       "       [6.59702193],\n",
       "       [6.5519538 ],\n",
       "       [6.61731444],\n",
       "       [6.68703461],\n",
       "       [6.61852393],\n",
       "       [6.68143682],\n",
       "       [6.46604157],\n",
       "       [6.54215032],\n",
       "       [6.63761192],\n",
       "       [7.0693436 ],\n",
       "       [6.68043081],\n",
       "       [6.38995821],\n",
       "       [6.78997749],\n",
       "       [6.55202104],\n",
       "       [6.84132897],\n",
       "       [6.66016388],\n",
       "       [6.90565013],\n",
       "       [6.92666061],\n",
       "       [6.66970967],\n",
       "       [6.51509041],\n",
       "       [6.90646236],\n",
       "       [6.91655016],\n",
       "       [6.52586054],\n",
       "       [6.63896189],\n",
       "       [6.75324557],\n",
       "       [6.75296437],\n",
       "       [7.00174564],\n",
       "       [6.5698296 ],\n",
       "       [6.3592232 ],\n",
       "       [6.61157566],\n",
       "       [6.93413403],\n",
       "       [6.89462315],\n",
       "       [6.54550292],\n",
       "       [6.45144345],\n",
       "       [6.52588098],\n",
       "       [6.89175525],\n",
       "       [6.61010802],\n",
       "       [6.93105633],\n",
       "       [6.61967701],\n",
       "       [6.84390513],\n",
       "       [6.36400678],\n",
       "       [6.65284   ],\n",
       "       [6.71209919],\n",
       "       [6.82086295],\n",
       "       [6.44901696],\n",
       "       [6.96011345],\n",
       "       [6.90459124],\n",
       "       [6.75509975],\n",
       "       [6.45302556],\n",
       "       [6.55089444],\n",
       "       [6.68135389],\n",
       "       [6.90712519],\n",
       "       [6.50262389],\n",
       "       [6.60618027],\n",
       "       [6.57362387],\n",
       "       [6.84139982],\n",
       "       [6.66261131],\n",
       "       [6.92848697],\n",
       "       [6.61373997],\n",
       "       [6.59808803],\n",
       "       [6.46878797],\n",
       "       [6.50900024],\n",
       "       [6.90329946],\n",
       "       [6.90058113],\n",
       "       [6.65819292],\n",
       "       [6.60743261],\n",
       "       [6.90911638],\n",
       "       [6.78557851],\n",
       "       [6.49962193],\n",
       "       [6.99443628],\n",
       "       [6.51051234],\n",
       "       [6.58779466],\n",
       "       [6.90203497],\n",
       "       [6.91511874],\n",
       "       [6.67208761],\n",
       "       [6.55105564],\n",
       "       [6.71703588],\n",
       "       [6.41432452],\n",
       "       [6.57820674],\n",
       "       [6.46351074],\n",
       "       [6.88086826],\n",
       "       [6.61190655],\n",
       "       [6.57178898],\n",
       "       [6.87187273],\n",
       "       [6.57726379],\n",
       "       [6.52084225],\n",
       "       [6.57020809],\n",
       "       [6.75200802],\n",
       "       [6.91048779],\n",
       "       [6.60279604],\n",
       "       [6.6666678 ],\n",
       "       [6.45084652],\n",
       "       [6.57796817],\n",
       "       [6.86592641],\n",
       "       [6.60963144],\n",
       "       [6.91584574],\n",
       "       [6.70722043],\n",
       "       [6.74426549],\n",
       "       [6.51108462],\n",
       "       [6.48768016],\n",
       "       [6.68741531],\n",
       "       [6.90428671],\n",
       "       [6.6454888 ],\n",
       "       [6.87117821],\n",
       "       [6.54386419],\n",
       "       [6.81485347],\n",
       "       [6.80955943],\n",
       "       [6.59844541],\n",
       "       [6.66376685],\n",
       "       [6.602336  ],\n",
       "       [6.57369341],\n",
       "       [6.89606222],\n",
       "       [6.57257708],\n",
       "       [6.35695639],\n",
       "       [6.91082631],\n",
       "       [6.43460386],\n",
       "       [6.56148354],\n",
       "       [6.57680964],\n",
       "       [6.61811927],\n",
       "       [6.4577157 ],\n",
       "       [6.63278917],\n",
       "       [6.90897301],\n",
       "       [6.91264266],\n",
       "       [6.89023822],\n",
       "       [6.8717446 ],\n",
       "       [6.90409911],\n",
       "       [6.65223966],\n",
       "       [6.70448723],\n",
       "       [6.42489212],\n",
       "       [7.01972557],\n",
       "       [6.52279297],\n",
       "       [6.56354188],\n",
       "       [6.87772331],\n",
       "       [6.67842918],\n",
       "       [6.56238055],\n",
       "       [6.39747246],\n",
       "       [6.58112495],\n",
       "       [6.90899327],\n",
       "       [6.88084016],\n",
       "       [6.65061109],\n",
       "       [6.78497479],\n",
       "       [6.71065384],\n",
       "       [6.47507543],\n",
       "       [6.90752588],\n",
       "       [6.90327554],\n",
       "       [6.89889797],\n",
       "       [6.90469007],\n",
       "       [6.79715421],\n",
       "       [6.87326141],\n",
       "       [6.82772799],\n",
       "       [6.87482335],\n",
       "       [6.48075641],\n",
       "       [6.6042626 ],\n",
       "       [6.61497956],\n",
       "       [6.60557614],\n",
       "       [6.67480019],\n",
       "       [6.86549969],\n",
       "       [7.00111514],\n",
       "       [6.77040339],\n",
       "       [6.88812855],\n",
       "       [6.83955438],\n",
       "       [6.87346137],\n",
       "       [6.83449355],\n",
       "       [6.71057221],\n",
       "       [6.53667571],\n",
       "       [6.60301577],\n",
       "       [6.51889324],\n",
       "       [6.59067246],\n",
       "       [6.77039638],\n",
       "       [6.52211505],\n",
       "       [6.90578763],\n",
       "       [6.64211837],\n",
       "       [6.66671127],\n",
       "       [6.81611927],\n",
       "       [6.75134502],\n",
       "       [6.91033448],\n",
       "       [6.65780974],\n",
       "       [6.6347651 ],\n",
       "       [6.56691377],\n",
       "       [6.90374852],\n",
       "       [6.9027734 ],\n",
       "       [6.91682152],\n",
       "       [6.913841  ],\n",
       "       [6.64535816],\n",
       "       [6.9063822 ],\n",
       "       [6.59855863],\n",
       "       [6.91601874],\n",
       "       [6.4689023 ],\n",
       "       [6.83333446],\n",
       "       [6.81635375],\n",
       "       [6.89777425],\n",
       "       [6.95263293],\n",
       "       [6.67502857],\n",
       "       [6.60189745],\n",
       "       [6.91755005],\n",
       "       [6.99620893],\n",
       "       [6.86278393],\n",
       "       [6.85200511],\n",
       "       [6.64951129],\n",
       "       [6.55398226],\n",
       "       [6.91384411],\n",
       "       [6.36131618],\n",
       "       [6.6774125 ],\n",
       "       [6.92493175],\n",
       "       [6.66119564],\n",
       "       [6.60589295],\n",
       "       [6.50139367],\n",
       "       [6.57565296],\n",
       "       [6.60361531],\n",
       "       [6.57321956],\n",
       "       [6.3502476 ],\n",
       "       [6.54733631],\n",
       "       [6.86758006],\n",
       "       [6.91893615],\n",
       "       [6.81535285],\n",
       "       [6.85801329],\n",
       "       [6.56754971],\n",
       "       [6.90596668],\n",
       "       [6.77177899],\n",
       "       [6.60075268],\n",
       "       [6.53691949],\n",
       "       [6.57059343],\n",
       "       [6.87496295],\n",
       "       [6.61245349],\n",
       "       [7.01885532],\n",
       "       [6.89407403],\n",
       "       [6.71991096],\n",
       "       [6.57659088],\n",
       "       [6.51968169],\n",
       "       [6.75937   ],\n",
       "       [6.66690985],\n",
       "       [6.79604911],\n",
       "       [6.60028772],\n",
       "       [6.35918944],\n",
       "       [6.8600293 ],\n",
       "       [6.8090243 ],\n",
       "       [6.72325572],\n",
       "       [6.88744251],\n",
       "       [6.31868201],\n",
       "       [6.55363236],\n",
       "       [7.04519819],\n",
       "       [6.6003996 ],\n",
       "       [6.81899767],\n",
       "       [6.68269308],\n",
       "       [6.88057006],\n",
       "       [6.54976683],\n",
       "       [6.89147233],\n",
       "       [6.55122991],\n",
       "       [6.5631778 ],\n",
       "       [6.82415829],\n",
       "       [6.63264057],\n",
       "       [6.50391332],\n",
       "       [6.71506148],\n",
       "       [6.61473901],\n",
       "       [6.8555347 ],\n",
       "       [6.87741886],\n",
       "       [6.54415446],\n",
       "       [6.55478103],\n",
       "       [6.90212008],\n",
       "       [6.41960344],\n",
       "       [6.82776546],\n",
       "       [6.53686376],\n",
       "       [6.60014289],\n",
       "       [6.85530828],\n",
       "       [6.61308271],\n",
       "       [6.47499747],\n",
       "       [6.84701291],\n",
       "       [6.60098743],\n",
       "       [6.55523394],\n",
       "       [6.93149651],\n",
       "       [6.62198165],\n",
       "       [6.66328259],\n",
       "       [6.75805395],\n",
       "       [6.68549428],\n",
       "       [6.8536246 ],\n",
       "       [6.90517147],\n",
       "       [6.91733282],\n",
       "       [6.89620155],\n",
       "       [6.90676957],\n",
       "       [6.91436196],\n",
       "       [6.67935061],\n",
       "       [6.51477911],\n",
       "       [6.8896094 ],\n",
       "       [6.64973883],\n",
       "       [6.79910936],\n",
       "       [6.72883138],\n",
       "       [6.88269766],\n",
       "       [6.90615503],\n",
       "       [6.56669271],\n",
       "       [6.87741107],\n",
       "       [6.5132232 ],\n",
       "       [6.74633906],\n",
       "       [6.62577411],\n",
       "       [6.55053139],\n",
       "       [6.59477632],\n",
       "       [6.87849057],\n",
       "       [6.66976793],\n",
       "       [6.58412924],\n",
       "       [6.90833077],\n",
       "       [6.69047059],\n",
       "       [6.72197119],\n",
       "       [6.70298105],\n",
       "       [6.55424605],\n",
       "       [6.89831223],\n",
       "       [6.62074649],\n",
       "       [6.94563841],\n",
       "       [6.90949663],\n",
       "       [6.76765599],\n",
       "       [6.61055759],\n",
       "       [6.4540389 ],\n",
       "       [6.62783162],\n",
       "       [6.89758246],\n",
       "       [6.50848891],\n",
       "       [6.45674617],\n",
       "       [6.52077534],\n",
       "       [6.32090117],\n",
       "       [6.90771126],\n",
       "       [6.67507942],\n",
       "       [6.49785742],\n",
       "       [6.91332225],\n",
       "       [6.5922889 ],\n",
       "       [6.34114815],\n",
       "       [6.66202895],\n",
       "       [6.86689315],\n",
       "       [6.89782207],\n",
       "       [6.47542535],\n",
       "       [6.45236492],\n",
       "       [6.85559258],\n",
       "       [6.44109472],\n",
       "       [6.59508697],\n",
       "       [6.68538947],\n",
       "       [6.92445211],\n",
       "       [6.40445837],\n",
       "       [6.46419985],\n",
       "       [6.87629443],\n",
       "       [6.61051425],\n",
       "       [6.46904123],\n",
       "       [6.33944893],\n",
       "       [6.54274638],\n",
       "       [6.53340931],\n",
       "       [6.82026951],\n",
       "       [6.91606244],\n",
       "       [6.74758087],\n",
       "       [6.33431612],\n",
       "       [6.61530695],\n",
       "       [6.58862607],\n",
       "       [6.80964324],\n",
       "       [6.91519843],\n",
       "       [6.91885431],\n",
       "       [6.69834568],\n",
       "       [6.71229755],\n",
       "       [6.90751674],\n",
       "       [6.58691225],\n",
       "       [6.8483487 ],\n",
       "       [6.69009898],\n",
       "       [6.50795547],\n",
       "       [6.78226362],\n",
       "       [6.71416839],\n",
       "       [6.74422799],\n",
       "       [6.42752379],\n",
       "       [6.47704581],\n",
       "       [6.46916241],\n",
       "       [6.36692961],\n",
       "       [6.91483308],\n",
       "       [6.84620925],\n",
       "       [6.74526851],\n",
       "       [6.91563751],\n",
       "       [6.88452153],\n",
       "       [6.61250745],\n",
       "       [6.87361923],\n",
       "       [6.98892487],\n",
       "       [6.85021748],\n",
       "       [6.7813128 ],\n",
       "       [6.33815764],\n",
       "       [6.67515737],\n",
       "       [6.81354719],\n",
       "       [6.65524838],\n",
       "       [6.63841936],\n",
       "       [6.65041996],\n",
       "       [6.49130521],\n",
       "       [6.91322051],\n",
       "       [6.59809898],\n",
       "       [6.93072236],\n",
       "       [6.76626057],\n",
       "       [6.63404449],\n",
       "       [6.6077602 ],\n",
       "       [6.70888434],\n",
       "       [6.58672794],\n",
       "       [6.93550332],\n",
       "       [6.31847993],\n",
       "       [6.51445296],\n",
       "       [6.87064017],\n",
       "       [6.53238473],\n",
       "       [6.56056763],\n",
       "       [6.86736207],\n",
       "       [6.34991492],\n",
       "       [6.91459143],\n",
       "       [6.5658719 ],\n",
       "       [6.9207086 ],\n",
       "       [6.53492179],\n",
       "       [6.73976867],\n",
       "       [6.53672843],\n",
       "       [6.89659565],\n",
       "       [6.64669255],\n",
       "       [6.84235951],\n",
       "       [6.58071664],\n",
       "       [6.6536166 ],\n",
       "       [6.91205384],\n",
       "       [6.75571871],\n",
       "       [6.91863715],\n",
       "       [6.55125197],\n",
       "       [6.63894297],\n",
       "       [6.54946179],\n",
       "       [6.70350179],\n",
       "       [6.77147389],\n",
       "       [6.64820597],\n",
       "       [6.90563591],\n",
       "       [6.3270068 ],\n",
       "       [6.5655555 ],\n",
       "       [6.40316628],\n",
       "       [6.7065348 ],\n",
       "       [6.92001155],\n",
       "       [6.80707462],\n",
       "       [6.62063058],\n",
       "       [6.69217073],\n",
       "       [6.55249889],\n",
       "       [6.42583026],\n",
       "       [6.5970418 ],\n",
       "       [6.54823057],\n",
       "       [6.90794564],\n",
       "       [6.99170347],\n",
       "       [6.61976182],\n",
       "       [6.61089156],\n",
       "       [6.6748672 ],\n",
       "       [6.50723866],\n",
       "       [6.90629018],\n",
       "       [6.84933508],\n",
       "       [6.8976128 ],\n",
       "       [6.5593533 ],\n",
       "       [6.91439971],\n",
       "       [6.60457845],\n",
       "       [6.78413862],\n",
       "       [6.52229264],\n",
       "       [6.8371165 ],\n",
       "       [6.56536319],\n",
       "       [6.81698151],\n",
       "       [6.77061246],\n",
       "       [6.57245671],\n",
       "       [6.54425878],\n",
       "       [6.72529085],\n",
       "       [6.90204301],\n",
       "       [6.64044751],\n",
       "       [6.57029295],\n",
       "       [6.62420503],\n",
       "       [6.77299272],\n",
       "       [6.92713159],\n",
       "       [6.47047452],\n",
       "       [6.65820945],\n",
       "       [6.77330619],\n",
       "       [6.56293294],\n",
       "       [6.42095021],\n",
       "       [6.5931193 ],\n",
       "       [6.66554799],\n",
       "       [6.69520968],\n",
       "       [6.90725272],\n",
       "       [6.65209601],\n",
       "       [6.91542937],\n",
       "       [6.56875418],\n",
       "       [6.90590785],\n",
       "       [6.5970146 ],\n",
       "       [6.60232656],\n",
       "       [6.9843641 ],\n",
       "       [6.74657907],\n",
       "       [6.49613821],\n",
       "       [6.64790871],\n",
       "       [6.48571242],\n",
       "       [6.61636535],\n",
       "       [6.56475802],\n",
       "       [6.34903732],\n",
       "       [6.77766347],\n",
       "       [6.58839701],\n",
       "       [6.68672723],\n",
       "       [6.80637629],\n",
       "       [6.74098592],\n",
       "       [6.58728015],\n",
       "       [6.9056436 ],\n",
       "       [6.92654433],\n",
       "       [6.38228439],\n",
       "       [6.58500867],\n",
       "       [6.91053558],\n",
       "       [6.62766702],\n",
       "       [6.75970425],\n",
       "       [6.92374069],\n",
       "       [6.48214611],\n",
       "       [6.78065108],\n",
       "       [6.49059086],\n",
       "       [6.90529108],\n",
       "       [6.49761724],\n",
       "       [6.51501205],\n",
       "       [6.48799435],\n",
       "       [6.63318906],\n",
       "       [6.85170929],\n",
       "       [6.90656484],\n",
       "       [6.93275046],\n",
       "       [6.57740972],\n",
       "       [6.59290937],\n",
       "       [6.85046566],\n",
       "       [6.76527111],\n",
       "       [6.36186812],\n",
       "       [6.78385671],\n",
       "       [6.91655096],\n",
       "       [6.92816073],\n",
       "       [6.62495219],\n",
       "       [6.65238044],\n",
       "       [6.86358472],\n",
       "       [6.62894696],\n",
       "       [6.83330869],\n",
       "       [6.64652233],\n",
       "       [6.92786229],\n",
       "       [6.722497  ],\n",
       "       [6.83815373],\n",
       "       [6.89684047],\n",
       "       [6.61461379],\n",
       "       [6.90482432],\n",
       "       [6.85159702],\n",
       "       [6.89991963],\n",
       "       [6.9078144 ],\n",
       "       [6.61756447],\n",
       "       [6.62056786],\n",
       "       [6.63432523],\n",
       "       [6.88799004],\n",
       "       [6.68934372],\n",
       "       [6.86393686],\n",
       "       [6.58429517],\n",
       "       [6.72725876],\n",
       "       [6.73093709],\n",
       "       [6.63768584],\n",
       "       [6.82083105],\n",
       "       [6.93032608],\n",
       "       [6.62401584],\n",
       "       [6.55913664],\n",
       "       [6.69564045],\n",
       "       [6.67977857],\n",
       "       [6.85600502],\n",
       "       [6.59811931],\n",
       "       [6.63981318],\n",
       "       [6.81454885],\n",
       "       [6.75313984],\n",
       "       [6.91305141],\n",
       "       [6.42605304],\n",
       "       [6.88118102],\n",
       "       [6.90587284],\n",
       "       [6.92268715],\n",
       "       [6.74811538],\n",
       "       [6.88315146],\n",
       "       [6.87536094],\n",
       "       [6.50652889],\n",
       "       [6.63245479],\n",
       "       [6.34291857],\n",
       "       [6.63785327],\n",
       "       [6.91765951],\n",
       "       [6.86611468],\n",
       "       [6.55439714],\n",
       "       [6.66228831],\n",
       "       [6.87032605],\n",
       "       [6.91195024],\n",
       "       [6.72106884],\n",
       "       [6.55591196],\n",
       "       [6.61773138],\n",
       "       [6.58323976],\n",
       "       [6.90931845],\n",
       "       [6.93109885],\n",
       "       [6.71234022],\n",
       "       [6.51567911],\n",
       "       [6.3800782 ],\n",
       "       [6.63492263],\n",
       "       [6.52275769],\n",
       "       [6.4628818 ],\n",
       "       [6.90294213],\n",
       "       [6.87553542],\n",
       "       [6.91186695],\n",
       "       [6.91135482],\n",
       "       [6.47533805],\n",
       "       [6.89050755],\n",
       "       [6.75402912],\n",
       "       [6.9078408 ],\n",
       "       [6.91411453],\n",
       "       [6.90619286],\n",
       "       [6.87650857],\n",
       "       [6.71438551],\n",
       "       [6.7231755 ],\n",
       "       [6.91907161],\n",
       "       [6.69830102],\n",
       "       [6.62899996],\n",
       "       [6.56917178],\n",
       "       [6.78631023],\n",
       "       [6.74786556],\n",
       "       [6.65331191],\n",
       "       [6.75067247],\n",
       "       [6.68754949],\n",
       "       [6.79139184],\n",
       "       [6.78641301],\n",
       "       [6.90400702],\n",
       "       [6.91224618],\n",
       "       [6.69484567],\n",
       "       [6.61033213],\n",
       "       [6.90710869],\n",
       "       [6.64561419],\n",
       "       [6.54308924],\n",
       "       [7.02146082],\n",
       "       [6.71942411],\n",
       "       [6.80023113],\n",
       "       [6.73332433],\n",
       "       [6.6581514 ],\n",
       "       [6.75106088],\n",
       "       [6.91248729],\n",
       "       [6.49699352],\n",
       "       [6.78696614],\n",
       "       [6.86370857],\n",
       "       [6.44676308],\n",
       "       [6.90621653],\n",
       "       [6.78399397],\n",
       "       [6.66353773],\n",
       "       [6.72613446],\n",
       "       [6.91039511],\n",
       "       [6.92594554],\n",
       "       [6.71389754],\n",
       "       [6.69577501],\n",
       "       [6.41568554],\n",
       "       [6.90634814],\n",
       "       [7.01915618],\n",
       "       [6.90613383],\n",
       "       [6.6060539 ],\n",
       "       [6.45433292],\n",
       "       [6.88073745],\n",
       "       [6.90808228],\n",
       "       [6.67474205],\n",
       "       [6.79375761],\n",
       "       [6.49343381],\n",
       "       [6.93956394],\n",
       "       [6.72846708],\n",
       "       [6.93065395],\n",
       "       [6.58670409],\n",
       "       [6.53413625],\n",
       "       [6.66334032],\n",
       "       [6.91052746],\n",
       "       [6.59293303],\n",
       "       [6.65773099],\n",
       "       [6.53476194],\n",
       "       [6.91538256],\n",
       "       [6.87519008],\n",
       "       [6.68735202],\n",
       "       [6.83417988],\n",
       "       [6.60530435],\n",
       "       [6.83515467],\n",
       "       [6.82511177],\n",
       "       [6.74909316],\n",
       "       [6.61157475],\n",
       "       [6.88974252],\n",
       "       [6.59692417],\n",
       "       [6.86609796],\n",
       "       [6.84931891],\n",
       "       [6.57644709],\n",
       "       [6.51426676],\n",
       "       [6.5584144 ],\n",
       "       [6.75977984],\n",
       "       [6.62655105],\n",
       "       [6.60625948],\n",
       "       [6.64717245],\n",
       "       [6.32720083],\n",
       "       [6.63055831],\n",
       "       [6.93991145],\n",
       "       [6.9134973 ],\n",
       "       [6.71635958],\n",
       "       [6.90633253],\n",
       "       [6.56386702],\n",
       "       [6.87219634],\n",
       "       [6.68817795],\n",
       "       [6.84915362],\n",
       "       [6.82806435],\n",
       "       [6.72658133],\n",
       "       [6.36626309],\n",
       "       [6.74573159],\n",
       "       [6.80809974],\n",
       "       [6.35447168],\n",
       "       [6.58127827],\n",
       "       [6.89443701],\n",
       "       [6.69821408],\n",
       "       [6.89192515],\n",
       "       [6.49053059],\n",
       "       [6.90580566],\n",
       "       [6.59764951],\n",
       "       [6.73275073],\n",
       "       [6.71666452],\n",
       "       [6.49604584],\n",
       "       [6.73289009],\n",
       "       [6.94058143],\n",
       "       [6.59687303],\n",
       "       [6.91073256],\n",
       "       [6.57977681],\n",
       "       [6.52452523],\n",
       "       [6.89488315],\n",
       "       [6.82408085],\n",
       "       [6.889783  ],\n",
       "       [6.32332779],\n",
       "       [6.75633279],\n",
       "       [6.91957887],\n",
       "       [6.64503824],\n",
       "       [6.91233023],\n",
       "       [6.76486567],\n",
       "       [6.32846007],\n",
       "       [6.70612051],\n",
       "       [6.59097591],\n",
       "       [6.86943582],\n",
       "       [6.77510732],\n",
       "       [6.4387168 ],\n",
       "       [6.50331606],\n",
       "       [6.91296258],\n",
       "       [6.79213295],\n",
       "       [6.66712795],\n",
       "       [6.92157936],\n",
       "       [6.65034875],\n",
       "       [6.68380414],\n",
       "       [6.93570717],\n",
       "       [6.62638477],\n",
       "       [6.92357132],\n",
       "       [6.61534679],\n",
       "       [6.90580919],\n",
       "       [6.93540515],\n",
       "       [6.67427538],\n",
       "       [6.65829735],\n",
       "       [6.60695293],\n",
       "       [6.73746597],\n",
       "       [6.60224122],\n",
       "       [6.64953165],\n",
       "       [6.56459757],\n",
       "       [6.40283276],\n",
       "       [6.52406833],\n",
       "       [6.81692544],\n",
       "       [6.65771803],\n",
       "       [6.63216656],\n",
       "       [6.6626682 ],\n",
       "       [6.84001092],\n",
       "       [6.89779893],\n",
       "       [6.51834231],\n",
       "       [6.57465648],\n",
       "       [6.90602901],\n",
       "       [6.59052364],\n",
       "       [6.62841621],\n",
       "       [7.00543577],\n",
       "       [6.89873124],\n",
       "       [6.65092731],\n",
       "       [6.86128076],\n",
       "       [6.6348167 ],\n",
       "       [6.36921848],\n",
       "       [6.61081202],\n",
       "       [6.93188288],\n",
       "       [6.89470974],\n",
       "       [6.53201276],\n",
       "       [6.7338265 ],\n",
       "       [6.86773757],\n",
       "       [6.91258364],\n",
       "       [6.80452624],\n",
       "       [6.42009436],\n",
       "       [6.58707311],\n",
       "       [6.73082005],\n",
       "       [6.49965004],\n",
       "       [6.61851126],\n",
       "       [6.9090478 ],\n",
       "       [6.46801795],\n",
       "       [6.53169698],\n",
       "       [6.72305428],\n",
       "       [6.57255434],\n",
       "       [6.81573231],\n",
       "       [6.75048726],\n",
       "       [6.8809416 ],\n",
       "       [6.52402639],\n",
       "       [6.91338494],\n",
       "       [6.72119206],\n",
       "       [6.38997061],\n",
       "       [6.7950435 ],\n",
       "       [6.91738631],\n",
       "       [6.90132971],\n",
       "       [6.90746028],\n",
       "       [6.72470544],\n",
       "       [6.56440124],\n",
       "       [6.66581036],\n",
       "       [6.57587278],\n",
       "       [6.89109528],\n",
       "       [6.84478212],\n",
       "       [6.90996232],\n",
       "       [6.61509334],\n",
       "       [6.64407474],\n",
       "       [6.38004771],\n",
       "       [6.60102673],\n",
       "       [6.65855559],\n",
       "       [6.88613788],\n",
       "       [6.84332141],\n",
       "       [6.57605429],\n",
       "       [6.54888112],\n",
       "       [6.68617324],\n",
       "       [6.48703858],\n",
       "       [6.83408581],\n",
       "       [6.88837624],\n",
       "       [6.75115463],\n",
       "       [6.53045787],\n",
       "       [6.91607077],\n",
       "       [6.65346838],\n",
       "       [6.88200436]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "      TD    DT\n",
      "TD   0.0  34.0\n",
      "DT  29.0   0.0\n"
     ]
    }
   ],
   "source": [
    "wins_score = np.zeros((len(models), len(models)))\n",
    "\n",
    "metric_to_score = 'f1'\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[metric_to_score]\n",
    "    for i, m1 in enumerate(models):\n",
    "        for j, m2 in enumerate(models[i:]):\n",
    "            if cur_df.loc[m1][metric_to_score] > cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][metric_to_score] < cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = np.array(models)[order_of_models], index=np.array(models)[order_of_models]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
