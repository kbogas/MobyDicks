{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Tensor decomposition for classifcaiton\n",
    "### Date: 29/10/2024\n",
    "### Status: Works out of the box! Interesting idea, as it is a likelihood-based model.\n",
    "### Idea: \n",
    "Fit a PCA on the concat(X, Y) matrix, that is the feature matrix augmented with the class label per sample, generating a matrix of shape: $(Samples \\times Features + 1)$.\n",
    "\n",
    "Then, at test time create two matrices $Y_1 = concat(X_{test}, Ones)$, and $Y_0 = concat(X_{test}, Zeros)$ and score the log-likelihood of each sample, given the PCA-fitted model.\n",
    "\n",
    "The resulting label is $1$ if $Y_1 > Y_0$ else $0$. (i.e. we keep the label of the most-probable configuration for each sample).\n",
    "\n",
    "### Results:\n",
    "34/64 (53%) wins over generic Decision Tree. Not bad.\n",
    "\n",
    "Details:\n",
    "- We keep 90% of the features as projection dimension for PCA\n",
    "- Also experimented to find the optimal number of components by:\n",
    "  - First fitting a PCA with components equal to features and finding the number of components with 90% cummulative variance, and then re-fitting the PCA. Worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "models = ['TD', 'DT']\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state)\n",
    "    \n",
    "    for model_name in models:\n",
    "        time_s = time.time()\n",
    "        if model_name == 'DT':\n",
    "            clf = DecisionTreeClassifier(random_state=random_state)\n",
    "            # clf.fit(X_train, y_train)\n",
    "            # y_probas = clf.predict_proba(X_test)\n",
    "            # y_pred = np.argmax(y_probas, axis=1)\n",
    "            y_pred = cross_val_predict(clf, X, y, cv=cv).astype(int)\n",
    "        \n",
    "        \n",
    "        elif model_name == 'TD':\n",
    "            from sklearn.decomposition import PCA\n",
    "            y_pred = np.empty_like(y)\n",
    "            for train_indices, test_indices in cv.split(X,y):\n",
    "                X_train, y_train = X[train_indices], y[train_indices]\n",
    "                X_test, y_test = X[test_indices], y[test_indices]\n",
    "                \n",
    "                ext = np.hstack((X_train, y_train.reshape(-1,1)))\n",
    "                ext_zeros = np.hstack((X_test, np.zeros_like(y_test).reshape(-1,1)))\n",
    "                ext_ones = np.hstack((X_test, np.ones_like(y_test).reshape(-1,1)))\n",
    "                \n",
    "                tr = PCA(n_components=int(0.9*X_train.shape[1])) # PCA(n_components='mle', svd_solver='full')#\n",
    "                # tr = PCA(n_components=X_train.shape[1])\n",
    "                \n",
    "                # tr.fit(ext)\n",
    "                \n",
    "                # num_important = np.argwhere(tr.explained_variance_ratio_.cumsum() >= 0.8)[0][0] + 1\n",
    "\n",
    "                # tr = PCA(n_components=num_important)\n",
    "                tr.fit(ext)\n",
    "                \n",
    "                print(f\"Will fit on {tr.n_components_}/{X_train.shape[1]} (reduction: {100*(X_train.shape[1] - tr.n_components_)/X_train.shape[1]:.2f} %)\")\n",
    "                \n",
    "                zeros_tr = tr.score_samples(ext_zeros)\n",
    "                ones_tr = tr.score_samples(ext_ones)\n",
    "                exp_ll = np.exp(np.vstack((zeros_tr, ones_tr)))\n",
    "                y_pred_cur = (exp_ll[1,:] > exp_ll[0,:]).astype(int)\n",
    "                y_pred[test_indices] = y_pred_cur\n",
    "            #y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "      TD    DT\n",
      "TD   0.0  34.0\n",
      "DT  29.0   0.0\n"
     ]
    }
   ],
   "source": [
    "wins_score = np.zeros((len(models), len(models)))\n",
    "\n",
    "metric_to_score = 'f1'\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[metric_to_score]\n",
    "    for i, m1 in enumerate(models):\n",
    "        for j, m2 in enumerate(models[i:]):\n",
    "            if cur_df.loc[m1][metric_to_score] > cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][metric_to_score] < cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = np.array(models)[order_of_models], index=np.array(models)[order_of_models]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "prime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
