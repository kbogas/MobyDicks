{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Sample weights based on difficutly\n",
    "### Date: 12/6/2025\n",
    "### Status: Better scores on 20/33, worst on 10/33 rest are the same over RF with same learning params. More time needed obvs.\n",
    "### Idea: \n",
    "\n",
    "1) First run an RF classifier on the train data (let's say with fixed n_estimators=n=100, max_depth=d=5). IN this classifier there will be n trees, each of which will have at most 2**d leaves.\n",
    "\n",
    "2) Then use this RF classifier to embed each training (and at inference, test) sample by passing the sample down the tree and keeping track of which leaf node the tree lands on. Essentially for each tree we have a number ranging from 1 to 2**d indicating the leaf node (per some order). So in total we will have n such numbers as embedding for each sample (or nxd matrix if we ohe them, but i don't think it is needed with the following order i will propose).\n",
    "\n",
    "3) In order to ascertain a specific order of leaves for each node, we will sort them according to the percentage of samples that exist in each leaf node (based on fitting on the train set), so leaf node 0 will be the one with the most samples of class 0 in it, leaf node 1 the one with the second most samples of class 0 etc, while leaf node 2**d will be the the most populated by class 1 samples. So with this order in place there is a relative meaning to a sample getting assigned to a leaf node from 1 to 2**d, where 1 means most probably a 0 while 2**d means most probably a class 1 sample, according to the tree at hand. Obviously this process must be done for each tree separately.\n",
    "\n",
    "4) With 2,3 in place essentially for each train sample we embed it to a 1xn vector with values ranging from 1 to 2**d, where each feature value now indicates how probable it is is according to each tree.\n",
    "\n",
    "5) Now on top of that embedding, I want to have an NN, let's use what is the sota as an MLP architecture which takes as input the embedded samples, maybe concatenated as well with the original feature samples) and it is fitted using torch. \n",
    "\n",
    "\n",
    "### Results:\n",
    "Run versus RF with the same number of trees (100) and fixed max_depth Νονε.\n",
    "\n",
    "Tree with concatenation was better 20/33 datasets, lost 10/33 and the same on the rest.\n",
    "\n",
    "So we have **better performance on average, 6 times the time needed though (4 seconds vs 24 seconds)**\n",
    "\n",
    "\n",
    "\n",
    "### Comments on results:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "xd6 (1/74)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "--- Fitting Random Forest ---\n",
      "--- Creating Leaf Probability Embeddings ---\n",
      "--- Transforming Data with Forest ---\n",
      "--- Fitting MLP (Input Dim: 100) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ec161d0b8643c5963c1f630050c686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kbougatiotis/miniconda3/envs/peft/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_conn\n",
       "ector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kbougatiotis/miniconda3/envs/peft/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_conn\n",
       "ector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kbougatiotis/miniconda3/envs/peft/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_conn\n",
       "ector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kbougatiotis/miniconda3/envs/peft/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_conn\n",
       "ector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "from sklearn.base import clone\n",
    "from tree_embedding_nn import TreeNetClassifier\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "pl.seed_everything(random_state)\n",
    "\n",
    "\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "    # & (dataset_df[\"n_features\"] >= 10)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"][:]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "models = {\n",
    "    \"Baseline\": {},\n",
    "    \"Tree_NN\": {'concat':False},\n",
    "    \"Tree_NN_Concat\": {'concat':True},\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "num_estimators = 100\n",
    "max_depth = 10\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "base_class = RandomForestClassifier(n_estimators=num_estimators, max_depth=max_depth, random_state=42)\n",
    "  ##DecisionTreeClassifier(max_depth=None, random_state=42)#\n",
    "\n",
    "res = [] \n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:2]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    if 'deprecated' in classification_dataset:\n",
    "        print(f\"Skipping {classification_dataset} as deprecated from PMLB...\")\n",
    "        continue\n",
    "    try:\n",
    "        X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    except ValueError as e:\n",
    "        print(f'Probably not found dataset {classification_dataset} in PMLB and skipping...\\n {e}')\n",
    "        continue\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "\n",
    "    for model_name, model_kwargs in models.items():\n",
    "        y_pred = np.empty_like(y)\n",
    "        sample_weights = None\n",
    "        time_s = time.time()\n",
    "        for train_indices, test_indices in cv.split(X,y):\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            X_test, y_test = X[test_indices], y[test_indices]\n",
    "            \n",
    "            X_train_filtered = X_train.copy()\n",
    "            y_train_filtered = y_train.copy()\n",
    "            if model_name.startswith(\"Tree_NN\"):\n",
    "                clf = TreeNetClassifier(\n",
    "                    n_estimators=num_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    mlp_hidden_dims=[32, 16],\n",
    "                    lr=0.005,\n",
    "                    epochs=100,\n",
    "                    patience=3,\n",
    "                    batch_size=256,\n",
    "                    check_val_every_n_epoch = 5,\n",
    "                    concat_original_features=model_kwargs['concat'],  # Try with False to see the difference\n",
    "                    device=\"auto\",\n",
    "                )\n",
    "            else:\n",
    "                clf = clone(base_class)\n",
    "            #print(model_name, X_train_filtered.shape[0])\n",
    "            clf.fit(X_train_filtered , y_train_filtered)\n",
    "            y_pred_cur = clf.predict(X_test)\n",
    "\n",
    "            y_pred[test_indices] = y_pred_cur\n",
    "            #print(f'TRUE', y_test)\n",
    "            \n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique datasets: 33\n",
      "            model      rank\n",
      "2  Tree_NN_Concat  1.636364\n",
      "0        Baseline  2.060606\n",
      "1         Tree_NN  2.303030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_952666/98381570.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "res = pd.read_csv(\"./results/tree_emb_res_depth_None.csv\")\n",
    "print(f'# of unique datasets: {res[\"dataset\"].unique().shape[0]}')\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "Baseline           3.399176\n",
       "Tree_NN           19.656898\n",
       "Tree_NN_Concat    23.027129\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.groupby('model')['time'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "                Tree_NN_Concat  Baseline  Tree_NN\n",
      "Tree_NN_Concat             0.0      20.0     25.0\n",
      "Baseline                  10.0       0.0     17.0\n",
      "Tree_NN                    7.0      15.0      0.0\n"
     ]
    }
   ],
   "source": [
    "model_names = res['model'].unique()\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "metric_to_score = 'f1'\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[metric_to_score]\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1][metric_to_score] > cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][metric_to_score] < cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "# Uncomment this for percentage wins\n",
    "# wins_score /= res['dataset'].unique().shape[0]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = model_names[order_of_models], index=model_names[order_of_models]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
