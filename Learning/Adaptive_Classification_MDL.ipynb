{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Adaptive-collective classification\n",
    "### Date: 18/7/2024\n",
    "### Status: Need to work on the idea more.\n",
    "### Idea: (on binary classification)\n",
    "The idea was to fit LRs/simple DTs on subsets that are easily distinguisable betwen them. Afterwards we would only have to select the correct classifier to predict each sample at inference time.\n",
    "\n",
    "Conceptually this is related to other ideas/questions as well:\n",
    "1. Can we split a given training dataset to multiple sets that are linearly separable? This seems too PAC-related and was not really confident to tackle this.\n",
    "2. For finding the correct classifier adaptively for each sample thought of the following:\n",
    "   1. First thought of something like check whether taking a step/partial fit with the sample to infer would change the original weights/model.\n",
    "      1. The problem with this approach is that we need to have the label of the sample to infer (obv. unknown).\n",
    "      2. To tackle the previous I created the **MDL** classifier. We essentially re-train 2 classifiers, one with the full-training + (the query sample, pos) and the second with the full-training + (the query sample, neg).\n",
    "      3. Then we count how much the model was changed:\n",
    "         1. One way is to count the differences in model weights/feature importances_ (did not work well) -- MODEL BASED.\n",
    "         2. Better yet was to count the number of changes against the original predictions (worked ok) -- PERF BASED.\n",
    "         3. Better yet is to count the change in accuracy (because the original predictionc could be wrong) (worked ok) -- PERF BASED.\n",
    "         4. Tried also to check whether it changed the max_depth (with max_depth = None) (works ok) -- MODEL BASED.W\n",
    "      4. **DOES NOT WORK**\n",
    "   2. Then we could do something distance based on the original training samples.\n",
    "      1. We can think of things related to knn-graphs and label smoothness on the graph, except for distance based things.\n",
    "\n",
    "A surrogate solution I started working on was:\n",
    "\n",
    "1. Iteratively do the following during training (start with the full dataset):\n",
    "   1. On the remaining samples, fit a simple (LR/bounded DT).\n",
    "   2. Remove the correctly classified ones and repeat the process creating a new classifier\n",
    "   3. Break the loop when all samples can be correctly classified by the respective classifier (or there is a very small number left miss-classified)\n",
    "2. At inference time for each sample:\n",
    "   1. We need to find the correct classifier to make the prediction.\n",
    "      1. Iterate over the classifiers keeping their weights and updating them with a partial fit on the query sample.\n",
    "      2. Whichever classifier does not change it's previous predictions (on the training samples) is the most suitable and used for prediction.\n",
    "      3. **THIS IS INCOMPLETE**\n",
    "      4. As a surrogate we can take the mean prediction of the classifiers in  bagging fashion.\n",
    "\n",
    "\n",
    "### Results:\n",
    "1. Created a (wrong, probably) implementation of the Normal Equation for classification (**NE_CLF**). Need to check the logit/expit functions.\n",
    "2. The **MDL** classifier:\n",
    "   1. Fit a bounded DT on the whole dataset.\n",
    "   2. At inference time, re-fit two DTs similar to the original using the full training set + the sample with pos and neg label.\n",
    "   3. Count the changes this created. In case the change for the positive label was bigger then infer negative and vice-versa.\n",
    "   4. If no changes keep the original prediction.\n",
    "   5. **IS NOT BETTER**\n",
    "3. The **Cascader** is the incomplete version of the main idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmlb import fetch_data\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       212\n",
      "           1       0.93      0.95      0.94       357\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.92      0.91      0.92       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n",
      "[[186  26]\n",
      " [ 18 339]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=None)\n",
    "# y_pred = cross_val_predict(clf, X, y, cv=cv)\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos->neg': 2, 'neg->pos': 2, 'pos->pos': 7, 'neg->neg': 1, 'same': 45}\n",
      "{'pos->neg': 1, 'neg->pos': 0, 'pos->pos': 1, 'neg->neg': 0, 'same': 55}\n",
      "{'pos->neg': 3, 'neg->pos': 1, 'pos->pos': 1, 'neg->neg': 1, 'same': 51}\n",
      "{'pos->neg': 4, 'neg->pos': 2, 'pos->pos': 3, 'neg->neg': 1, 'same': 47}\n",
      "{'pos->neg': 5, 'neg->pos': 0, 'pos->pos': 2, 'neg->neg': 5, 'same': 45}\n",
      "{'pos->neg': 3, 'neg->pos': 1, 'pos->pos': 1, 'neg->neg': 1, 'same': 51}\n",
      "{'pos->neg': 5, 'neg->pos': 2, 'pos->pos': 1, 'neg->neg': 0, 'same': 49}\n",
      "{'pos->neg': 6, 'neg->pos': 3, 'pos->pos': 3, 'neg->neg': 5, 'same': 40}\n",
      "{'pos->neg': 1, 'neg->pos': 0, 'pos->pos': 14, 'neg->neg': 10, 'same': 32}\n",
      "{'pos->neg': 0, 'neg->pos': 0, 'pos->pos': 4, 'neg->neg': 10, 'same': 42}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       212\n",
      "           1       0.92      0.89      0.91       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.88      0.89      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[186  26]\n",
      " [ 38 319]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class MDL(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, clf=DecisionTreeClassifier(max_depth=3, random_state=42)):\n",
    "        self.base_clf = clf\n",
    "        self.clf = []\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.orig_pred = []\n",
    "        self.metric_to_use = accuracy_score\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.clf = clone(self.base_clf)\n",
    "        self.clf.fit(X, y)\n",
    "        self.orig_pred = self.clf.predict(X)\n",
    "        self.orig_score = self.metric_to_use(y, self.orig_pred)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        preds = []\n",
    "        count_changed = {'pos->neg':0, 'neg->pos':0, 'pos->pos':0, 'neg->neg':0, 'same':0}\n",
    "        preds_test = self.clf.predict(X)\n",
    "        res = []\n",
    "        \n",
    "        for i_x, x in enumerate(X):\n",
    "            cur_pred = preds_test[i_x]\n",
    "            \n",
    "            X_aug = np.vstack((self.X, x.reshape(1,-1)))\n",
    "            y_aug_neg = np.concatenate((self.y, np.array([0])))\n",
    "            y_aug_pos = np.concatenate((self.y, np.array([1])))\n",
    "            \n",
    "            clf_pos = clone(self.base_clf)\n",
    "            clf_pos.fit(X_aug, y_aug_pos)\n",
    "            #counts_diff_pos = ((clf_pos.feature_importances_-self.clf.feature_importances_)**2).sum()\n",
    "            y_pos_new = clf_pos.predict(self.X)\n",
    "            #counts_diff_pos = (y_pos_new != self.orig_pred).sum()\n",
    "            counts_diff_pos = int((1 - f1_score(self.y, y_pos_new))*len(self.y))\n",
    "            #diff_acc_pos = self.metric_to_use(self.y, y_pos_new) - self.orig_score #self.clf.tree_.max_depth - clf_pos.tree_.max_depth #\n",
    "            \n",
    "            clf_neg = clone(self.base_clf)\n",
    "            clf_neg.fit(X_aug, y_aug_neg)\n",
    "            #counts_diff_neg = ((clf_neg.feature_importances_-self.clf.feature_importances_)**2).sum()\n",
    "            y_neg_new = clf_neg.predict(self.X)\n",
    "            #counts_diff_neg = (y_neg_new != self.orig_pred).sum()\n",
    "            counts_diff_neg = int((1 - f1_score(self.y, y_neg_new))*len(self.y))\n",
    "            #diff_acc_neg = self.metric_to_use(self.y, y_neg_new) - self.orig_score# self.clf.tree_.max_depth - clf_neg.tree_.max_depth #\n",
    "            change = \"\"\n",
    "            #if diff_acc_pos < diff_acc_neg:\n",
    "            if counts_diff_pos > counts_diff_neg:\n",
    "                if cur_pred == 1:\n",
    "                    count_changed['pos->neg'] += 1\n",
    "                    change = \"pos->neg\"\n",
    "                else:\n",
    "                    count_changed['neg->neg'] += 1\n",
    "                    change = \"neg->neg\"\n",
    "                cur_pred = 0\n",
    "                #print(f'POS CHANGED: {counts_diff_pos} > NEG CHANGED: {counts_diff_neg} -> NEG')\n",
    "                \n",
    "             \n",
    "            #elif diff_acc_pos > diff_acc_neg:\n",
    "            elif counts_diff_pos < counts_diff_neg:\n",
    "                if cur_pred == 0:\n",
    "                    count_changed['neg->pos'] += 1\n",
    "                    change = \"neg->pos\"\n",
    "                else:\n",
    "                    count_changed['pos->pos'] += 1\n",
    "                    change = 'pos->pos'\n",
    "                cur_pred = 1\n",
    "                #print(f'POS CHANGED: {counts_diff_pos} < NEG CHANGED: {counts_diff_neg} -> POS')\n",
    "            else:\n",
    "                count_changed['same'] += 1\n",
    "                change = 'same'\n",
    "            preds.append(cur_pred)\n",
    "            res.append((i_x, y[i_x], preds_test[i_x], cur_pred, change))\n",
    "        print(count_changed)\n",
    "            \n",
    "        return np.array(preds), res\n",
    "            \n",
    "\n",
    "# clf = MDL(clf=DecisionTreeClassifier(max_depth=2, random_state=42))#DecisionTreeClassifier(max_depth=3, random_state=42))\n",
    "# clf.fit(X,y)\n",
    "# y_pred = clf.predict(X)\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "res_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    clf = MDL(clf=DecisionTreeClassifier(max_depth=5, random_state=42))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred, res = clf.predict(X_test, y_test)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    res_all.extend(res)\n",
    "    \n",
    "# y_pred = cross_val_predict(clf, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "neg->pos    4\n",
       "pos->neg    4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_df = pd.DataFrame(res_all, columns=['index', 'label', 'orig', 'final', 'status'])\n",
    "res_all_df[(res_all_df['label'] !=res_all_df['orig']) & (res_all_df['label'] != res_all_df['final'])]['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 3 clfs...\n",
      "Fitted 3 clfs...\n",
      "Fitted 3 clfs...\n",
      "Fitted 2 clfs...\n",
      "Fitted 3 clfs...\n",
      "Fitted 2 clfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f0ba4661910>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "\n",
    "class Dummy(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.array([self.label for x in X])\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return logit(self.predict_proba(X))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)\n",
    "\n",
    "class NE_CLF(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        A = np.hstack([X, np.ones(X.shape[0]).reshape(-1,1)])\n",
    "        all_coefs = np.linalg.lstsq(A, y)[0]\n",
    "        self.coef_ = all_coefs[:-1]\n",
    "        self.intercept_ = all_coefs[-1]\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        probas = expit(X @ self.coef_.T + self.intercept_)\n",
    "        return probas\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5).astype(int)\n",
    "        \n",
    "\n",
    "class Cascader(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 clf=SGDClassifier(random_state=42, n_jobs=1),\n",
    "                 acceptable_miss_ratio=0.01#loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None\n",
    "                 ):\n",
    "        self.clf = clf\n",
    "        self.clfs = []\n",
    "        self.orig_preds = []\n",
    "        self.acceptable_miss_ratio = acceptable_miss_ratio\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        missed_samples = np.arange(X.shape[0])\n",
    "        acceptable_number_of_missed_training_samples = int(self.acceptable_miss_ratio*X.shape[0])\n",
    "        while len(missed_samples) > acceptable_number_of_missed_training_samples:\n",
    "            if np.bincount(y[missed_samples]).shape[0] == 1:\n",
    "                cur_clf = Dummy(label=y[0])\n",
    "                pred = y[missed_samples]\n",
    "                #break\n",
    "            else:\n",
    "                cur_clf = clone(self.clf)\n",
    "                #print(len(missed_samples), np.bincount(y[missed_samples]))\n",
    "                cur_clf.fit(X[missed_samples], y[missed_samples])\n",
    "                pred = cur_clf.predict(X[missed_samples])\n",
    "                # print(pred, y)\n",
    "                missed_samples = np.where(pred !=  y[missed_samples])[0]\n",
    "                #print(missed_samples)\n",
    "            self.clfs.append(cur_clf)\n",
    "            self.orig_preds.append(pred)\n",
    "        print(f'Fitted {len(self.clfs)} clfs...')\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = []\n",
    "        # for clf in self.clfs:\n",
    "        #     try:\n",
    "        #         cur_probas = expit(clf.decision_function(X))\n",
    "        #     except AttributeError:\n",
    "        #         cur_probas = clf.predict_proba(X)[:,1]\n",
    "        #     probas.append(cur_probas)\n",
    "            \n",
    "        # probas = np.array(probas).T\n",
    "        # probas = probas.mean(axis=1)\n",
    "        \n",
    "        # return probas\n",
    "        \n",
    "        for x in X:\n",
    "            cur_proba = -1\n",
    "            # for clf_index, clf in enumerate(self.clfs):\n",
    "            #     clf_backup = clone(self.clf)\n",
    "                \n",
    "            #     clf_backup.coef_ = clf.coef_\n",
    "            #     clf_backup.intercept_ = clf.intercept_\n",
    "            #     clf_backup.classes_ = clf.classes_\n",
    "                \n",
    "            #     orig_preds = self.orig_preds[clf_index]\n",
    "                \n",
    "            #     clf.partial_fit(x.reshape(1,-1))\n",
    "            #     new_preds = clf.predict(self.X)\n",
    "                \n",
    "            #     self.clfs[clf_index] = clf_backup\n",
    "            #     if all(orig_preds == new_preds): \n",
    "            #         cur_proba = clf_backup.decision_function(x.reshape(1,-1))[0]\n",
    "            #         break\n",
    "            if cur_proba == -1:\n",
    "                cur_proba = np.mean([expit(clf.decision_function(x.reshape(1,-1))[0]) for clf in self.clfs])\n",
    "            probas.append(cur_proba)\n",
    "        return np.array(probas)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        preds = (probas > 0.5).astype(int)\n",
    "        #print(preds)\n",
    "        return preds\n",
    "\n",
    "# clf = Cascader(clf=DecisionTreeClassifier(max_depth=3, random_state=42))#DecisionTreeClassifier(max_depth=3, random_state=42))\n",
    "# clf.fit(X,y)\n",
    "# clf.predict(X)\n",
    "\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    clf= Cascader(\n",
    "        clf=SGDClassifier(random_state=42),\n",
    "        acceptable_miss_ratio=0.005\n",
    "        )\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    \n",
    "# y_pred = cross_val_predict(clf, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))   \n",
    "\n",
    "#y_pred = cross_val_predict(clf, X, y, cv=5, n_jobs=1)\n",
    "            # no classifier could fit it\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "clf.fit(X, y)\n",
    "missed_samples = (clf.predict(X) != y)\n",
    "missed_samples.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
