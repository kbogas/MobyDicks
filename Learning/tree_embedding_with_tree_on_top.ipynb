{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "xd6 (1/74)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "tokyo1 (2/74)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       346\n",
      "           1       0.94      0.95      0.94       613\n",
      "\n",
      "    accuracy                           0.93       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.93      0.93      0.93       959\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       346\n",
      "           1       0.94      0.94      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       346\n",
      "           1       0.94      0.94      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       346\n",
      "           1       0.94      0.94      0.94       613\n",
      "\n",
      "    accuracy                           0.93       959\n",
      "   macro avg       0.92      0.92      0.92       959\n",
      "weighted avg       0.93      0.93      0.93       959\n",
      "\n",
      "tic_tac_toe (3/74)\n",
      "(958, 9) with ratio : 1.8855\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93       332\n",
      "           1       0.94      1.00      0.97       626\n",
      "\n",
      "    accuracy                           0.96       958\n",
      "   macro avg       0.97      0.94      0.95       958\n",
      "weighted avg       0.96      0.96      0.96       958\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92       332\n",
      "           1       0.93      0.99      0.96       626\n",
      "\n",
      "    accuracy                           0.95       958\n",
      "   macro avg       0.96      0.93      0.94       958\n",
      "weighted avg       0.95      0.95      0.94       958\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92       332\n",
      "           1       0.93      0.99      0.96       626\n",
      "\n",
      "    accuracy                           0.95       958\n",
      "   macro avg       0.96      0.93      0.94       958\n",
      "weighted avg       0.95      0.95      0.94       958\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       332\n",
      "           1       0.99      1.00      1.00       626\n",
      "\n",
      "    accuracy                           1.00       958\n",
      "   macro avg       1.00      0.99      1.00       958\n",
      "weighted avg       1.00      1.00      1.00       958\n",
      "\n",
      "threeOf9 (4/74)\n",
      "(512, 9) with ratio : 1.1513\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       274\n",
      "           1       0.98      1.00      0.99       238\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.99      0.99       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       274\n",
      "           1       0.98      1.00      0.99       238\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.99      0.99       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       274\n",
      "           1       0.98      1.00      0.99       238\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.99      0.99       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       274\n",
      "           1       1.00      1.00      1.00       238\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n",
      "spectf (5/74)\n",
      "(349, 44) with ratio : 2.6737\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82        95\n",
      "           1       0.92      0.95      0.94       254\n",
      "\n",
      "    accuracy                           0.91       349\n",
      "   macro avg       0.89      0.87      0.88       349\n",
      "weighted avg       0.91      0.91      0.91       349\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        95\n",
      "           1       0.93      0.95      0.94       254\n",
      "\n",
      "    accuracy                           0.91       349\n",
      "   macro avg       0.90      0.88      0.89       349\n",
      "weighted avg       0.91      0.91      0.91       349\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        95\n",
      "           1       0.93      0.95      0.94       254\n",
      "\n",
      "    accuracy                           0.91       349\n",
      "   macro avg       0.90      0.88      0.89       349\n",
      "weighted avg       0.91      0.91      0.91       349\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        95\n",
      "           1       0.94      0.92      0.93       254\n",
      "\n",
      "    accuracy                           0.90       349\n",
      "   macro avg       0.87      0.88      0.87       349\n",
      "weighted avg       0.90      0.90      0.90       349\n",
      "\n",
      "spect (6/74)\n",
      "(267, 22) with ratio : 3.8545\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.51        55\n",
      "           1       0.87      0.91      0.89       212\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.72      0.68      0.70       267\n",
      "weighted avg       0.80      0.82      0.81       267\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.49      0.50        55\n",
      "           1       0.87      0.88      0.88       212\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.69      0.69      0.69       267\n",
      "weighted avg       0.80      0.80      0.80       267\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.38      0.44        55\n",
      "           1       0.85      0.91      0.88       212\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.69      0.65      0.66       267\n",
      "weighted avg       0.78      0.80      0.79       267\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.60      0.55        55\n",
      "           1       0.89      0.85      0.87       212\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.70      0.73      0.71       267\n",
      "weighted avg       0.81      0.80      0.81       267\n",
      "\n",
      "sonar (7/74)\n",
      "(208, 60) with ratio : 1.1443\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       111\n",
      "           1       0.88      0.75      0.81        97\n",
      "\n",
      "    accuracy                           0.84       208\n",
      "   macro avg       0.84      0.83      0.83       208\n",
      "weighted avg       0.84      0.84      0.84       208\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       111\n",
      "           1       0.88      0.75      0.81        97\n",
      "\n",
      "    accuracy                           0.84       208\n",
      "   macro avg       0.84      0.83      0.83       208\n",
      "weighted avg       0.84      0.84      0.84       208\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       111\n",
      "           1       0.88      0.75      0.81        97\n",
      "\n",
      "    accuracy                           0.84       208\n",
      "   macro avg       0.84      0.83      0.83       208\n",
      "weighted avg       0.84      0.84      0.84       208\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       111\n",
      "           1       0.82      0.82      0.82        97\n",
      "\n",
      "    accuracy                           0.83       208\n",
      "   macro avg       0.83      0.83      0.83       208\n",
      "weighted avg       0.83      0.83      0.83       208\n",
      "\n",
      "saheart (8/74)\n",
      "(462, 9) with ratio : 1.8875\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       302\n",
      "           1       0.57      0.41      0.47       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.65      0.62      0.62       462\n",
      "weighted avg       0.67      0.69      0.67       462\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       302\n",
      "           1       0.58      0.42      0.49       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.65      0.63      0.63       462\n",
      "weighted avg       0.68      0.69      0.68       462\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       302\n",
      "           1       0.57      0.42      0.48       160\n",
      "\n",
      "    accuracy                           0.69       462\n",
      "   macro avg       0.65      0.63      0.63       462\n",
      "weighted avg       0.68      0.69      0.68       462\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       302\n",
      "           1       0.53      0.48      0.50       160\n",
      "\n",
      "    accuracy                           0.67       462\n",
      "   macro avg       0.63      0.63      0.63       462\n",
      "weighted avg       0.66      0.67      0.67       462\n",
      "\n",
      "profb (9/74)\n",
      "(672, 9) with ratio : 2.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78       448\n",
      "           1       0.52      0.27      0.35       224\n",
      "\n",
      "    accuracy                           0.67       672\n",
      "   macro avg       0.61      0.57      0.57       672\n",
      "weighted avg       0.64      0.67      0.64       672\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       448\n",
      "           1       0.56      0.31      0.40       224\n",
      "\n",
      "    accuracy                           0.69       672\n",
      "   macro avg       0.64      0.59      0.59       672\n",
      "weighted avg       0.66      0.69      0.66       672\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       448\n",
      "           1       0.56      0.31      0.40       224\n",
      "\n",
      "    accuracy                           0.69       672\n",
      "   macro avg       0.64      0.59      0.59       672\n",
      "weighted avg       0.66      0.69      0.66       672\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       448\n",
      "           1       0.46      0.39      0.42       224\n",
      "\n",
      "    accuracy                           0.65       672\n",
      "   macro avg       0.59      0.58      0.58       672\n",
      "weighted avg       0.63      0.65      0.64       672\n",
      "\n",
      "prnn_synth (10/74)\n",
      "(250, 2) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       125\n",
      "           1       0.84      0.83      0.84       125\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.84      0.84       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       125\n",
      "           1       0.83      0.83      0.83       125\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.83      0.83      0.83       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       125\n",
      "           1       0.83      0.83      0.83       125\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.83      0.83      0.83       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       125\n",
      "           1       0.83      0.85      0.84       125\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.84      0.84       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n",
      "prnn_crabs (11/74)\n",
      "(200, 7) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       100\n",
      "           1       0.95      0.93      0.94       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       100\n",
      "           1       0.95      0.95      0.95       100\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.95       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       100\n",
      "           1       0.94      0.96      0.95       100\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.95       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       100\n",
      "           1       0.93      0.96      0.95       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.95      0.94       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n",
      "postoperative_patient_data (12/74)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        64\n",
      "           1       0.10      0.04      0.06        24\n",
      "\n",
      "    accuracy                           0.64        88\n",
      "   macro avg       0.40      0.45      0.42        88\n",
      "weighted avg       0.54      0.64      0.58        88\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76        64\n",
      "           1       0.08      0.04      0.06        24\n",
      "\n",
      "    accuracy                           0.61        88\n",
      "   macro avg       0.39      0.43      0.41        88\n",
      "weighted avg       0.53      0.61      0.57        88\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76        64\n",
      "           1       0.08      0.04      0.06        24\n",
      "\n",
      "    accuracy                           0.61        88\n",
      "   macro avg       0.39      0.43      0.41        88\n",
      "weighted avg       0.53      0.61      0.57        88\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71        64\n",
      "           1       0.06      0.04      0.05        24\n",
      "\n",
      "    accuracy                           0.56        88\n",
      "   macro avg       0.37      0.40      0.38        88\n",
      "weighted avg       0.51      0.56      0.53        88\n",
      "\n",
      "parity5 (13/74)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      16.0\n",
      "           1       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00      32.0\n",
      "   macro avg       0.00      0.00      0.00      32.0\n",
      "weighted avg       0.00      0.00      0.00      32.0\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      16.0\n",
      "           1       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00      32.0\n",
      "   macro avg       0.00      0.00      0.00      32.0\n",
      "weighted avg       0.00      0.00      0.00      32.0\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      16.0\n",
      "           1       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00      32.0\n",
      "   macro avg       0.00      0.00      0.00      32.0\n",
      "weighted avg       0.00      0.00      0.00      32.0\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      16.0\n",
      "           1       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00      32.0\n",
      "   macro avg       0.00      0.00      0.00      32.0\n",
      "weighted avg       0.00      0.00      0.00      32.0\n",
      "\n",
      "mux6 (14/74)\n",
      "(128, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        64\n",
      "           1       0.97      0.91      0.94        64\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.94      0.94      0.94       128\n",
      "weighted avg       0.94      0.94      0.94       128\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        64\n",
      "           1       0.97      0.91      0.94        64\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.94      0.94      0.94       128\n",
      "weighted avg       0.94      0.94      0.94       128\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        64\n",
      "           1       0.97      0.91      0.94        64\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.94      0.94      0.94       128\n",
      "weighted avg       0.94      0.94      0.94       128\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        64\n",
      "           1       0.97      0.94      0.95        64\n",
      "\n",
      "    accuracy                           0.95       128\n",
      "   macro avg       0.95      0.95      0.95       128\n",
      "weighted avg       0.95      0.95      0.95       128\n",
      "\n",
      "monk3 (15/74)\n",
      "(554, 6) with ratio : 1.0827\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       266\n",
      "           1       0.98      0.97      0.97       288\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       266\n",
      "           1       0.98      0.97      0.98       288\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       266\n",
      "           1       0.98      0.97      0.98       288\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       266\n",
      "           1       0.98      0.99      0.98       288\n",
      "\n",
      "    accuracy                           0.98       554\n",
      "   macro avg       0.98      0.98      0.98       554\n",
      "weighted avg       0.98      0.98      0.98       554\n",
      "\n",
      "monk2 (16/74)\n",
      "(601, 6) with ratio : 1.9175\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       395\n",
      "           1       0.98      0.83      0.89       206\n",
      "\n",
      "    accuracy                           0.93       601\n",
      "   macro avg       0.95      0.91      0.92       601\n",
      "weighted avg       0.94      0.93      0.93       601\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       395\n",
      "           1       0.98      0.83      0.90       206\n",
      "\n",
      "    accuracy                           0.94       601\n",
      "   macro avg       0.95      0.91      0.93       601\n",
      "weighted avg       0.94      0.94      0.93       601\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       395\n",
      "           1       0.98      0.83      0.90       206\n",
      "\n",
      "    accuracy                           0.94       601\n",
      "   macro avg       0.95      0.91      0.93       601\n",
      "weighted avg       0.94      0.94      0.93       601\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       395\n",
      "           1       0.98      0.96      0.97       206\n",
      "\n",
      "    accuracy                           0.98       601\n",
      "   macro avg       0.98      0.97      0.98       601\n",
      "weighted avg       0.98      0.98      0.98       601\n",
      "\n",
      "monk1 (17/74)\n",
      "(556, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       278\n",
      "           1       1.00      0.97      0.98       278\n",
      "\n",
      "    accuracy                           0.98       556\n",
      "   macro avg       0.98      0.98      0.98       556\n",
      "weighted avg       0.98      0.98      0.98       556\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       278\n",
      "           1       1.00      0.96      0.98       278\n",
      "\n",
      "    accuracy                           0.98       556\n",
      "   macro avg       0.98      0.98      0.98       556\n",
      "weighted avg       0.98      0.98      0.98       556\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       278\n",
      "           1       1.00      0.96      0.98       278\n",
      "\n",
      "    accuracy                           0.98       556\n",
      "   macro avg       0.98      0.98      0.98       556\n",
      "weighted avg       0.98      0.98      0.98       556\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       556\n",
      "   macro avg       1.00      1.00      1.00       556\n",
      "weighted avg       1.00      1.00      1.00       556\n",
      "\n",
      "molecular_biology_promoters (18/74)\n",
      "(106, 57) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        53\n",
      "           1       0.90      0.87      0.88        53\n",
      "\n",
      "    accuracy                           0.89       106\n",
      "   macro avg       0.89      0.89      0.89       106\n",
      "weighted avg       0.89      0.89      0.89       106\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        53\n",
      "           1       0.90      0.87      0.88        53\n",
      "\n",
      "    accuracy                           0.89       106\n",
      "   macro avg       0.89      0.89      0.89       106\n",
      "weighted avg       0.89      0.89      0.89       106\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        53\n",
      "           1       0.90      0.87      0.88        53\n",
      "\n",
      "    accuracy                           0.89       106\n",
      "   macro avg       0.89      0.89      0.89       106\n",
      "weighted avg       0.89      0.89      0.89       106\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        53\n",
      "           1       0.89      0.89      0.89        53\n",
      "\n",
      "    accuracy                           0.89       106\n",
      "   macro avg       0.89      0.89      0.89       106\n",
      "weighted avg       0.89      0.89      0.89       106\n",
      "\n",
      "lupus (19/74)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74        52\n",
      "           1       0.61      0.57      0.59        35\n",
      "\n",
      "    accuracy                           0.68        87\n",
      "   macro avg       0.66      0.66      0.66        87\n",
      "weighted avg       0.68      0.68      0.68        87\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70        52\n",
      "           1       0.56      0.54      0.55        35\n",
      "\n",
      "    accuracy                           0.64        87\n",
      "   macro avg       0.63      0.63      0.63        87\n",
      "weighted avg       0.64      0.64      0.64        87\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        52\n",
      "           1       0.61      0.54      0.58        35\n",
      "\n",
      "    accuracy                           0.68        87\n",
      "   macro avg       0.66      0.66      0.66        87\n",
      "weighted avg       0.67      0.68      0.67        87\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70        52\n",
      "           1       0.56      0.57      0.56        35\n",
      "\n",
      "    accuracy                           0.64        87\n",
      "   macro avg       0.63      0.63      0.63        87\n",
      "weighted avg       0.65      0.64      0.64        87\n",
      "\n",
      "labor (20/74)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        20\n",
      "           1       0.97      0.89      0.93        37\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.90      0.92      0.91        57\n",
      "weighted avg       0.92      0.91      0.91        57\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        20\n",
      "           1       0.97      0.89      0.93        37\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.90      0.92      0.91        57\n",
      "weighted avg       0.92      0.91      0.91        57\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        20\n",
      "           1       0.97      0.89      0.93        37\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.90      0.92      0.91        57\n",
      "weighted avg       0.92      0.91      0.91        57\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        20\n",
      "           1       0.94      0.89      0.92        37\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.88      0.90      0.89        57\n",
      "weighted avg       0.90      0.89      0.90        57\n",
      "\n",
      "irish (21/74)\n",
      "(500, 5) with ratio : 1.2523\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "ionosphere (22/74)\n",
      "(351, 34) with ratio : 1.7857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       126\n",
      "           1       0.94      0.96      0.95       225\n",
      "\n",
      "    accuracy                           0.93       351\n",
      "   macro avg       0.93      0.92      0.93       351\n",
      "weighted avg       0.93      0.93      0.93       351\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       126\n",
      "           1       0.94      0.97      0.95       225\n",
      "\n",
      "    accuracy                           0.94       351\n",
      "   macro avg       0.94      0.93      0.93       351\n",
      "weighted avg       0.94      0.94      0.94       351\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       126\n",
      "           1       0.94      0.97      0.95       225\n",
      "\n",
      "    accuracy                           0.94       351\n",
      "   macro avg       0.94      0.93      0.93       351\n",
      "weighted avg       0.94      0.94      0.94       351\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       126\n",
      "           1       0.94      0.96      0.95       225\n",
      "\n",
      "    accuracy                           0.93       351\n",
      "   macro avg       0.93      0.92      0.93       351\n",
      "weighted avg       0.93      0.93      0.93       351\n",
      "\n",
      "horse_colic_surgery (23/74)\n",
      "Probably not found dataset horse_colic_surgery in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "hepatitis (24/74)\n",
      "(155, 19) with ratio : 3.8438\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        32\n",
      "           1       0.88      0.95      0.91       123\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.80      0.73      0.75       155\n",
      "weighted avg       0.85      0.86      0.85       155\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.50      0.60        32\n",
      "           1       0.88      0.96      0.92       123\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.82      0.73      0.76       155\n",
      "weighted avg       0.86      0.86      0.85       155\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        32\n",
      "           1       0.88      0.95      0.91       123\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.80      0.73      0.75       155\n",
      "weighted avg       0.85      0.86      0.85       155\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        32\n",
      "           1       0.90      0.91      0.91       123\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.77      0.77      0.77       155\n",
      "weighted avg       0.85      0.85      0.85       155\n",
      "\n",
      "heart_disease_zurich (25/74)\n",
      "Probably not found dataset heart_disease_zurich in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_va_long_beach (26/74)\n",
      "Probably not found dataset heart_disease_va_long_beach in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_hungarian (27/74)\n",
      "Probably not found dataset heart_disease_hungarian in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "heart_disease_cleveland (28/74)\n",
      "Probably not found dataset heart_disease_cleveland in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "haberman (29/74)\n",
      "(306, 3) with ratio : 2.7778\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       225\n",
      "           1       0.39      0.27      0.32        81\n",
      "\n",
      "    accuracy                           0.69       306\n",
      "   macro avg       0.57      0.56      0.56       306\n",
      "weighted avg       0.66      0.69      0.67       306\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       225\n",
      "           1       0.36      0.28      0.32        81\n",
      "\n",
      "    accuracy                           0.68       306\n",
      "   macro avg       0.56      0.55      0.55       306\n",
      "weighted avg       0.65      0.68      0.66       306\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       225\n",
      "           1       0.34      0.27      0.30        81\n",
      "\n",
      "    accuracy                           0.67       306\n",
      "   macro avg       0.55      0.54      0.54       306\n",
      "weighted avg       0.64      0.67      0.65       306\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       225\n",
      "           1       0.37      0.38      0.38        81\n",
      "\n",
      "    accuracy                           0.66       306\n",
      "   macro avg       0.57      0.57      0.57       306\n",
      "weighted avg       0.67      0.66      0.67       306\n",
      "\n",
      "glass2 (30/74)\n",
      "(163, 9) with ratio : 1.1447\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        87\n",
      "           1       0.89      0.84      0.86        76\n",
      "\n",
      "    accuracy                           0.88       163\n",
      "   macro avg       0.88      0.88      0.88       163\n",
      "weighted avg       0.88      0.88      0.88       163\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        87\n",
      "           1       0.88      0.86      0.87        76\n",
      "\n",
      "    accuracy                           0.88       163\n",
      "   macro avg       0.88      0.88      0.88       163\n",
      "weighted avg       0.88      0.88      0.88       163\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        87\n",
      "           1       0.89      0.87      0.88        76\n",
      "\n",
      "    accuracy                           0.89       163\n",
      "   macro avg       0.89      0.89      0.89       163\n",
      "weighted avg       0.89      0.89      0.89       163\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89        87\n",
      "           1       0.89      0.86      0.87        76\n",
      "\n",
      "    accuracy                           0.88       163\n",
      "   macro avg       0.88      0.88      0.88       163\n",
      "weighted avg       0.88      0.88      0.88       163\n",
      "\n",
      "credit_approval_germany (31/74)\n",
      "Probably not found dataset credit_approval_germany in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "credit_approval_australia (32/74)\n",
      "Probably not found dataset credit_approval_australia in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "corral (33/74)\n",
      "(160, 6) with ratio : 1.2857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        90\n",
      "           1       1.00      0.99      0.99        70\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        90\n",
      "           1       1.00      0.99      0.99        70\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        90\n",
      "           1       1.00      0.99      0.99        70\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        70\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      "\n",
      "congressional_voting_records (34/74)\n",
      "Probably not found dataset congressional_voting_records in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "bupa (35/74)\n",
      "(345, 5) with ratio : 1.0414\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53       169\n",
      "           1       0.55      0.55      0.55       176\n",
      "\n",
      "    accuracy                           0.54       345\n",
      "   macro avg       0.54      0.54      0.54       345\n",
      "weighted avg       0.54      0.54      0.54       345\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.54       169\n",
      "           1       0.56      0.55      0.55       176\n",
      "\n",
      "    accuracy                           0.55       345\n",
      "   macro avg       0.55      0.55      0.55       345\n",
      "weighted avg       0.55      0.55      0.55       345\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54       169\n",
      "           1       0.55      0.55      0.55       176\n",
      "\n",
      "    accuracy                           0.54       345\n",
      "   macro avg       0.54      0.54      0.54       345\n",
      "weighted avg       0.54      0.54      0.54       345\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53       169\n",
      "           1       0.55      0.54      0.54       176\n",
      "\n",
      "    accuracy                           0.54       345\n",
      "   macro avg       0.54      0.54      0.54       345\n",
      "weighted avg       0.54      0.54      0.54       345\n",
      "\n",
      "breast_cancer_wisconsin_original (36/74)\n",
      "Probably not found dataset breast_cancer_wisconsin_original in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "breast_cancer_wisconsin_diagnostic (37/74)\n",
      "Probably not found dataset breast_cancer_wisconsin_diagnostic in PMLB and skipping...\n",
      " Dataset not found in PMLB.\n",
      "breast_cancer (38/74)\n",
      "(286, 9) with ratio : 2.3647\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       201\n",
      "           1       0.56      0.39      0.46        85\n",
      "\n",
      "    accuracy                           0.73       286\n",
      "   macro avg       0.67      0.63      0.64       286\n",
      "weighted avg       0.71      0.73      0.71       286\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       201\n",
      "           1       0.50      0.36      0.42        85\n",
      "\n",
      "    accuracy                           0.70       286\n",
      "   macro avg       0.63      0.61      0.61       286\n",
      "weighted avg       0.68      0.70      0.69       286\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       201\n",
      "           1       0.52      0.38      0.44        85\n",
      "\n",
      "    accuracy                           0.71       286\n",
      "   macro avg       0.64      0.61      0.62       286\n",
      "weighted avg       0.69      0.71      0.69       286\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       201\n",
      "           1       0.47      0.44      0.45        85\n",
      "\n",
      "    accuracy                           0.69       286\n",
      "   macro avg       0.62      0.61      0.62       286\n",
      "weighted avg       0.68      0.69      0.68       286\n",
      "\n",
      "biomed (39/74)\n",
      "(209, 8) with ratio : 1.7867\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        75\n",
      "           1       0.92      0.98      0.95       134\n",
      "\n",
      "    accuracy                           0.93       209\n",
      "   macro avg       0.94      0.91      0.92       209\n",
      "weighted avg       0.93      0.93      0.93       209\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        75\n",
      "           1       0.92      0.98      0.95       134\n",
      "\n",
      "    accuracy                           0.93       209\n",
      "   macro avg       0.94      0.91      0.92       209\n",
      "weighted avg       0.93      0.93      0.93       209\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        75\n",
      "           1       0.92      0.98      0.95       134\n",
      "\n",
      "    accuracy                           0.93       209\n",
      "   macro avg       0.94      0.91      0.92       209\n",
      "weighted avg       0.93      0.93      0.93       209\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        75\n",
      "           1       0.91      0.95      0.93       134\n",
      "\n",
      "    accuracy                           0.91       209\n",
      "   macro avg       0.91      0.89      0.90       209\n",
      "weighted avg       0.91      0.91      0.91       209\n",
      "\n",
      "backache (40/74)\n",
      "(180, 32) with ratio : 6.2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       155\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.86       180\n",
      "   macro avg       0.43      0.50      0.46       180\n",
      "weighted avg       0.74      0.86      0.80       180\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       155\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.86       180\n",
      "   macro avg       0.43      0.50      0.46       180\n",
      "weighted avg       0.74      0.86      0.79       180\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       155\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.86       180\n",
      "   macro avg       0.43      0.50      0.46       180\n",
      "weighted avg       0.74      0.86      0.79       180\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       155\n",
      "           1       0.39      0.28      0.33        25\n",
      "\n",
      "    accuracy                           0.84       180\n",
      "   macro avg       0.64      0.60      0.62       180\n",
      "weighted avg       0.82      0.84      0.83       180\n",
      "\n",
      "appendicitis (41/74)\n",
      "(106, 7) with ratio : 4.0476\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        85\n",
      "           1       0.71      0.57      0.63        21\n",
      "\n",
      "    accuracy                           0.87       106\n",
      "   macro avg       0.80      0.76      0.78       106\n",
      "weighted avg       0.86      0.87      0.86       106\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        85\n",
      "           1       0.69      0.52      0.59        21\n",
      "\n",
      "    accuracy                           0.86       106\n",
      "   macro avg       0.79      0.73      0.75       106\n",
      "weighted avg       0.85      0.86      0.85       106\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        85\n",
      "           1       0.71      0.57      0.63        21\n",
      "\n",
      "    accuracy                           0.87       106\n",
      "   macro avg       0.80      0.76      0.78       106\n",
      "weighted avg       0.86      0.87      0.86       106\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        85\n",
      "           1       0.62      0.62      0.62        21\n",
      "\n",
      "    accuracy                           0.85       106\n",
      "   macro avg       0.76      0.76      0.76       106\n",
      "weighted avg       0.85      0.85      0.85       106\n",
      "\n",
      "analcatdata_lawsuit (42/74)\n",
      "(264, 4) with ratio : 12.8947\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       245\n",
      "           1       0.89      0.89      0.89        19\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       245\n",
      "           1       0.94      0.84      0.89        19\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.96      0.92      0.94       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       245\n",
      "           1       0.89      0.84      0.86        19\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.94      0.92      0.93       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       245\n",
      "           1       0.82      0.95      0.88        19\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.91      0.97      0.93       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "analcatdata_japansolvent (43/74)\n",
      "(52, 9) with ratio : 1.0800\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86        25\n",
      "           1       0.86      0.89      0.87        27\n",
      "\n",
      "    accuracy                           0.87        52\n",
      "   macro avg       0.87      0.86      0.86        52\n",
      "weighted avg       0.87      0.87      0.87        52\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.83      0.89      0.86        27\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.85      0.84      0.85        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86        25\n",
      "           1       0.86      0.89      0.87        27\n",
      "\n",
      "    accuracy                           0.87        52\n",
      "   macro avg       0.87      0.86      0.86        52\n",
      "weighted avg       0.87      0.87      0.87        52\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86        25\n",
      "           1       0.86      0.89      0.87        27\n",
      "\n",
      "    accuracy                           0.87        52\n",
      "   macro avg       0.87      0.86      0.86        52\n",
      "weighted avg       0.87      0.87      0.87        52\n",
      "\n",
      "analcatdata_fraud (44/74)\n",
      "(42, 11) with ratio : 2.2308\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76        29\n",
      "           1       0.38      0.23      0.29        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.54      0.53      0.52        42\n",
      "weighted avg       0.60      0.64      0.61        42\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77        29\n",
      "           1       0.44      0.31      0.36        13\n",
      "\n",
      "    accuracy                           0.67        42\n",
      "   macro avg       0.59      0.57      0.57        42\n",
      "weighted avg       0.64      0.67      0.65        42\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77        29\n",
      "           1       0.44      0.31      0.36        13\n",
      "\n",
      "    accuracy                           0.67        42\n",
      "   macro avg       0.59      0.57      0.57        42\n",
      "weighted avg       0.64      0.67      0.65        42\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75        29\n",
      "           1       0.47      0.54      0.50        13\n",
      "\n",
      "    accuracy                           0.67        42\n",
      "   macro avg       0.62      0.63      0.62        42\n",
      "weighted avg       0.68      0.67      0.67        42\n",
      "\n",
      "analcatdata_cyyoung9302 (45/74)\n",
      "(92, 10) with ratio : 3.8421\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91        73\n",
      "           1       0.71      0.53      0.61        19\n",
      "\n",
      "    accuracy                           0.86        92\n",
      "   macro avg       0.80      0.74      0.76        92\n",
      "weighted avg       0.85      0.86      0.85        92\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        73\n",
      "           1       0.77      0.53      0.62        19\n",
      "\n",
      "    accuracy                           0.87        92\n",
      "   macro avg       0.83      0.74      0.77        92\n",
      "weighted avg       0.86      0.87      0.86        92\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        73\n",
      "           1       0.77      0.53      0.62        19\n",
      "\n",
      "    accuracy                           0.87        92\n",
      "   macro avg       0.83      0.74      0.77        92\n",
      "weighted avg       0.86      0.87      0.86        92\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        73\n",
      "           1       0.58      0.58      0.58        19\n",
      "\n",
      "    accuracy                           0.83        92\n",
      "   macro avg       0.73      0.73      0.73        92\n",
      "weighted avg       0.83      0.83      0.83        92\n",
      "\n",
      "analcatdata_cyyoung8092 (46/74)\n",
      "(97, 10) with ratio : 3.0417\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        73\n",
      "           1       0.50      0.33      0.40        24\n",
      "\n",
      "    accuracy                           0.75        97\n",
      "   macro avg       0.65      0.61      0.62        97\n",
      "weighted avg       0.73      0.75      0.73        97\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86        73\n",
      "           1       0.56      0.38      0.45        24\n",
      "\n",
      "    accuracy                           0.77        97\n",
      "   macro avg       0.69      0.64      0.65        97\n",
      "weighted avg       0.75      0.77      0.76        97\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86        73\n",
      "           1       0.56      0.38      0.45        24\n",
      "\n",
      "    accuracy                           0.77        97\n",
      "   macro avg       0.69      0.64      0.65        97\n",
      "weighted avg       0.75      0.77      0.76        97\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        73\n",
      "           1       0.62      0.62      0.62        24\n",
      "\n",
      "    accuracy                           0.81        97\n",
      "   macro avg       0.75      0.75      0.75        97\n",
      "weighted avg       0.81      0.81      0.81        97\n",
      "\n",
      "analcatdata_creditscore (47/74)\n",
      "(100, 6) with ratio : 2.7037\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.98      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.98      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.98      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.98      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "analcatdata_boxing2 (48/74)\n",
      "(132, 3) with ratio : 1.1639\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        61\n",
      "           1       0.66      0.73      0.69        71\n",
      "\n",
      "    accuracy                           0.65       132\n",
      "   macro avg       0.65      0.64      0.64       132\n",
      "weighted avg       0.65      0.65      0.65       132\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55        61\n",
      "           1       0.62      0.68      0.65        71\n",
      "\n",
      "    accuracy                           0.61       132\n",
      "   macro avg       0.60      0.60      0.60       132\n",
      "weighted avg       0.60      0.61      0.60       132\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.51      0.53        61\n",
      "           1       0.61      0.65      0.63        71\n",
      "\n",
      "    accuracy                           0.58       132\n",
      "   macro avg       0.58      0.58      0.58       132\n",
      "weighted avg       0.58      0.58      0.58       132\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.64        61\n",
      "           1       0.69      0.76      0.72        71\n",
      "\n",
      "    accuracy                           0.69       132\n",
      "   macro avg       0.69      0.68      0.68       132\n",
      "weighted avg       0.69      0.69      0.69       132\n",
      "\n",
      "analcatdata_boxing1 (49/74)\n",
      "(120, 3) with ratio : 1.8571\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.55      0.61        42\n",
      "           1       0.78      0.87      0.82        78\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.74      0.71      0.72       120\n",
      "weighted avg       0.75      0.76      0.75       120\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60        42\n",
      "           1       0.78      0.85      0.81        78\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.72      0.70      0.70       120\n",
      "weighted avg       0.73      0.74      0.74       120\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.59        42\n",
      "           1       0.77      0.86      0.81        78\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.72      0.69      0.70       120\n",
      "weighted avg       0.73      0.74      0.73       120\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68        42\n",
      "           1       0.81      0.91      0.86        78\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.79      0.75      0.77       120\n",
      "weighted avg       0.80      0.80      0.79       120\n",
      "\n",
      "analcatdata_bankruptcy (50/74)\n",
      "(50, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77        25\n",
      "           1       0.75      0.84      0.79        25\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77        25\n",
      "           1       0.75      0.84      0.79        25\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78        25\n",
      "           1       0.76      0.88      0.81        25\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.81      0.80      0.80        50\n",
      "weighted avg       0.81      0.80      0.80        50\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78        25\n",
      "           1       0.76      0.88      0.81        25\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.81      0.80      0.80        50\n",
      "weighted avg       0.81      0.80      0.80        50\n",
      "\n",
      "analcatdata_asbestos (51/74)\n",
      "(83, 3) with ratio : 1.2432\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        46\n",
      "           1       0.79      0.73      0.76        37\n",
      "\n",
      "    accuracy                           0.80        83\n",
      "   macro avg       0.80      0.79      0.79        83\n",
      "weighted avg       0.80      0.80      0.79        83\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        46\n",
      "           1       0.78      0.76      0.77        37\n",
      "\n",
      "    accuracy                           0.80        83\n",
      "   macro avg       0.79      0.79      0.79        83\n",
      "weighted avg       0.79      0.80      0.79        83\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        46\n",
      "           1       0.76      0.76      0.76        37\n",
      "\n",
      "    accuracy                           0.78        83\n",
      "   macro avg       0.78      0.78      0.78        83\n",
      "weighted avg       0.78      0.78      0.78        83\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        46\n",
      "           1       0.81      0.78      0.79        37\n",
      "\n",
      "    accuracy                           0.82        83\n",
      "   macro avg       0.82      0.82      0.82        83\n",
      "weighted avg       0.82      0.82      0.82        83\n",
      "\n",
      "analcatdata_aids (52/74)\n",
      "(50, 4) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57        25\n",
      "           1       0.55      0.48      0.51        25\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.54      0.54      0.54        50\n",
      "weighted avg       0.54      0.54      0.54        50\n",
      "\n",
      "Local_RFEmb_DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50        25\n",
      "           1       0.48      0.44      0.46        25\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.48      0.48      0.48        50\n",
      "weighted avg       0.48      0.48      0.48        50\n",
      "\n",
      "Local_RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55        25\n",
      "           1       0.54      0.52      0.53        25\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.54      0.54      0.54        50\n",
      "weighted avg       0.54      0.54      0.54        50\n",
      "\n",
      "RFEmb_LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59        25\n",
      "           1       0.58      0.56      0.57        25\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.58      0.58      0.58        50\n",
      "weighted avg       0.58      0.58      0.58        50\n",
      "\n",
      "_deprecated_wdbc (53/74)\n",
      "Skipping _deprecated_wdbc as deprecated from PMLB...\n",
      "_deprecated_vote (54/74)\n",
      "Skipping _deprecated_vote as deprecated from PMLB...\n",
      "_deprecated_pima (55/74)\n",
      "Skipping _deprecated_pima as deprecated from PMLB...\n",
      "_deprecated_hungarian (56/74)\n",
      "Skipping _deprecated_hungarian as deprecated from PMLB...\n",
      "_deprecated_house_votes_84 (57/74)\n",
      "Skipping _deprecated_house_votes_84 as deprecated from PMLB...\n",
      "_deprecated_horse_colic (58/74)\n",
      "Skipping _deprecated_horse_colic as deprecated from PMLB...\n",
      "_deprecated_heart_statlog (59/74)\n",
      "Skipping _deprecated_heart_statlog as deprecated from PMLB...\n",
      "_deprecated_heart_h (60/74)\n",
      "Skipping _deprecated_heart_h as deprecated from PMLB...\n",
      "_deprecated_heart_c (61/74)\n",
      "Skipping _deprecated_heart_c as deprecated from PMLB...\n",
      "_deprecated_german (62/74)\n",
      "Skipping _deprecated_german as deprecated from PMLB...\n",
      "_deprecated_diabetes (63/74)\n",
      "Skipping _deprecated_diabetes as deprecated from PMLB...\n",
      "_deprecated_crx (64/74)\n",
      "Skipping _deprecated_crx as deprecated from PMLB...\n",
      "_deprecated_credit_g (65/74)\n",
      "Skipping _deprecated_credit_g as deprecated from PMLB...\n",
      "_deprecated_credit_a (66/74)\n",
      "Skipping _deprecated_credit_a as deprecated from PMLB...\n",
      "_deprecated_colic (67/74)\n",
      "Skipping _deprecated_colic as deprecated from PMLB...\n",
      "_deprecated_cleve (68/74)\n",
      "Skipping _deprecated_cleve as deprecated from PMLB...\n",
      "_deprecated_buggyCrx (69/74)\n",
      "Skipping _deprecated_buggyCrx as deprecated from PMLB...\n",
      "_deprecated_breast_w (70/74)\n",
      "Skipping _deprecated_breast_w as deprecated from PMLB...\n",
      "_deprecated_breast_cancer_wisconsin (71/74)\n",
      "Skipping _deprecated_breast_cancer_wisconsin as deprecated from PMLB...\n",
      "_deprecated_breast (72/74)\n",
      "Skipping _deprecated_breast as deprecated from PMLB...\n",
      "_deprecated_australian (73/74)\n",
      "Skipping _deprecated_australian as deprecated from PMLB...\n",
      "            model      rank\n",
      "0        Baseline  2.214286\n",
      "3        RFEmb_LR  2.238095\n",
      "1  Local_RFEmb_DT  2.547619\n",
      "2  Local_RFEmb_LR  3.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3607086/1161172448.py:124: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "    # & (dataset_df[\"n_features\"] >= 10)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"][:]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "num_estimators = 100\n",
    "max_depth = None\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Baseline\": {},\n",
    "    #\"Ensemble\": {},\n",
    "    \"Local_RFEmb_DT\":{\"meta\":\"DT\"},\n",
    "    \"Local_RFEmb_LR\":{\"meta\":\"LR\"},\n",
    "    \"RFEmb_LR\":{\"meta\":\"LR\", \"max_depth\":max_depth, \"n_estimators\":num_estimators},\n",
    "    #\"RFEmb_DT\":{\"meta\":\"DT\", \"max_depth\":max_depth, \"n_estimators\":num_estimators},\n",
    "\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "base_class = RandomForestClassifier(n_estimators=num_estimators, max_depth=max_depth, random_state=42)\n",
    "  ##DecisionTreeClassifier(max_depth=None, random_state=42)#\n",
    "\n",
    "res = [] \n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    if 'deprecated' in classification_dataset:\n",
    "        print(f\"Skipping {classification_dataset} as deprecated from PMLB...\")\n",
    "        continue\n",
    "    try:\n",
    "        X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    except ValueError as e:\n",
    "        print(f'Probably not found dataset {classification_dataset} in PMLB and skipping...\\n {e}')\n",
    "        continue\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "\n",
    "    for model_name, model_kwargs in models.items():\n",
    "        y_pred = np.empty_like(y)\n",
    "        sample_weights = None\n",
    "        time_s = time.time()\n",
    "        for train_indices, test_indices in cv.split(X,y):\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            X_test, y_test = X[test_indices], y[test_indices]\n",
    "            \n",
    "            X_train_filtered = X_train.copy()\n",
    "            y_train_filtered = y_train.copy()\n",
    "            if model_name.startswith(\"RFEmb\"):\n",
    "                clf = RFEmb(**model_kwargs)\n",
    "            elif  model_name.startswith(\"Ensemble\"):\n",
    "                clf =  VotingClassifier(estimators=[('lr', LogisticRegression(random_state=random_state, class_weight='balanced')), \n",
    "                                                    ('rf', clone(base_class))], voting='soft')\n",
    "            elif model_name.startswith(\"Local_\"):\n",
    "                clf = RFEmbLocalLr(**model_kwargs)\n",
    "            else:\n",
    "                clf = clone(base_class)\n",
    "            #print(model_name, X_train_filtered.shape[0])\n",
    "            clf.fit(X_train_filtered , y_train_filtered)\n",
    "            y_pred_cur = clf.predict(X_test)\n",
    "\n",
    "            y_pred[test_indices] = y_pred_cur\n",
    "            #print(f'TRUE', y_test)\n",
    "            \n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        #break\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "Baseline           72.96602260241028  28.99319541196636\n",
       "Local_RFEmb_DT    72.86766629311722  28.720729218495112\n",
       "Local_RFEmb_LR    73.15306757332732  28.564311133629243\n",
       "RFEmb_LR          75.66004000695199  26.050665314526324\n",
       "Name: f1, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*res.groupby('model')['f1'].mean()).astype(str) + \"  \" + (100*res.groupby('model')['f1'].std()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RFEmbLocalLr(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth = 10, random_state=42, meta='DT'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.embedder = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=self.random_state)\n",
    "        if meta == \"DT\":\n",
    "            self.final_clf = DecisionTreeClassifier(random_state=self.random_state)\n",
    "        elif meta == 'LR':\n",
    "            self.final_clf = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.embedder.fit(X,y)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.X_train_to_leaves = self.embedder.apply(X)\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            query_leaves = self.embedder.apply(x.reshape(1,-1))\n",
    "            mask = (query_leaves == self.X_train_to_leaves).mean(axis=1) > 0.5\n",
    "            num_to_use = (query_leaves == self.X_train_to_leaves).sum(axis=1)\n",
    "            X_to_use, y_to_use = [], []\n",
    "            for train_index, to_use in enumerate(mask):\n",
    "                if to_use:\n",
    "                    num_iter = num_to_use[train_index]\n",
    "                    X_to_use.extend([self.X_train[train_index] for _ in range(num_iter)])\n",
    "                    y_to_use.extend([self.y_train[train_index] for _ in range(num_iter)])\n",
    "            if len(X_to_use) > 0:\n",
    "                X_to_use = np.vstack(X_to_use)\n",
    "                y_to_use = np.array(y_to_use)\n",
    "                if y_to_use.mean() == 1:\n",
    "                    probas = np.array([0,1]).reshape(1,2)\n",
    "                elif y_to_use.mean() == 0:\n",
    "                    probas = np.array([1,0]).reshape(1,2)\n",
    "                else:\n",
    "                    clf = clone(self.final_clf)\n",
    "                    #print(X_to_use.shape, y_to_use.shape, y_to_use)\n",
    "                    clf.fit(X_to_use, y_to_use)\n",
    "                    probas = clf.predict_proba(x.reshape(1,-1)).reshape(1,2)\n",
    "            else:\n",
    "                probas = self.embedder.predict_proba(x.reshape(1,-1)).reshape(1,2)\n",
    "            \n",
    "            \n",
    "            # to_use_mask  = (query_leaves == self.X_train_to_leaves).sum(axis=1)>0\n",
    "            # print(to_use_mask.sum(), self.X_train.shape[0],  (query_leaves == self.X_train_to_leaves).sum(axis=1).sum())\n",
    "            # #print(self.X_train.shape, to_use_mask.shape)\n",
    "            # if self.y_train[to_use_mask].mean() == 1:\n",
    "            #     probas = np.array([0,1]).reshape(1,2)\n",
    "            # elif self.y_train[to_use_mask].mean() == 0:\n",
    "            #     probas = np.array([1,0]).reshape(1,2)\n",
    "            # else:\n",
    "            #     clf = clone(self.final_clf)\n",
    "            #     clf.fit(self.X_train[to_use_mask], self.y_train[to_use_mask])\n",
    "            #     probas = clf.predict_proba(x.reshape(1,-1)).reshape(1,2)\n",
    "            preds.append(probas)\n",
    "        return np.array(preds).reshape(-1,2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        #print(probas.shape)\n",
    "        return (probas[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "clf = RFEmbLocalLr(meta='LR')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class RFEmb(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth = 10, random_state=42, meta='LR'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.embedder = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=self.random_state)\n",
    "        if meta == \"DT\":\n",
    "            self.final_clf = DecisionTreeClassifier(random_state=self.random_state)\n",
    "        elif meta == 'LR':\n",
    "            self.final_clf = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.embedder.fit(X,y)\n",
    "       \n",
    "        X_emb, _ = self.embedder.decision_path(X)\n",
    "        self.final_clf.fit(X_emb, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_emb, _ = self.embedder.decision_path(X)    \n",
    "        return self.final_clf.predict_proba(X_emb)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_emb, _ = self.embedder.decision_path(X)      \n",
    "        return self.final_clf.predict(X_emb)\n",
    "clf = RFEmb(meta='DT')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
