{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Sample weights based on difficutly\n",
    "### Date: 10/02/2025\n",
    "### Status: Pending results\n",
    "### Idea: \n",
    "If we have a way of scoring the samples from \"easy-to-learn\" to \"hard-to-learn\", can we use this with a learning strategy to improve generalization?\n",
    "\n",
    "The implicit assumption is probably that some of the \"hard\" to classify samples are either noise or would \"bend the model out of shape\" to accommodate for them (not sure any is true).\n",
    "\n",
    "There are 2 major components in this:\n",
    "1. A scoring mechanism on the difficulty of the samples.\n",
    "2. A strategy given the scores for each samples, that would lead to a better learner.\n",
    "\n",
    "\n",
    "I've worked out the following for the above points:\n",
    "\n",
    "##### Difficulty scoring\n",
    "\n",
    "A simple solution is to fit decision trees with incrementaly increasing depth and check which samples are predicted correctly at the corresponding level.\n",
    "The final score for each sample is the lowest depth for which it was correctly classified (i.e. low depth  implies easy model, so low score).\n",
    "\n",
    "\n",
    "Interestingly enough, I've tried fitting a DT with arbitraty depth and then counting the path length for each sample and it is somewhat inversely correlated with the above score\n",
    "(i.e. small path lengh is usually found on the previous methods high-depth samples)\n",
    "\n",
    "\n",
    "##### Score-based strategy\n",
    "\n",
    "Tried out a few things by hand. Focused on the following:\n",
    "\n",
    "1. *Curriculum learning - Hard (CRH)*: Keep only the easiest k% of the training data (according to the score). This is closer to the assumption that difficult samples are mainly noise.\n",
    "2. *Curriculum learning - Soft (CRS)*: Again sample k% of the dataset with probability proportional to the inverse score (i.e. high probability on low scores - easy samples). This is the relaxed version of the above\n",
    "3. *Weighted learning - Easy (WLE)*: Weight the samples during learning according the inverse of their scores (i.e. high weights on low scores - easy samples). The idea is to focus on the easy samples.\n",
    "4. *Weighted learning - Hard (WLH)*: Weight the samples during learning according their scores (i.e. high weights on high scores - hard samples). The idea is to focus on the hard samples.\n",
    "\n",
    "\n",
    "So the overall workflow is:\n",
    "1. Generate train split\n",
    "2. Fit incrementally-increasing-depth DTs on the train data and keep track of the lowest possible DT that correctly classifies each sample.\n",
    "3. Use the selected strategy to sample the dataset or generate the according weights for learning\n",
    "4. Fit a classifier on top \n",
    "\n",
    "\n",
    "### Results:\n",
    "\n",
    "**Best one being WLH with 57.30% better scores than the baseline and avg. rank of 3 over 90 datasets (<=150 features binary classification)** \n",
    "\n",
    "\n",
    "With **best methods over Baseline (RF)** scoring better on X/90 datasets:\n",
    "\n",
    "      model      rank\n",
    "4  CRS_pc99  3.584270\n",
    "\n",
    "6    WLH_sq  3.662921\n",
    "\n",
    "\n",
    "Ranking and wins shown below\n",
    "\n",
    "\n",
    "\n",
    "Comments on results:\n",
    "1. Top Curriculum learning methods seem to perform better than Weight learning methods (this was not expected)\n",
    "2. Time taken for the pre-processing <= 1 sec. on average, 10 seconds at most for 48K samples\n",
    "3. No clear winnger on scaling of scores\n",
    "4. In CR methods, decreasing the cutoff  makes the CR methods use less data so after a bit the results drop drammaticaly. In the experimented range [0.8, 0.9, 0.95, 0.99] there was not a clear winner. 0.99 seems the clear winner, with 0.90 being the second best in ranking but 0.95  being better against baseline.\n",
    "\n",
    "Details:\n",
    "1. Tried out with different variants of the above. \n",
    "   1. For all models there was a variant regarding how the score of each sample is calculated. Starting from the default scores we could extra:\n",
    "      1. Square these scores (pushing out small probas to zero and keeping mainly big scores - aka easy samples)\n",
    "      2. Softmaxing the same as above but smoother\n",
    "      3. Square + softmax\n",
    "   2.  Specifically tweaking the percentile cutoff for *CRH* and *CRS* in keepin 90% or 80% of the top-k easy samples.\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localized Boundary Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.46      0.62       127\n",
      "           1       0.49      0.96      0.64        68\n",
      "\n",
      "    accuracy                           0.63       195\n",
      "   macro avg       0.72      0.71      0.63       195\n",
      "weighted avg       0.79      0.63      0.63       195\n",
      "\n",
      "\n",
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.63      0.75       127\n",
      "           1       0.57      0.91      0.70        68\n",
      "\n",
      "    accuracy                           0.73       195\n",
      "   macro avg       0.75      0.77      0.73       195\n",
      "weighted avg       0.80      0.73      0.73       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "class LocalizedBoundaryClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=0.5, use_pca=False, random_state=None, print_=False):\n",
    "        self.k = k\n",
    "        self.use_pca = use_pca\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        self.local_model = LogisticRegression(max_iter=10000, random_state=self.random_state, class_weight='balanced') # Or LogisticRegression\n",
    "        self.pos_tree = None\n",
    "        self.neg_tree = None\n",
    "        self.feature_thresholds = None\n",
    "        self.important_features = None\n",
    "        self.print_ = print_\n",
    "        self.classes_ = None #required for sklearn classifiers\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X = self.scaler.fit_transform(X)\n",
    "        \n",
    "        self.k = min(self.k, X.shape[0])\n",
    "        \n",
    "        if self.use_pca:\n",
    "            true_components = int(np.sqrt(X.shape[1]))\n",
    "            self.pca = PCA(n_components=true_components, random_state=self.random_state)\n",
    "            X = self.pca.fit_transform(X)\n",
    "             \n",
    "\n",
    "        X_pos = X[y == 1]\n",
    "        X_neg = X[y == 0]\n",
    "\n",
    "        self.pos_tree = BallTree(X_pos)\n",
    "        self.neg_tree = BallTree(X_neg)\n",
    "        \n",
    "        self.X_combined = np.vstack([self.pos_tree.data, self.neg_tree.data])\n",
    "        self.y_combined = np.concatenate([np.ones(len(self.pos_tree.data)), np.zeros(len(self.neg_tree.data))])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _find_important_features(self, X_query, X_pos_neighbors, X_neg_neighbors):\n",
    "        pos_diffs = X_pos_neighbors - X_query\n",
    "        neg_diffs = X_neg_neighbors - X_query\n",
    "\n",
    "        \n",
    "        important_features = np.array([], dtype=int)\n",
    "        for aggr_name, aggr_function in zip(['median', 'mean', 'max', 'min'], [np.median, np.mean, np.max, np.min]):\n",
    "            \n",
    "            pos_diff = aggr_function(pos_diffs, axis=0)\n",
    "            neg_diff = aggr_function(neg_diffs, axis=0)\n",
    "            for aggr_in_sign in ['prod', 'sum']:\n",
    "                if aggr_in_sign == 'prod':\n",
    "                    sign_diffs = np.sign(pos_diff) * np.sign(neg_diff)\n",
    "                else:\n",
    "                    sign_diffs = np.sign(pos_diff) + np.sign(neg_diff)\n",
    "                cur_important_features = np.where(sign_diffs < 0)[0]\n",
    "                important_features = np.concatenate((important_features, cur_important_features))\n",
    "                # Cases where equal feats\n",
    "                if sign_diffs[0] == sign_diffs.sum()/len(sign_diffs):\n",
    "                    cur_important_features = np.concatenate((np.where(pos_diff != 0)[0], np.where(neg_diff != 0)[0]))\n",
    "                    important_features = np.concatenate((important_features, cur_important_features))\n",
    "                if len(important_features) != 0 :\n",
    "                    break\n",
    "            if len(important_features) != 0 :\n",
    "                    break\n",
    "        # Extreme cases where the median is zero and we do have changes per feat:\n",
    "        # if len(important_features) == 0 :\n",
    "        #     print('Did not find important features for this sample')\n",
    "            \n",
    "        \n",
    "        \n",
    "        feature_thresholds = {}\n",
    "\n",
    "        for feature_idx in important_features:\n",
    "            # Find a threshold where the sign changes\n",
    "            #threshold = (pos_diff[feature_idx] + neg_diff[feature_idx]) / 2 + X_query[feature_idx] #simple average for the threshold\n",
    "            feature_thresholds[feature_idx] = (min(pos_diffs[:, feature_idx].min(), neg_diffs[:, feature_idx].min()), max(pos_diffs[:, feature_idx].max(), neg_diffs[:, feature_idx].max()))\n",
    "\n",
    "        return important_features, feature_thresholds\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.scaler.transform(X)\n",
    "        if self.use_pca:\n",
    "            X = self.pca.transform(X)\n",
    "\n",
    "        predictions = []\n",
    "        for x_query in X:\n",
    "            predictions.append(self._predict_one(x_query.reshape(1, -1))) #make sure it is 2d\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "    def _predict_one(self, x_query):\n",
    "        #print('k pos', min(self.k, self.pos_tree.data.base.shape[0]), int(0.5*self.pos_tree.data.shape[0]))\n",
    "        #print('k neg', min(self.k, self.neg_tree.data.base.shape[0]), int(0.5*self.neg_tree.data.shape[0]))\n",
    "        dist_pos, ind_pos = self.pos_tree.query(x_query, k=max(1, int(self.k*self.pos_tree.data.base.shape[0])))\n",
    "        dist_pos = dist_pos[0]\n",
    "        ind_pos = ind_pos[0]\n",
    "        \n",
    "        dist_neg, ind_neg = self.neg_tree.query(x_query, k=max(1, int(self.k*self.neg_tree.data.base.shape[0])))\n",
    "        dist_neg = dist_neg[0]\n",
    "        ind_neg = ind_neg[0]\n",
    "        \n",
    "        min_dist = min(dist_pos.min(), dist_neg.min()) + 1e-6\n",
    "        \n",
    "        \n",
    "        dist_pos = (dist_pos - min_dist).clip(min=1e-6) / np.abs(min_dist)\n",
    "        pos_std_dists = np.bincount(np.round(dist_pos,0).astype(int))\n",
    "        # print('dists', dist_pos)\n",
    "        # print('stds', np.round(dist_pos,0).astype(int))\n",
    "        \n",
    "        try:\n",
    "            pos_cumsum = pos_std_dists.cumsum()\n",
    "            index_to_stop = (pos_cumsum > 0).argmax()\n",
    "            mask_to_keep = np.zeros_like(dist_pos)\n",
    "            mask_to_keep[:pos_cumsum[index_to_stop]] = 1#np.abs(dist_pos) <= self.factor_of_distance_away\n",
    "        except ValueError:\n",
    "            mask_to_keep = np.ones_like(dist_pos)\n",
    "        mask_to_keep = mask_to_keep.astype(bool)\n",
    "\n",
    "        # mask_to_keep = (dist_pos - (dist_pos.mean() + 2*dist_pos.std()) > 0) | (dist_pos - (dist_pos.mean() - 2*dist_pos.std()) > 0)\n",
    "        ind_pos = ind_pos[mask_to_keep]\n",
    "        dist_pos = dist_pos[mask_to_keep]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        dist_neg = (dist_neg - min_dist).clip(min=1e-6) / np.abs(min_dist)\n",
    "       \n",
    "        neg_std_dists = np.bincount(np.round(dist_neg,0).astype(int))\n",
    "        \n",
    "        try:\n",
    "            neg_cumsum = neg_std_dists.cumsum()\n",
    "            index_to_stop = (neg_cumsum > 0).argmax()\n",
    "            # first_non_zero_diff = (np.diff(pos_cumsum) > 0).argmax()\n",
    "            # index_to_stop = np.where(pos_cumsum>0)[0][first_non_zero_diff]\n",
    "            # print('will stop at index:', index_to_stop, 'based on', first_non_zero_diff, 'of cumsum: ', np.where(pos_cumsum>0)[0])\n",
    "            mask_to_keep = np.zeros_like(dist_neg)\n",
    "            mask_to_keep[:neg_cumsum[index_to_stop]] = 1#np.abs(dist_pos) <= self.factor_of_distance_away\n",
    "        except ValueError:\n",
    "            mask_to_keep = np.ones_like(dist_neg)\n",
    "            \n",
    "        mask_to_keep = mask_to_keep.astype(bool)\n",
    "       \n",
    "       \n",
    "        ind_neg = ind_neg[mask_to_keep]\n",
    "        dist_neg = dist_neg[mask_to_keep]\n",
    "        \n",
    "        #print('pos', dist_pos, '\\n neg', dist_neg)\n",
    "        \n",
    "        if len(ind_neg) == 0 or len(ind_pos) == 1:\n",
    "            if self.print_:\n",
    "                print(f\"Only kept positives\")\n",
    "            return 1\n",
    "        if len(ind_pos) == 0 or len(ind_neg) == 1:\n",
    "            if self.print_:\n",
    "                print(f\"Only kept negatives\")\n",
    "            return 0\n",
    "\n",
    "        X_pos_neighbors = self.pos_tree.data.base[ind_pos]  # Access data correctly\n",
    "        X_neg_neighbors = self.neg_tree.data.base[ind_neg]\n",
    "        self.important_features, self.feature_thresholds = self._find_important_features(x_query[0], X_pos_neighbors, X_neg_neighbors)\n",
    "\n",
    "        if len(self.important_features) == 0:\n",
    "            # Fallback: Predict based on majority class of k-NN\n",
    "            if self.print_:\n",
    "                print('Did not find important features for this sample')\n",
    "            least_k = min(dist_pos.shape[0], dist_neg.shape[0])\n",
    "\n",
    "            return self.classes_[np.argmin([sum(dist_neg[:least_k]), sum(dist_pos[:least_k])])]\n",
    "        # Get data for local model\n",
    "        X_local, y_local = self._get_local_data()\n",
    "\n",
    "\n",
    "        if len(np.unique(y_local)) < 2:\n",
    "            try:\n",
    "                # Just return the one class that is found\n",
    "                return self.classes_[np.bincount(y_local).argmax()]\n",
    "            except ValueError:\n",
    "                # If this is empty, then no samples satisfying the local criteria are found\n",
    "                if self.print_:\n",
    "                    print('Did not find local samples for this sample')\n",
    "                least_k = min(dist_pos.shape[0], dist_neg.shape[0])\n",
    "                return self.classes_[np.argmin([sum(dist_neg[:least_k]), sum(dist_pos[:least_k])])]\n",
    "\n",
    "        clf = clone(self.local_model)\n",
    "        # Fit and predict with the local model\n",
    "        clf.fit(X_local, y_local)\n",
    "        return clf.predict(x_query)[0] #return the prediction not the array\n",
    "\n",
    "    def _get_local_data(self):\n",
    "\n",
    "       \n",
    "\n",
    "        for feature_idx, (lower_bound, upper_bound) in self.feature_thresholds.items():\n",
    "            mask = (self.X_combined[:, feature_idx] >= lower_bound) & (self.X_combined[:, feature_idx] <= upper_bound)\n",
    "        # print(mask.sum()/X_combined.shape[0])\n",
    "\n",
    "        return self.X_combined[mask], self.y_combined[mask].astype(int)\n",
    "# Load data and split\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X, y = fetch_data('xd6', return_X_y=True)\n",
    "if y.max() != 1 or y.min() != 0:\n",
    "    for wanted, actual in enumerate(np.unique(y)):\n",
    "        y[y==actual] = wanted\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate and train our classifier\n",
    "lbc = LocalizedBoundaryClassifier(k=0.1, use_pca=False, random_state=42)\n",
    "lbc.fit(X_train, y_train)\n",
    "y_pred_lbc = lbc.predict(X_test)\n",
    "\n",
    "# Instantiate and train a Random Forest classifier\n",
    "rf = LogisticRegression(max_iter=10000, class_weight='balanced', random_state=42)#RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Localized Boundary Classifier:\")\n",
    "print(classification_report(y_test, y_pred_lbc))\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "postoperative_patient_data (1/13)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.55      0.63        64\n",
      "           1       0.29      0.50      0.37        24\n",
      "\n",
      "    accuracy                           0.53        88\n",
      "   macro avg       0.52      0.52      0.50        88\n",
      "weighted avg       0.62      0.53      0.56        88\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.64        64\n",
      "           1       0.28      0.46      0.35        24\n",
      "\n",
      "    accuracy                           0.53        88\n",
      "   macro avg       0.51      0.51      0.49        88\n",
      "weighted avg       0.61      0.53      0.56        88\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.55      0.62        64\n",
      "           1       0.26      0.42      0.32        24\n",
      "\n",
      "    accuracy                           0.51        88\n",
      "   macro avg       0.49      0.48      0.47        88\n",
      "weighted avg       0.59      0.51      0.54        88\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65        64\n",
      "           1       0.29      0.46      0.35        24\n",
      "\n",
      "    accuracy                           0.55        88\n",
      "   macro avg       0.51      0.52      0.50        88\n",
      "weighted avg       0.62      0.55      0.57        88\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65        64\n",
      "           1       0.29      0.46      0.35        24\n",
      "\n",
      "    accuracy                           0.55        88\n",
      "   macro avg       0.51      0.52      0.50        88\n",
      "weighted avg       0.62      0.55      0.57        88\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.64        64\n",
      "           1       0.28      0.46      0.35        24\n",
      "\n",
      "    accuracy                           0.53        88\n",
      "   macro avg       0.51      0.51      0.49        88\n",
      "weighted avg       0.61      0.53      0.56        88\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.55      0.63        64\n",
      "           1       0.29      0.50      0.37        24\n",
      "\n",
      "    accuracy                           0.53        88\n",
      "   macro avg       0.52      0.52      0.50        88\n",
      "weighted avg       0.62      0.53      0.56        88\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.65        64\n",
      "           1       0.31      0.50      0.38        24\n",
      "\n",
      "    accuracy                           0.56        88\n",
      "   macro avg       0.53      0.54      0.52        88\n",
      "weighted avg       0.63      0.56      0.58        88\n",
      "\n",
      "parity5 (2/13)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.31      0.28        16\n",
      "           1       0.08      0.06      0.07        16\n",
      "\n",
      "    accuracy                           0.19        32\n",
      "   macro avg       0.17      0.19      0.17        32\n",
      "weighted avg       0.17      0.19      0.17        32\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70        16\n",
      "           1       0.73      0.50      0.59        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.67      0.66      0.65        32\n",
      "weighted avg       0.67      0.66      0.65        32\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.44        16\n",
      "           1       0.33      0.25      0.29        16\n",
      "\n",
      "    accuracy                           0.38        32\n",
      "   macro avg       0.37      0.38      0.37        32\n",
      "weighted avg       0.37      0.38      0.37        32\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59        16\n",
      "           1       0.57      0.50      0.53        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.56      0.56      0.56        32\n",
      "weighted avg       0.56      0.56      0.56        32\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.42        16\n",
      "           1       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.41      0.41      0.41        32\n",
      "weighted avg       0.41      0.41      0.41        32\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        16\n",
      "           1       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.44      0.44      0.44        32\n",
      "weighted avg       0.44      0.44      0.44        32\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.55        16\n",
      "           1       0.53      0.50      0.52        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.53        32\n",
      "weighted avg       0.53      0.53      0.53        32\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.48        16\n",
      "           1       0.53      0.62      0.57        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.53        32\n",
      "weighted avg       0.53      0.53      0.53        32\n",
      "\n",
      "lupus (3/13)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77        52\n",
      "           1       0.65      0.74      0.69        35\n",
      "\n",
      "    accuracy                           0.74        87\n",
      "   macro avg       0.73      0.74      0.73        87\n",
      "weighted avg       0.74      0.74      0.74        87\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57        52\n",
      "           1       0.44      0.57      0.50        35\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.54      0.55      0.54        87\n",
      "weighted avg       0.56      0.54      0.54        87\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61        52\n",
      "           1       0.49      0.66      0.56        35\n",
      "\n",
      "    accuracy                           0.59        87\n",
      "   macro avg       0.59      0.60      0.58        87\n",
      "weighted avg       0.62      0.59      0.59        87\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61        52\n",
      "           1       0.49      0.66      0.56        35\n",
      "\n",
      "    accuracy                           0.59        87\n",
      "   macro avg       0.59      0.60      0.58        87\n",
      "weighted avg       0.62      0.59      0.59        87\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61        52\n",
      "           1       0.49      0.66      0.56        35\n",
      "\n",
      "    accuracy                           0.59        87\n",
      "   macro avg       0.59      0.60      0.58        87\n",
      "weighted avg       0.62      0.59      0.59        87\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61        52\n",
      "           1       0.49      0.66      0.56        35\n",
      "\n",
      "    accuracy                           0.59        87\n",
      "   macro avg       0.59      0.60      0.58        87\n",
      "weighted avg       0.62      0.59      0.59        87\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.44      0.49        52\n",
      "           1       0.36      0.46      0.40        35\n",
      "\n",
      "    accuracy                           0.45        87\n",
      "   macro avg       0.45      0.45      0.44        87\n",
      "weighted avg       0.47      0.45      0.45        87\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.44      0.49        52\n",
      "           1       0.36      0.46      0.40        35\n",
      "\n",
      "    accuracy                           0.45        87\n",
      "   macro avg       0.45      0.45      0.44        87\n",
      "weighted avg       0.47      0.45      0.45        87\n",
      "\n",
      "labor (4/13)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        20\n",
      "           1       0.88      0.95      0.91        37\n",
      "\n",
      "    accuracy                           0.88        57\n",
      "   macro avg       0.88      0.85      0.86        57\n",
      "weighted avg       0.88      0.88      0.87        57\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.45      0.55        20\n",
      "           1       0.75      0.89      0.81        37\n",
      "\n",
      "    accuracy                           0.74        57\n",
      "   macro avg       0.72      0.67      0.68        57\n",
      "weighted avg       0.73      0.74      0.72        57\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71        20\n",
      "           1       0.81      0.95      0.88        37\n",
      "\n",
      "    accuracy                           0.82        57\n",
      "   macro avg       0.84      0.77      0.79        57\n",
      "weighted avg       0.83      0.82      0.82        57\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        20\n",
      "           1       0.80      0.89      0.85        37\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.78      0.75      0.76        57\n",
      "weighted avg       0.79      0.79      0.78        57\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68        20\n",
      "           1       0.82      0.86      0.84        37\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.77      0.76      0.76        57\n",
      "weighted avg       0.79      0.79      0.79        57\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68        20\n",
      "           1       0.82      0.86      0.84        37\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.77      0.76      0.76        57\n",
      "weighted avg       0.79      0.79      0.79        57\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        20\n",
      "           1       0.78      0.78      0.78        37\n",
      "\n",
      "    accuracy                           0.72        57\n",
      "   macro avg       0.69      0.69      0.69        57\n",
      "weighted avg       0.72      0.72      0.72        57\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56        20\n",
      "           1       0.76      0.84      0.79        37\n",
      "\n",
      "    accuracy                           0.72        57\n",
      "   macro avg       0.69      0.67      0.68        57\n",
      "weighted avg       0.71      0.72      0.71        57\n",
      "\n",
      "analcatdata_japansolvent (5/13)\n",
      "(52, 9) with ratio : 1.0800\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.83      0.89      0.86        27\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.85      0.84      0.85        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63        25\n",
      "           1       0.65      0.41      0.50        27\n",
      "\n",
      "    accuracy                           0.58        52\n",
      "   macro avg       0.59      0.58      0.57        52\n",
      "weighted avg       0.60      0.58      0.56        52\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62        25\n",
      "           1       0.64      0.59      0.62        27\n",
      "\n",
      "    accuracy                           0.62        52\n",
      "   macro avg       0.62      0.62      0.62        52\n",
      "weighted avg       0.62      0.62      0.62        52\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        25\n",
      "           1       0.73      0.59      0.65        27\n",
      "\n",
      "    accuracy                           0.67        52\n",
      "   macro avg       0.68      0.68      0.67        52\n",
      "weighted avg       0.68      0.67      0.67        52\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64        25\n",
      "           1       0.67      0.59      0.63        27\n",
      "\n",
      "    accuracy                           0.63        52\n",
      "   macro avg       0.64      0.64      0.63        52\n",
      "weighted avg       0.64      0.63      0.63        52\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64        25\n",
      "           1       0.67      0.59      0.63        27\n",
      "\n",
      "    accuracy                           0.63        52\n",
      "   macro avg       0.64      0.64      0.63        52\n",
      "weighted avg       0.64      0.63      0.63        52\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.52      0.59        25\n",
      "           1       0.64      0.78      0.70        27\n",
      "\n",
      "    accuracy                           0.65        52\n",
      "   macro avg       0.66      0.65      0.65        52\n",
      "weighted avg       0.66      0.65      0.65        52\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.48      0.57        25\n",
      "           1       0.63      0.81      0.71        27\n",
      "\n",
      "    accuracy                           0.65        52\n",
      "   macro avg       0.67      0.65      0.64        52\n",
      "weighted avg       0.67      0.65      0.64        52\n",
      "\n",
      "analcatdata_fraud (6/13)\n",
      "(42, 11) with ratio : 2.2308\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78        29\n",
      "           1       0.53      0.69      0.60        13\n",
      "\n",
      "    accuracy                           0.71        42\n",
      "   macro avg       0.68      0.71      0.69        42\n",
      "weighted avg       0.74      0.71      0.72        42\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        29\n",
      "           1       0.33      0.23      0.27        13\n",
      "\n",
      "    accuracy                           0.62        42\n",
      "   macro avg       0.52      0.51      0.51        42\n",
      "weighted avg       0.58      0.62      0.60        42\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75        29\n",
      "           1       0.40      0.31      0.35        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.56      0.55      0.55        42\n",
      "weighted avg       0.62      0.64      0.63        42\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71        29\n",
      "           1       0.40      0.46      0.43        13\n",
      "\n",
      "    accuracy                           0.62        42\n",
      "   macro avg       0.57      0.58      0.57        42\n",
      "weighted avg       0.64      0.62      0.63        42\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74        29\n",
      "           1       0.43      0.46      0.44        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.59      0.59      0.59        42\n",
      "weighted avg       0.65      0.64      0.65        42\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74        29\n",
      "           1       0.43      0.46      0.44        13\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.59      0.59      0.59        42\n",
      "weighted avg       0.65      0.64      0.65        42\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        29\n",
      "           1       0.33      0.31      0.32        13\n",
      "\n",
      "    accuracy                           0.60        42\n",
      "   macro avg       0.52      0.52      0.52        42\n",
      "weighted avg       0.59      0.60      0.59        42\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        29\n",
      "           1       0.58      0.54      0.56        13\n",
      "\n",
      "    accuracy                           0.74        42\n",
      "   macro avg       0.69      0.68      0.69        42\n",
      "weighted avg       0.73      0.74      0.74        42\n",
      "\n",
      "analcatdata_cyyoung9302 (7/13)\n",
      "(92, 10) with ratio : 3.8421\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.88        73\n",
      "           1       0.56      0.79      0.65        19\n",
      "\n",
      "    accuracy                           0.83        92\n",
      "   macro avg       0.75      0.81      0.77        92\n",
      "weighted avg       0.86      0.83      0.84        92\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67        73\n",
      "           1       0.19      0.37      0.25        19\n",
      "\n",
      "    accuracy                           0.54        92\n",
      "   macro avg       0.49      0.48      0.46        92\n",
      "weighted avg       0.66      0.54      0.58        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69        73\n",
      "           1       0.20      0.37      0.26        19\n",
      "\n",
      "    accuracy                           0.57        92\n",
      "   macro avg       0.49      0.49      0.48        92\n",
      "weighted avg       0.67      0.57      0.60        92\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.65        73\n",
      "           1       0.16      0.32      0.21        19\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.46      0.44      0.43        92\n",
      "weighted avg       0.64      0.51      0.56        92\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66        73\n",
      "           1       0.16      0.32      0.21        19\n",
      "\n",
      "    accuracy                           0.52        92\n",
      "   macro avg       0.46      0.45      0.44        92\n",
      "weighted avg       0.64      0.52      0.56        92\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66        73\n",
      "           1       0.16      0.32      0.21        19\n",
      "\n",
      "    accuracy                           0.52        92\n",
      "   macro avg       0.46      0.45      0.44        92\n",
      "weighted avg       0.64      0.52      0.56        92\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76        73\n",
      "           1       0.32      0.58      0.42        19\n",
      "\n",
      "    accuracy                           0.66        92\n",
      "   macro avg       0.59      0.63      0.59        92\n",
      "weighted avg       0.75      0.66      0.69        92\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76        73\n",
      "           1       0.32      0.58      0.42        19\n",
      "\n",
      "    accuracy                           0.66        92\n",
      "   macro avg       0.59      0.63      0.59        92\n",
      "weighted avg       0.75      0.66      0.69        92\n",
      "\n",
      "analcatdata_cyyoung8092 (8/13)\n",
      "(97, 10) with ratio : 3.0417\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        73\n",
      "           1       0.57      0.71      0.63        24\n",
      "\n",
      "    accuracy                           0.79        97\n",
      "   macro avg       0.73      0.77      0.74        97\n",
      "weighted avg       0.81      0.79      0.80        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.74        73\n",
      "           1       0.33      0.46      0.39        24\n",
      "\n",
      "    accuracy                           0.64        97\n",
      "   macro avg       0.57      0.58      0.57        97\n",
      "weighted avg       0.68      0.64      0.66        97\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81        73\n",
      "           1       0.49      0.71      0.58        24\n",
      "\n",
      "    accuracy                           0.74        97\n",
      "   macro avg       0.69      0.73      0.70        97\n",
      "weighted avg       0.79      0.74      0.76        97\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80        73\n",
      "           1       0.46      0.67      0.54        24\n",
      "\n",
      "    accuracy                           0.72        97\n",
      "   macro avg       0.66      0.70      0.67        97\n",
      "weighted avg       0.77      0.72      0.74        97\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81        73\n",
      "           1       0.47      0.71      0.57        24\n",
      "\n",
      "    accuracy                           0.73        97\n",
      "   macro avg       0.68      0.72      0.69        97\n",
      "weighted avg       0.78      0.73      0.75        97\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81        73\n",
      "           1       0.47      0.71      0.57        24\n",
      "\n",
      "    accuracy                           0.73        97\n",
      "   macro avg       0.68      0.72      0.69        97\n",
      "weighted avg       0.78      0.73      0.75        97\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.60      0.73        73\n",
      "           1       0.41      0.83      0.55        24\n",
      "\n",
      "    accuracy                           0.66        97\n",
      "   macro avg       0.66      0.72      0.64        97\n",
      "weighted avg       0.79      0.66      0.68        97\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72        73\n",
      "           1       0.40      0.83      0.54        24\n",
      "\n",
      "    accuracy                           0.65        97\n",
      "   macro avg       0.66      0.71      0.63        97\n",
      "weighted avg       0.79      0.65      0.67        97\n",
      "\n",
      "analcatdata_creditscore (9/13)\n",
      "(100, 6) with ratio : 2.7037\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        27\n",
      "           1       1.00      0.97      0.99        73\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.97      0.99      0.98       100\n",
      "weighted avg       0.98      0.98      0.98       100\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.59      0.71        27\n",
      "           1       0.87      0.97      0.92        73\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.88      0.78      0.81       100\n",
      "weighted avg       0.87      0.87      0.86       100\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81        27\n",
      "           1       0.90      0.99      0.94        73\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.93      0.85      0.87       100\n",
      "weighted avg       0.91      0.91      0.91       100\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.73        27\n",
      "           1       0.88      0.95      0.91        73\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.85      0.81      0.82       100\n",
      "weighted avg       0.87      0.87      0.87       100\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76        27\n",
      "           1       0.90      0.95      0.92        73\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.86      0.82      0.84       100\n",
      "weighted avg       0.88      0.88      0.88       100\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76        27\n",
      "           1       0.90      0.95      0.92        73\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.86      0.82      0.84       100\n",
      "weighted avg       0.88      0.88      0.88       100\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.48      0.41        27\n",
      "           1       0.78      0.67      0.72        73\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.56      0.58      0.56       100\n",
      "weighted avg       0.66      0.62      0.64       100\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.41      0.35        27\n",
      "           1       0.75      0.67      0.71        73\n",
      "\n",
      "    accuracy                           0.60       100\n",
      "   macro avg       0.53      0.54      0.53       100\n",
      "weighted avg       0.64      0.60      0.61       100\n",
      "\n",
      "analcatdata_bankruptcy (10/13)\n",
      "(50, 6) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        25\n",
      "           1       0.78      0.84      0.81        25\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.80      0.80        50\n",
      "weighted avg       0.80      0.80      0.80        50\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        25\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        25\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.92      0.90      0.90        50\n",
      "weighted avg       0.92      0.90      0.90        50\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        25\n",
      "           1       1.00      0.84      0.91        25\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.92      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        25\n",
      "           1       1.00      0.84      0.91        25\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.92      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        25\n",
      "           1       1.00      0.84      0.91        25\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.92      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        25\n",
      "           1       0.76      0.76      0.76        25\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78        25\n",
      "           1       0.79      0.76      0.78        25\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "analcatdata_asbestos (11/13)\n",
      "(83, 3) with ratio : 1.2432\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81        46\n",
      "           1       0.74      0.86      0.80        37\n",
      "\n",
      "    accuracy                           0.81        83\n",
      "   macro avg       0.81      0.81      0.81        83\n",
      "weighted avg       0.82      0.81      0.81        83\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        46\n",
      "           1       0.60      0.68      0.63        37\n",
      "\n",
      "    accuracy                           0.65        83\n",
      "   macro avg       0.65      0.65      0.65        83\n",
      "weighted avg       0.66      0.65      0.65        83\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.65      0.70      0.68        37\n",
      "\n",
      "    accuracy                           0.70        83\n",
      "   macro avg       0.70      0.70      0.70        83\n",
      "weighted avg       0.70      0.70      0.70        83\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.65      0.70      0.68        37\n",
      "\n",
      "    accuracy                           0.70        83\n",
      "   macro avg       0.70      0.70      0.70        83\n",
      "weighted avg       0.70      0.70      0.70        83\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.65      0.70      0.68        37\n",
      "\n",
      "    accuracy                           0.70        83\n",
      "   macro avg       0.70      0.70      0.70        83\n",
      "weighted avg       0.70      0.70      0.70        83\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.65      0.70      0.68        37\n",
      "\n",
      "    accuracy                           0.70        83\n",
      "   macro avg       0.70      0.70      0.70        83\n",
      "weighted avg       0.70      0.70      0.70        83\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58        46\n",
      "           1       0.41      0.32      0.36        37\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.48      0.48      0.47        83\n",
      "weighted avg       0.48      0.49      0.48        83\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58        46\n",
      "           1       0.41      0.32      0.36        37\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.48      0.48      0.47        83\n",
      "weighted avg       0.48      0.49      0.48        83\n",
      "\n",
      "analcatdata_aids (12/13)\n",
      "(50, 4) with ratio : 1.0000\n",
      "\n",
      "Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69        25\n",
      "           1       0.71      0.48      0.57        25\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.66      0.64      0.63        50\n",
      "weighted avg       0.66      0.64      0.63        50\n",
      "\n",
      "Localised_.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        25\n",
      "           1       0.77      0.68      0.72        25\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.74      0.74      0.74        50\n",
      "weighted avg       0.74      0.74      0.74        50\n",
      "\n",
      "Localised_.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84        25\n",
      "           1       0.90      0.72      0.80        25\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.83      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "Localised_.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        25\n",
      "           1       0.90      0.76      0.83        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.84      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "Localised_.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        25\n",
      "           1       0.90      0.76      0.83        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.84      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "Localised_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        25\n",
      "           1       0.90      0.76      0.83        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.84      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "Localised_.2_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67        25\n",
      "           1       0.67      0.64      0.65        25\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.66      0.66      0.66        50\n",
      "weighted avg       0.66      0.66      0.66        50\n",
      "\n",
      "Localised_.5_pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.68      0.68      0.68        25\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.68      0.68      0.68        50\n",
      "weighted avg       0.68      0.68      0.68        50\n",
      "\n",
      "              model      rank\n",
      "0          Baseline  2.666667\n",
      "4      Localised_.5  3.916667\n",
      "6      Localised_.9  3.916667\n",
      "2      Localised_.2  4.250000\n",
      "7       Localised_1  4.833333\n",
      "5  Localised_.5_pca  5.083333\n",
      "1      Localised_.1  5.666667\n",
      "3  Localised_.2_pca  5.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3642564/537650829.py:102: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "from sklearn.base import clone\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "    & (dataset_df[\"n_instances\"] <= 100)\n",
    "][\"dataset\"][:]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Baseline\": {},\n",
    "    \n",
    "    # \"Localised_10_2\":{\"k\":10, \"factor_of_distance_away\":2},\n",
    "    # \"Localised_10_1.5\":{\"k\":10, \"factor_of_distance_away\":1.5},\n",
    "    \"Localised_.1\":{\"k\":0.1},\n",
    "    \"Localised_.2\":{\"k\":0.2},\n",
    "    \"Localised_.5\":{\"k\":0.5},\n",
    "    \"Localised_.9\":{\"k\":0.9},\n",
    "    \"Localised_1\":{\"k\":1.0},\n",
    "\n",
    "    \"Localised_.2_pca\":{\"k\":0.2, \"use_pca\":True},\n",
    "    \"Localised_.5_pca\":{\"k\":0.5,  \"use_pca\":True},\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "base_class = LogisticRegression(random_state=random_state, class_weight='balanced')#RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42) #DecisionTreeClassifier(max_depth=None, random_state=42)#\n",
    "\n",
    "res = [] \n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for model_name, model_kwargs in models.items():\n",
    "        y_pred = np.empty_like(y)\n",
    "        sample_weights = None\n",
    "        time_s = time.time()\n",
    "        for train_indices, test_indices in cv.split(X,y):\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            X_test, y_test = X[test_indices], y[test_indices]\n",
    "            \n",
    "            if \"Localised\" in model_name:\n",
    "                clf = LocalizedBoundaryClassifier(**model_kwargs)\n",
    "            else:\n",
    "                clf = clone(base_class)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            \n",
    "            y_pred_cur = clf.predict(X_test)\n",
    "\n",
    "            y_pred[test_indices] = y_pred_cur\n",
    "            \n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "                  Baseline  Localised_.5  Localised_.9  Localised_.2  \\\n",
      "Baseline               0.0           9.0           9.0           9.0   \n",
      "Localised_.5           3.0           0.0           3.0           6.0   \n",
      "Localised_.9           3.0           4.0           0.0           6.0   \n",
      "Localised_.2           3.0           4.0           4.0           0.0   \n",
      "Localised_1            3.0           4.0           1.0           6.0   \n",
      "Localised_.5_pca       3.0           5.0           5.0           5.0   \n",
      "Localised_.1           3.0           3.0           2.0           3.0   \n",
      "Localised_.2_pca       2.0           4.0           4.0           4.0   \n",
      "\n",
      "                  Localised_1  Localised_.5_pca  Localised_.1  \\\n",
      "Baseline                  9.0               9.0           9.0   \n",
      "Localised_.5              4.0               7.0           9.0   \n",
      "Localised_.9              1.0               7.0          10.0   \n",
      "Localised_.2              4.0               7.0           9.0   \n",
      "Localised_1               0.0               7.0           9.0   \n",
      "Localised_.5_pca          5.0               0.0           5.0   \n",
      "Localised_.1              2.0               7.0           0.0   \n",
      "Localised_.2_pca          4.0               2.0           5.0   \n",
      "\n",
      "                  Localised_.2_pca  \n",
      "Baseline                       9.0  \n",
      "Localised_.5                   8.0  \n",
      "Localised_.9                   8.0  \n",
      "Localised_.2                   8.0  \n",
      "Localised_1                    8.0  \n",
      "Localised_.5_pca               7.0  \n",
      "Localised_.1                   7.0  \n",
      "Localised_.2_pca               0.0  \n"
     ]
    }
   ],
   "source": [
    "model_names = res['model'].unique()\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "metric_to_score = 'f1'\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[metric_to_score]\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1][metric_to_score] > cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][metric_to_score] < cur_df.loc[m2][metric_to_score]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "# Uncomment this for percentage wins\n",
    "# wins_score /= res['dataset'].unique().shape[0]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = model_names[order_of_models], index=model_names[order_of_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model      rank\n",
      "0  CRS_pc99  3.584270\n",
      "1    WLH_sq  3.662921\n",
      "2  Baseline  3.764045\n",
      "3  CRH_pc99  3.921348\n",
      "4  CRS_pc95  4.191011\n",
      "5    WLE_sm  4.314607\n",
      "6  CRH_pc95  4.561798\n"
     ]
    }
   ],
   "source": [
    "print(mean_ranks.reset_index(drop=True).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance over number of samples and imbalance ratio for baseline vs best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **No clear trend** when plotting against imbalance, number of samples or number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200728/2580015051.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_200728/2580015051.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "model=Baseline<br>dataset_class_imb=%{x}<br>f1=%{y}<extra></extra>",
         "legendgroup": "Baseline",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Baseline",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          2.0217391304347827,
          1.6839622641509433,
          1.5892857142857142,
          1.0016229375169057,
          1.7716763005780347,
          2.0822320117474304,
          1.8855421686746987,
          1.1512605042016806,
          2.6736842105263157,
          3.8545454545454545,
          1.5377826806398236,
          1.1443298969072164,
          1.8875,
          1.019650655021834,
          2,
          1,
          1,
          2.6666666666666665,
          1.8656716417910448,
          2.407313997477932,
          1.0179533213644525,
          1,
          1,
          1.0745658835546477,
          1.0827067669172932,
          1.9174757281553398,
          1,
          1,
          3.5342465753424657,
          1.8438995215311005,
          1.4857142857142858,
          1.85,
          1.0929927963326784,
          1.2522522522522523,
          1.7857142857142858,
          19.94701986754967,
          1.7735849056603774,
          1.5892857142857142,
          1.7058823529411764,
          3.84375,
          1.25,
          1.7735849056603774,
          1.1956521739130435,
          2.7777777777777777,
          1.144736842105263,
          2.3333333333333335,
          4.857142857142857,
          64.03448275862068,
          1.8656716417910448,
          1.247557003257329,
          2.3333333333333335,
          1.247557003257329,
          1.2857142857142858,
          1.7058823529411764,
          15.761092150170649,
          1.1956521739130435,
          6.072135785007072,
          1.0929927963326784,
          1.0414201183431953,
          1.247557003257329,
          1.900414937759336,
          1.6839622641509433,
          2.364705882352941,
          1.900414937759336,
          1.7866666666666666,
          1.2306397306397305,
          6.2,
          1.247557003257329,
          4.0476190476190474,
          12.894736842105264,
          1.08,
          2.230769230769231,
          3.8421052631578947,
          3.0416666666666665,
          2.7037037037037037,
          1.1639344262295082,
          1.8571428571428572,
          1,
          1.2432432432432432,
          1,
          1.0793974980852694,
          3.179173440574998,
          1.02,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          1,
          0.9383886255924171,
          0.9411764705882353,
          0.9699850604373217,
          0.942323314378554,
          0.6104746317512275,
          0.9681429681429682,
          0.9896049896049897,
          0.937984496124031,
          0.8873563218390804,
          0.9406827084499161,
          0.8111111111111111,
          0.4727272727272727,
          0.9475712123297096,
          0.35398230088495575,
          0.8353413654618473,
          0.9393939393939394,
          0.058823529411764705,
          0.6201232032854209,
          0.8453674121405751,
          0.5247079964061097,
          0,
          0.9354838709677419,
          1,
          0.9738219895287958,
          0.8947368421052632,
          0.9817518248175182,
          0.8846153846153846,
          0.9980657640232108,
          0.8182977366911062,
          0.5882352941176471,
          0.9295774647887324,
          0.9919330743949806,
          1,
          0.949671772428884,
          0.9900891972249752,
          0.7035175879396985,
          0.9501466275659824,
          0.7607843137254902,
          0.9140625,
          0.7725321888412017,
          0.8393782383419689,
          0.847953216374269,
          0.3188405797101449,
          0.8648648648648649,
          0.8384970336189849,
          0.32974910394265233,
          0.992776886035313,
          0.625,
          0.8617886178861789,
          0.8377850162866449,
          0.8813559322033898,
          0.9928057553956835,
          0.8846960167714885,
          0.08516129032258064,
          0.7794117647058824,
          0.8295003965107058,
          0.992822966507177,
          0.5511363636363636,
          0.8926701570680629,
          0.9527720739219713,
          0.9383886255924171,
          0.4583333333333333,
          0.9488752556237219,
          0.9458483754512635,
          0.8761742100768574,
          0,
          0.8491803278688524,
          0.631578947368421,
          0.8947368421052632,
          0.8727272727272727,
          0.2857142857142857,
          0.6060606060606061,
          0.4,
          0.993103448275862,
          0.6933333333333334,
          0.8242424242424242,
          0.7924528301886793,
          0.7605633802816901,
          0.5106382978723404,
          1,
          0.9086867889787598,
          0.6232114467408585,
          0.5704971475142624,
          0.6481012658227848,
          0.6288659793814433,
          0.5399239543726235,
          0.6670926517571885,
          0.5708687132593077
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "model=CRH_pc99<br>dataset_class_imb=%{x}<br>f1=%{y}<extra></extra>",
         "legendgroup": "CRH_pc99",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "CRH_pc99",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          2.0217391304347827,
          1.6839622641509433,
          1.5892857142857142,
          1.0016229375169057,
          1.7716763005780347,
          2.0822320117474304,
          1.8855421686746987,
          1.1512605042016806,
          2.6736842105263157,
          3.8545454545454545,
          1.5377826806398236,
          1.1443298969072164,
          1.8875,
          1.019650655021834,
          2,
          1,
          1,
          2.6666666666666665,
          1.8656716417910448,
          2.407313997477932,
          1.0179533213644525,
          1,
          1,
          1.0745658835546477,
          1.0827067669172932,
          1.9174757281553398,
          1,
          1,
          3.5342465753424657,
          1.8438995215311005,
          1.4857142857142858,
          1.85,
          1.0929927963326784,
          1.2522522522522523,
          1.7857142857142858,
          19.94701986754967,
          1.7735849056603774,
          1.5892857142857142,
          1.7058823529411764,
          3.84375,
          1.25,
          1.7735849056603774,
          1.1956521739130435,
          2.7777777777777777,
          1.144736842105263,
          2.3333333333333335,
          4.857142857142857,
          64.03448275862068,
          1.8656716417910448,
          1.247557003257329,
          2.3333333333333335,
          1.247557003257329,
          1.2857142857142858,
          1.7058823529411764,
          15.761092150170649,
          1.1956521739130435,
          6.072135785007072,
          1.0929927963326784,
          1.0414201183431953,
          1.247557003257329,
          1.900414937759336,
          1.6839622641509433,
          2.364705882352941,
          1.900414937759336,
          1.7866666666666666,
          1.2306397306397305,
          6.2,
          1.247557003257329,
          4.0476190476190474,
          12.894736842105264,
          1.08,
          2.230769230769231,
          3.8421052631578947,
          3.0416666666666665,
          2.7037037037037037,
          1.1639344262295082,
          1.8571428571428572,
          1,
          1.2432432432432432,
          1,
          1.0793974980852694,
          3.179173440574998,
          1.02,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          1,
          0.9349397590361446,
          0.9473684210526315,
          0.9699349945828819,
          0.942323314378554,
          0.6157635467980296,
          0.9577897160399079,
          0.9896049896049897,
          0.9382239382239382,
          0.8822170900692841,
          0.934236522720858,
          0.8064516129032258,
          0.4332129963898917,
          0.9499589827727646,
          0.36151603498542273,
          0.8353413654618473,
          0.9447236180904522,
          0.06666666666666667,
          0.6197183098591549,
          0.8407360406091371,
          0.5328467153284672,
          0,
          0.926829268292683,
          0.9939086294416244,
          0.9808695652173913,
          0.8716577540106952,
          0.9686924493554327,
          0.9019607843137255,
          0.9942196531791907,
          0.8186900958466453,
          0.6268656716417911,
          0.9041095890410958,
          0.9827846572032618,
          0.9977528089887641,
          0.9475982532751092,
          0.9881500987491771,
          0.7326732673267327,
          0.9504373177842566,
          0.8,
          0.9076923076923077,
          0.7719298245614035,
          0.8459530026109661,
          0.8372093023255814,
          0.36879432624113473,
          0.8551724137931035,
          0.8438320209973753,
          0.3106060606060606,
          0.9922522041143468,
          0.6307053941908713,
          0.8515497553017944,
          0.8385826771653543,
          0.8894668400520156,
          0.9928057553956835,
          0.8829568788501027,
          0.08356545961002786,
          0.7954545454545454,
          0.82922954725973,
          0.9833686120350771,
          0.5813953488372093,
          0.8891786179921773,
          0.9512195121951219,
          0.9425837320574163,
          0.4927536231884058,
          0.9527720739219713,
          0.9290780141843972,
          0.8759439050701187,
          0,
          0.8626817447495961,
          0.6111111111111112,
          0.9230769230769231,
          0.8888888888888888,
          0.5217391304347826,
          0.6470588235294118,
          0.43243243243243246,
          0.993103448275862,
          0.7105263157894737,
          0.8242424242424242,
          0.7843137254901961,
          0.7945205479452054,
          0.5217391304347826,
          0.995769773106012,
          0.9102064310195965,
          0.6209677419354839,
          0.580115036976171,
          0.6215538847117794,
          0.6238303181534622,
          0.5478757133798351,
          0.6603415559772297,
          0.5645994832041343
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "model"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "dataset_class_imb"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "f1"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"eab80df9-8b78-4459-bac9-a75bfbd66ebd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eab80df9-8b78-4459-bac9-a75bfbd66ebd\")) {                    Plotly.newPlot(                        \"eab80df9-8b78-4459-bac9-a75bfbd66ebd\",                        [{\"hovertemplate\":\"model=Baseline\\u003cbr\\u003edataset_class_imb=%{x}\\u003cbr\\u003ef1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Baseline\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Baseline\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.0217391304347827,1.6839622641509433,1.5892857142857142,1.0016229375169057,1.7716763005780347,2.0822320117474304,1.8855421686746987,1.1512605042016806,2.6736842105263157,3.8545454545454545,1.5377826806398236,1.1443298969072164,1.8875,1.019650655021834,2.0,1.0,1.0,2.6666666666666665,1.8656716417910448,2.407313997477932,1.0179533213644525,1.0,1.0,1.0745658835546477,1.0827067669172932,1.9174757281553398,1.0,1.0,3.5342465753424657,1.8438995215311005,1.4857142857142858,1.85,1.0929927963326784,1.2522522522522523,1.7857142857142858,19.94701986754967,1.7735849056603774,1.5892857142857142,1.7058823529411764,3.84375,1.25,1.7735849056603774,1.1956521739130435,2.7777777777777777,1.144736842105263,2.3333333333333335,4.857142857142857,64.03448275862068,1.8656716417910448,1.247557003257329,2.3333333333333335,1.247557003257329,1.2857142857142858,1.7058823529411764,15.761092150170649,1.1956521739130435,6.072135785007072,1.0929927963326784,1.0414201183431953,1.247557003257329,1.900414937759336,1.6839622641509433,2.364705882352941,1.900414937759336,1.7866666666666666,1.2306397306397305,6.2,1.247557003257329,4.0476190476190474,12.894736842105264,1.08,2.230769230769231,3.8421052631578947,3.0416666666666665,2.7037037037037037,1.1639344262295082,1.8571428571428572,1.0,1.2432432432432432,1.0,1.0793974980852694,3.179173440574998,1.02,1.0,1.0,1.0,1.0,1.0,1.0],\"xaxis\":\"x\",\"y\":[1.0,0.9383886255924171,0.9411764705882353,0.9699850604373217,0.942323314378554,0.6104746317512275,0.9681429681429682,0.9896049896049897,0.937984496124031,0.8873563218390804,0.9406827084499161,0.8111111111111111,0.4727272727272727,0.9475712123297096,0.35398230088495575,0.8353413654618473,0.9393939393939394,0.058823529411764705,0.6201232032854209,0.8453674121405751,0.5247079964061097,0.0,0.9354838709677419,1.0,0.9738219895287958,0.8947368421052632,0.9817518248175182,0.8846153846153846,0.9980657640232108,0.8182977366911062,0.5882352941176471,0.9295774647887324,0.9919330743949806,1.0,0.949671772428884,0.9900891972249752,0.7035175879396985,0.9501466275659824,0.7607843137254902,0.9140625,0.7725321888412017,0.8393782383419689,0.847953216374269,0.3188405797101449,0.8648648648648649,0.8384970336189849,0.32974910394265233,0.992776886035313,0.625,0.8617886178861789,0.8377850162866449,0.8813559322033898,0.9928057553956835,0.8846960167714885,0.08516129032258064,0.7794117647058824,0.8295003965107058,0.992822966507177,0.5511363636363636,0.8926701570680629,0.9527720739219713,0.9383886255924171,0.4583333333333333,0.9488752556237219,0.9458483754512635,0.8761742100768574,0.0,0.8491803278688524,0.631578947368421,0.8947368421052632,0.8727272727272727,0.2857142857142857,0.6060606060606061,0.4,0.993103448275862,0.6933333333333334,0.8242424242424242,0.7924528301886793,0.7605633802816901,0.5106382978723404,1.0,0.9086867889787598,0.6232114467408585,0.5704971475142624,0.6481012658227848,0.6288659793814433,0.5399239543726235,0.6670926517571885,0.5708687132593077],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"model=CRH_pc99\\u003cbr\\u003edataset_class_imb=%{x}\\u003cbr\\u003ef1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"CRH_pc99\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"CRH_pc99\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.0217391304347827,1.6839622641509433,1.5892857142857142,1.0016229375169057,1.7716763005780347,2.0822320117474304,1.8855421686746987,1.1512605042016806,2.6736842105263157,3.8545454545454545,1.5377826806398236,1.1443298969072164,1.8875,1.019650655021834,2.0,1.0,1.0,2.6666666666666665,1.8656716417910448,2.407313997477932,1.0179533213644525,1.0,1.0,1.0745658835546477,1.0827067669172932,1.9174757281553398,1.0,1.0,3.5342465753424657,1.8438995215311005,1.4857142857142858,1.85,1.0929927963326784,1.2522522522522523,1.7857142857142858,19.94701986754967,1.7735849056603774,1.5892857142857142,1.7058823529411764,3.84375,1.25,1.7735849056603774,1.1956521739130435,2.7777777777777777,1.144736842105263,2.3333333333333335,4.857142857142857,64.03448275862068,1.8656716417910448,1.247557003257329,2.3333333333333335,1.247557003257329,1.2857142857142858,1.7058823529411764,15.761092150170649,1.1956521739130435,6.072135785007072,1.0929927963326784,1.0414201183431953,1.247557003257329,1.900414937759336,1.6839622641509433,2.364705882352941,1.900414937759336,1.7866666666666666,1.2306397306397305,6.2,1.247557003257329,4.0476190476190474,12.894736842105264,1.08,2.230769230769231,3.8421052631578947,3.0416666666666665,2.7037037037037037,1.1639344262295082,1.8571428571428572,1.0,1.2432432432432432,1.0,1.0793974980852694,3.179173440574998,1.02,1.0,1.0,1.0,1.0,1.0,1.0],\"xaxis\":\"x\",\"y\":[1.0,0.9349397590361446,0.9473684210526315,0.9699349945828819,0.942323314378554,0.6157635467980296,0.9577897160399079,0.9896049896049897,0.9382239382239382,0.8822170900692841,0.934236522720858,0.8064516129032258,0.4332129963898917,0.9499589827727646,0.36151603498542273,0.8353413654618473,0.9447236180904522,0.06666666666666667,0.6197183098591549,0.8407360406091371,0.5328467153284672,0.0,0.926829268292683,0.9939086294416244,0.9808695652173913,0.8716577540106952,0.9686924493554327,0.9019607843137255,0.9942196531791907,0.8186900958466453,0.6268656716417911,0.9041095890410958,0.9827846572032618,0.9977528089887641,0.9475982532751092,0.9881500987491771,0.7326732673267327,0.9504373177842566,0.8,0.9076923076923077,0.7719298245614035,0.8459530026109661,0.8372093023255814,0.36879432624113473,0.8551724137931035,0.8438320209973753,0.3106060606060606,0.9922522041143468,0.6307053941908713,0.8515497553017944,0.8385826771653543,0.8894668400520156,0.9928057553956835,0.8829568788501027,0.08356545961002786,0.7954545454545454,0.82922954725973,0.9833686120350771,0.5813953488372093,0.8891786179921773,0.9512195121951219,0.9425837320574163,0.4927536231884058,0.9527720739219713,0.9290780141843972,0.8759439050701187,0.0,0.8626817447495961,0.6111111111111112,0.9230769230769231,0.8888888888888888,0.5217391304347826,0.6470588235294118,0.43243243243243246,0.993103448275862,0.7105263157894737,0.8242424242424242,0.7843137254901961,0.7945205479452054,0.5217391304347826,0.995769773106012,0.9102064310195965,0.6209677419354839,0.580115036976171,0.6215538847117794,0.6238303181534622,0.5478757133798351,0.6603415559772297,0.5645994832041343],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"dataset_class_imb\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"f1\"}},\"legend\":{\"title\":{\"text\":\"model\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eab80df9-8b78-4459-bac9-a75bfbd66ebd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "dataset_details = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 150)\n",
    "]\n",
    "\n",
    "\n",
    "res_to_keep = res[res['model'].isin([\"Baseline\", \"CRH_pc99\"])]\n",
    "res_to_keep['num_samples'] = res_to_keep['dataset'].map(dataset_details[['dataset', 'n_instances']].set_index('dataset')['n_instances'].to_dict().get)\n",
    "res_to_keep['num_feats'] = res_to_keep['dataset'].map(dataset_details[['dataset', 'n_features']].set_index('dataset')['n_features'].to_dict().get)\n",
    "# res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "\n",
    "\n",
    "fig = px.scatter(res_to_keep, x=\"dataset_class_imb\", y=\"f1\", color=\"model\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average time taken\n",
    "\n",
    "### The overhead is less than a second on average or 10 seconds at most (with 48K samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xd6 (1/90)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "wdbc (2/90)\n",
      "(569, 30) with ratio : 1.6840\n",
      "\n",
      "vote (3/90)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "twonorm (4/90)\n",
      "(7400, 20) with ratio : 1.0016\n",
      "\n",
      "tokyo1 (5/90)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "titanic (6/90)\n",
      "(2099, 8) with ratio : 2.0822\n",
      "\n",
      "tic_tac_toe (7/90)\n",
      "(958, 9) with ratio : 1.8855\n",
      "\n",
      "threeOf9 (8/90)\n",
      "(512, 9) with ratio : 1.1513\n",
      "\n",
      "spectf (9/90)\n",
      "(349, 44) with ratio : 2.6737\n",
      "\n",
      "spect (10/90)\n",
      "(267, 22) with ratio : 3.8545\n",
      "\n",
      "spambase (11/90)\n",
      "(4601, 57) with ratio : 1.5378\n",
      "\n",
      "sonar (12/90)\n",
      "(208, 60) with ratio : 1.1443\n",
      "\n",
      "saheart (13/90)\n",
      "(462, 9) with ratio : 1.8875\n",
      "\n",
      "ring (14/90)\n",
      "(7400, 20) with ratio : 1.0197\n",
      "\n",
      "profb (15/90)\n",
      "(672, 9) with ratio : 2.0000\n",
      "\n",
      "prnn_synth (16/90)\n",
      "(250, 2) with ratio : 1.0000\n",
      "\n",
      "prnn_crabs (17/90)\n",
      "(200, 7) with ratio : 1.0000\n",
      "\n",
      "postoperative_patient_data (18/90)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "pima (19/90)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "phoneme (20/90)\n",
      "(5404, 5) with ratio : 2.4073\n",
      "\n",
      "parity5+5 (21/90)\n",
      "(1124, 10) with ratio : 1.0180\n",
      "\n",
      "parity5 (22/90)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "mux6 (23/90)\n",
      "(128, 6) with ratio : 1.0000\n",
      "\n",
      "mushroom (24/90)\n",
      "(8124, 22) with ratio : 1.0746\n",
      "\n",
      "monk3 (25/90)\n",
      "(554, 6) with ratio : 1.0827\n",
      "\n",
      "monk2 (26/90)\n",
      "(601, 6) with ratio : 1.9175\n",
      "\n",
      "monk1 (27/90)\n",
      "(556, 6) with ratio : 1.0000\n",
      "\n",
      "molecular_biology_promoters (28/90)\n",
      "(106, 57) with ratio : 1.0000\n",
      "\n",
      "mofn_3_7_10 (29/90)\n",
      "(1324, 10) with ratio : 3.5342\n",
      "\n",
      "magic (30/90)\n",
      "(19020, 10) with ratio : 1.8439\n",
      "\n",
      "lupus (31/90)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "labor (32/90)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "kr_vs_kp (33/90)\n",
      "(3196, 36) with ratio : 1.0930\n",
      "\n",
      "irish (34/90)\n",
      "(500, 5) with ratio : 1.2523\n",
      "\n",
      "ionosphere (35/90)\n",
      "(351, 34) with ratio : 1.7857\n",
      "\n",
      "hypothyroid (36/90)\n",
      "(3163, 25) with ratio : 19.9470\n",
      "\n",
      "hungarian (37/90)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "house_votes_84 (38/90)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "horse_colic (39/90)\n",
      "(368, 22) with ratio : 1.7059\n",
      "\n",
      "hepatitis (40/90)\n",
      "(155, 19) with ratio : 3.8438\n",
      "\n",
      "heart_statlog (41/90)\n",
      "(270, 13) with ratio : 1.2500\n",
      "\n",
      "heart_h (42/90)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "heart_c (43/90)\n",
      "(303, 13) with ratio : 1.1957\n",
      "\n",
      "haberman (44/90)\n",
      "(306, 3) with ratio : 2.7778\n",
      "\n",
      "glass2 (45/90)\n",
      "(163, 9) with ratio : 1.1447\n",
      "\n",
      "german (46/90)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "flare (47/90)\n",
      "(1066, 10) with ratio : 4.8571\n",
      "\n",
      "dis (48/90)\n",
      "(3772, 29) with ratio : 64.0345\n",
      "\n",
      "diabetes (49/90)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "crx (50/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "credit_g (51/90)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "credit_a (52/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "corral (53/90)\n",
      "(160, 6) with ratio : 1.2857\n",
      "\n",
      "colic (54/90)\n",
      "(368, 22) with ratio : 1.7059\n",
      "\n",
      "coil2000 (55/90)\n",
      "(9822, 85) with ratio : 15.7611\n",
      "\n",
      "cleve (56/90)\n",
      "(303, 13) with ratio : 1.1957\n",
      "\n",
      "churn (57/90)\n",
      "(5000, 20) with ratio : 6.0721\n",
      "\n",
      "chess (58/90)\n",
      "(3196, 36) with ratio : 1.0930\n",
      "\n",
      "bupa (59/90)\n",
      "(345, 5) with ratio : 1.0414\n",
      "\n",
      "buggyCrx (60/90)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "breast_w (61/90)\n",
      "(699, 9) with ratio : 1.9004\n",
      "\n",
      "breast_cancer_wisconsin (62/90)\n",
      "(569, 30) with ratio : 1.6840\n",
      "\n",
      "breast_cancer (63/90)\n",
      "(286, 9) with ratio : 2.3647\n",
      "\n",
      "breast (64/90)\n",
      "(699, 10) with ratio : 1.9004\n",
      "\n",
      "biomed (65/90)\n",
      "(209, 8) with ratio : 1.7867\n",
      "\n",
      "banana (66/90)\n",
      "(5300, 2) with ratio : 1.2306\n",
      "\n",
      "backache (67/90)\n",
      "(180, 32) with ratio : 6.2000\n",
      "\n",
      "australian (68/90)\n",
      "(690, 14) with ratio : 1.2476\n",
      "\n",
      "appendicitis (69/90)\n",
      "(106, 7) with ratio : 4.0476\n",
      "\n",
      "analcatdata_lawsuit (70/90)\n",
      "(264, 4) with ratio : 12.8947\n",
      "\n",
      "analcatdata_japansolvent (71/90)\n",
      "(52, 9) with ratio : 1.0800\n",
      "\n",
      "analcatdata_fraud (72/90)\n",
      "(42, 11) with ratio : 2.2308\n",
      "\n",
      "analcatdata_cyyoung9302 (73/90)\n",
      "(92, 10) with ratio : 3.8421\n",
      "\n",
      "analcatdata_cyyoung8092 (74/90)\n",
      "(97, 10) with ratio : 3.0417\n",
      "\n",
      "analcatdata_creditscore (75/90)\n",
      "(100, 6) with ratio : 2.7037\n",
      "\n",
      "analcatdata_boxing2 (76/90)\n",
      "(132, 3) with ratio : 1.1639\n",
      "\n",
      "analcatdata_boxing1 (77/90)\n",
      "(120, 3) with ratio : 1.8571\n",
      "\n",
      "analcatdata_bankruptcy (78/90)\n",
      "(50, 6) with ratio : 1.0000\n",
      "\n",
      "analcatdata_asbestos (79/90)\n",
      "(83, 3) with ratio : 1.2432\n",
      "\n",
      "analcatdata_aids (80/90)\n",
      "(50, 4) with ratio : 1.0000\n",
      "\n",
      "agaricus_lepiota (81/90)\n",
      "(8145, 22) with ratio : 1.0794\n",
      "\n",
      "adult (82/90)\n",
      "(48842, 14) with ratio : 3.1792\n",
      "\n",
      "Hill_Valley_without_noise (83/90)\n",
      "(1212, 100) with ratio : 1.0200\n",
      "\n",
      "Hill_Valley_with_noise (84/90)\n",
      "(1212, 100) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001 (85/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001 (86/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1 (87/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1 (88/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n",
      "GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1 (89/90)\n",
      "(1600, 20) with ratio : 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Average time taken\n",
    "\n",
    "times = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    time_s = time.time()\n",
    "    scores_data =  np.zeros(len(X)) + max_depth + 1\n",
    "    for depth in range(1, max_depth):\n",
    "        clf = DecisionTreeClassifier(random_state=42, max_depth=depth)\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X)\n",
    "        found_flag = (y_pred == y).astype(int)*depth\n",
    "        found_flag[found_flag == 0] = max_depth + 1\n",
    "        scores_data = np.minimum(scores_data, found_flag)\n",
    "        if (scores_data >= max_depth).sum() == 0:\n",
    "            break\n",
    "    time_taken = time.time() - time_s\n",
    "    times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken (seconds): 0.64 +- 4.02 (mean +- 2*std)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean time taken (seconds): {np.mean(times):.2f} +- {2*np.std(times):.2f} (mean +- 2*std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
