{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: ??\n",
    "### Date: 11/02/2025\n",
    "### Status: Ongoing\n",
    "### Idea: \n",
    "The idea is to guide an embedder based on top-k of same and opossing class with a contrastive loss.\n",
    "\n",
    "Not sure how this is different than adversarial sampling contrastive loss.\n",
    "\n",
    "Maybe we can think of it as NX-Ent [check here p.4 bottom left](https://arxiv.org/pdf/2109.00217) but each training batch is essentially a subgraph of the whole dataset, where for each sample (most of) the top-k positive/negatives are found in the batch, so the positive/negative pairs created are not at random, but on its most similar of the same/opposing class.\n",
    "\n",
    "### Results:\n",
    "Seems working. I may be hacked though.\n",
    "\n",
    "Details:\n",
    "- Interestingly enough some cases where we just use the k-nn on top is better than the classification head.\n",
    "- Also, for the positive pairs it also works (sometimes better) when working on the least similar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "xd6 (1/64)\n",
      "(973, 9) with ratio : 2.0217\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       0.99      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n",
      "wdbc (2/64)\n",
      "(569, 30) with ratio : 1.6840\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       357\n",
      "           1       0.88      0.87      0.87       212\n",
      "\n",
      "    accuracy                           0.91       569\n",
      "   macro avg       0.90      0.90      0.90       569\n",
      "weighted avg       0.91      0.91      0.91       569\n",
      "\n",
      "vote (3/64)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       267\n",
      "           1       0.91      0.95      0.93       168\n",
      "\n",
      "    accuracy                           0.94       435\n",
      "   macro avg       0.94      0.94      0.94       435\n",
      "weighted avg       0.94      0.94      0.94       435\n",
      "\n",
      "tokyo1 (4/64)\n",
      "(959, 44) with ratio : 1.7717\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       346\n",
      "           1       0.93      0.94      0.94       613\n",
      "\n",
      "    accuracy                           0.92       959\n",
      "   macro avg       0.91      0.91      0.91       959\n",
      "weighted avg       0.92      0.92      0.92       959\n",
      "\n",
      "tic_tac_toe (5/64)\n",
      "(958, 9) with ratio : 1.8855\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       332\n",
      "           1       0.90      0.91      0.91       626\n",
      "\n",
      "    accuracy                           0.88       958\n",
      "   macro avg       0.86      0.86      0.86       958\n",
      "weighted avg       0.88      0.88      0.88       958\n",
      "\n",
      "threeOf9 (6/64)\n",
      "(512, 9) with ratio : 1.1513\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       274\n",
      "           1       0.98      1.00      0.99       238\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.99      0.99       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n",
      "spectf (7/64)\n",
      "(349, 44) with ratio : 2.6737\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.75        95\n",
      "           1       0.93      0.86      0.89       254\n",
      "\n",
      "    accuracy                           0.85       349\n",
      "   macro avg       0.81      0.84      0.82       349\n",
      "weighted avg       0.86      0.85      0.85       349\n",
      "\n",
      "spect (8/64)\n",
      "(267, 22) with ratio : 3.8545\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.51      0.46        55\n",
      "           1       0.86      0.82      0.84       212\n",
      "\n",
      "    accuracy                           0.75       267\n",
      "   macro avg       0.64      0.66      0.65       267\n",
      "weighted avg       0.77      0.75      0.76       267\n",
      "\n",
      "sonar (9/64)\n",
      "(208, 60) with ratio : 1.1443\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76       111\n",
      "           1       0.73      0.74      0.73        97\n",
      "\n",
      "    accuracy                           0.75       208\n",
      "   macro avg       0.75      0.75      0.75       208\n",
      "weighted avg       0.75      0.75      0.75       208\n",
      "\n",
      "saheart (10/64)\n",
      "(462, 9) with ratio : 1.8875\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       302\n",
      "           1       0.37      0.38      0.37       160\n",
      "\n",
      "    accuracy                           0.56       462\n",
      "   macro avg       0.52      0.52      0.52       462\n",
      "weighted avg       0.56      0.56      0.56       462\n",
      "\n",
      "profb (11/64)\n",
      "(672, 9) with ratio : 2.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       448\n",
      "           1       0.38      0.36      0.37       224\n",
      "\n",
      "    accuracy                           0.59       672\n",
      "   macro avg       0.53      0.53      0.53       672\n",
      "weighted avg       0.59      0.59      0.59       672\n",
      "\n",
      "prnn_synth (12/64)\n",
      "(250, 2) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       125\n",
      "           1       0.80      0.78      0.79       125\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.79      0.79      0.79       250\n",
      "weighted avg       0.79      0.79      0.79       250\n",
      "\n",
      "prnn_crabs (13/64)\n",
      "(200, 7) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       100\n",
      "           1       0.91      0.91      0.91       100\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.91      0.91      0.91       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "postoperative_patient_data (14/64)\n",
      "(88, 8) with ratio : 2.6667\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75        64\n",
      "           1       0.29      0.25      0.27        24\n",
      "\n",
      "    accuracy                           0.62        88\n",
      "   macro avg       0.51      0.51      0.51        88\n",
      "weighted avg       0.61      0.62      0.62        88\n",
      "\n",
      "pima (15/64)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       500\n",
      "           1       0.58      0.58      0.58       268\n",
      "\n",
      "    accuracy                           0.71       768\n",
      "   macro avg       0.68      0.68      0.68       768\n",
      "weighted avg       0.71      0.71      0.71       768\n",
      "\n",
      "parity5 (16/64)\n",
      "(32, 5) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        16\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.03        32\n",
      "   macro avg       0.03      0.03      0.03        32\n",
      "weighted avg       0.03      0.03      0.03        32\n",
      "\n",
      "mux6 (17/64)\n",
      "(128, 6) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        64\n",
      "           1       0.97      0.97      0.97        64\n",
      "\n",
      "    accuracy                           0.97       128\n",
      "   macro avg       0.97      0.97      0.97       128\n",
      "weighted avg       0.97      0.97      0.97       128\n",
      "\n",
      "monk3 (18/64)\n",
      "(554, 6) with ratio : 1.0827\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       266\n",
      "           1       0.98      0.96      0.97       288\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "monk2 (19/64)\n",
      "(601, 6) with ratio : 1.9175\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       395\n",
      "           1       0.98      1.00      0.99       206\n",
      "\n",
      "    accuracy                           0.99       601\n",
      "   macro avg       0.99      0.99      0.99       601\n",
      "weighted avg       0.99      0.99      0.99       601\n",
      "\n",
      "monk1 (20/64)\n",
      "(556, 6) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       278\n",
      "           1       0.95      0.93      0.94       278\n",
      "\n",
      "    accuracy                           0.94       556\n",
      "   macro avg       0.94      0.94      0.94       556\n",
      "weighted avg       0.94      0.94      0.94       556\n",
      "\n",
      "molecular_biology_promoters (21/64)\n",
      "(106, 57) with ratio : 1.0000\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74        53\n",
      "           1       0.74      0.75      0.75        53\n",
      "\n",
      "    accuracy                           0.75       106\n",
      "   macro avg       0.75      0.75      0.75       106\n",
      "weighted avg       0.75      0.75      0.75       106\n",
      "\n",
      "lupus (22/64)\n",
      "(87, 3) with ratio : 1.4857\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70        52\n",
      "           1       0.56      0.54      0.55        35\n",
      "\n",
      "    accuracy                           0.64        87\n",
      "   macro avg       0.63      0.63      0.63        87\n",
      "weighted avg       0.64      0.64      0.64        87\n",
      "\n",
      "labor (23/64)\n",
      "(57, 16) with ratio : 1.8500\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        20\n",
      "           1       0.86      0.86      0.86        37\n",
      "\n",
      "    accuracy                           0.82        57\n",
      "   macro avg       0.81      0.81      0.81        57\n",
      "weighted avg       0.82      0.82      0.82        57\n",
      "\n",
      "irish (24/64)\n",
      "(500, 5) with ratio : 1.2523\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       278\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "ionosphere (25/64)\n",
      "(351, 34) with ratio : 1.7857\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       126\n",
      "           1       0.92      0.92      0.92       225\n",
      "\n",
      "    accuracy                           0.90       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.90      0.90      0.90       351\n",
      "\n",
      "hungarian (26/64)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78       188\n",
      "           1       0.62      0.65      0.63       106\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "house_votes_84 (27/64)\n",
      "(435, 16) with ratio : 1.5893\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       267\n",
      "           1       0.88      0.93      0.91       168\n",
      "\n",
      "    accuracy                           0.93       435\n",
      "   macro avg       0.92      0.93      0.92       435\n",
      "weighted avg       0.93      0.93      0.93       435\n",
      "\n",
      "horse_colic (28/64)\n",
      "(368, 22) with ratio : 1.7059\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       232\n",
      "           1       0.69      0.67      0.68       136\n",
      "\n",
      "    accuracy                           0.77       368\n",
      "   macro avg       0.75      0.75      0.75       368\n",
      "weighted avg       0.77      0.77      0.77       368\n",
      "\n",
      "hepatitis (29/64)\n",
      "(155, 19) with ratio : 3.8438\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        32\n",
      "           1       0.87      0.84      0.85       123\n",
      "\n",
      "    accuracy                           0.77       155\n",
      "   macro avg       0.65      0.67      0.66       155\n",
      "weighted avg       0.78      0.77      0.77       155\n",
      "\n",
      "heart_statlog (30/64)\n",
      "(270, 13) with ratio : 1.2500\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       150\n",
      "           1       0.69      0.69      0.69       120\n",
      "\n",
      "    accuracy                           0.73       270\n",
      "   macro avg       0.72      0.72      0.72       270\n",
      "weighted avg       0.73      0.73      0.73       270\n",
      "\n",
      "heart_h (31/64)\n",
      "(294, 13) with ratio : 1.7736\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       106\n",
      "           1       0.82      0.80      0.81       188\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.74      0.75      0.74       294\n",
      "weighted avg       0.77      0.76      0.76       294\n",
      "\n",
      "heart_c (32/64)\n",
      "(303, 13) with ratio : 1.1957\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       138\n",
      "           1       0.75      0.76      0.75       165\n",
      "\n",
      "    accuracy                           0.73       303\n",
      "   macro avg       0.73      0.73      0.73       303\n",
      "weighted avg       0.73      0.73      0.73       303\n",
      "\n",
      "haberman (33/64)\n",
      "(306, 3) with ratio : 2.7778\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       225\n",
      "           1       0.35      0.33      0.34        81\n",
      "\n",
      "    accuracy                           0.66       306\n",
      "   macro avg       0.55      0.55      0.55       306\n",
      "weighted avg       0.65      0.66      0.65       306\n",
      "\n",
      "glass2 (34/64)\n",
      "(163, 9) with ratio : 1.1447\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78        87\n",
      "           1       0.74      0.76      0.75        76\n",
      "\n",
      "    accuracy                           0.77       163\n",
      "   macro avg       0.77      0.77      0.77       163\n",
      "weighted avg       0.77      0.77      0.77       163\n",
      "\n",
      "german (35/64)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.47       300\n",
      "           1       0.77      0.77      0.77       700\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.68      0.68      0.68      1000\n",
      "\n",
      "diabetes (36/64)\n",
      "(768, 8) with ratio : 1.8657\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       500\n",
      "           1       0.62      0.60      0.61       268\n",
      "\n",
      "    accuracy                           0.73       768\n",
      "   macro avg       0.70      0.70      0.70       768\n",
      "weighted avg       0.73      0.73      0.73       768\n",
      "\n",
      "crx (37/64)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       383\n",
      "           1       0.80      0.81      0.81       307\n",
      "\n",
      "    accuracy                           0.83       690\n",
      "   macro avg       0.82      0.82      0.82       690\n",
      "weighted avg       0.83      0.83      0.83       690\n",
      "\n",
      "credit_g (38/64)\n",
      "(1000, 20) with ratio : 2.3333\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       300\n",
      "           1       0.79      0.79      0.79       700\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.64      0.64      0.64      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n",
      "credit_a (39/64)\n",
      "(690, 15) with ratio : 1.2476\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       307\n",
      "           1       0.83      0.82      0.83       383\n",
      "\n",
      "    accuracy                           0.81       690\n",
      "   macro avg       0.81      0.81      0.81       690\n",
      "weighted avg       0.81      0.81      0.81       690\n",
      "\n",
      "corral (40/64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_index, classification_dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classification_datasets[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:]):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassification_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_index\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(classification_datasets)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m wanted, actual \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)):\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/pmlb/pmlb.py:66\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(dataset_name, return_X_y, local_cache_dir, dropna)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset_names:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset not found in PMLB.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     dataset_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGITHUB_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dataset_url, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/pmlb/pmlb.py:106\u001b[0m, in \u001b[0;36mget_dataset_url\u001b[0;34m(GITHUB_URL, dataset_name, suffix)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset_url\u001b[39m(GITHUB_URL, dataset_name, suffix):\n\u001b[1;32m    100\u001b[0m     dataset_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{GITHUB_URL}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{DATASET_NAME}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{DATASET_NAME}\u001b[39;00m\u001b[38;5;132;01m{SUFFIX}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    101\u001b[0m                                 GITHUB_URL\u001b[38;5;241m=\u001b[39mGITHUB_URL,\n\u001b[1;32m    102\u001b[0m                                 DATASET_NAME\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m    103\u001b[0m                                 SUFFIX\u001b[38;5;241m=\u001b[39msuffix\n\u001b[1;32m    104\u001b[0m                                 )\n\u001b[0;32m--> 106\u001b[0m     re \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset not found in PMLB.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/prime/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cached_path\n",
    "from pmlb import fetch_data\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "models = ['DT']\n",
    "\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "        \n",
    "    imb_ratio = np.bincount(y).max() / np.bincount(y).min()\n",
    "    print(f\"{X.shape} with ratio : {imb_ratio:.4f}\\n\")\n",
    "    \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state)\n",
    "    \n",
    "    for model_name in models:\n",
    "        time_s = time.time()\n",
    "        if model_name == 'DT':\n",
    "            clf = DecisionTreeClassifier(random_state=random_state)\n",
    "            # clf.fit(X_train, y_train)\n",
    "            # y_probas = clf.predict_proba(X_test)\n",
    "            # y_pred = np.argmax(y_probas, axis=1)\n",
    "            y_pred = cross_val_predict(clf, X, y, cv=cv).astype(int)\n",
    "        \n",
    "        \n",
    "        elif model_name == 'knn-dt':\n",
    "            pass\n",
    "            #y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        \n",
    "        \n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(model_name)    \n",
    "        print(classification_report(y, y_pred))\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, imb_ratio, model_name, time_end, acc, prec, rec, f1))\n",
    "        \n",
    "res = pd.DataFrame(res, columns=['dataset', 'dataset_class_imb', 'model', 'time', 'acc', 'pr', 'rec', 'f1'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)\n",
    "            \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # os.environ('PYTHONHASHSEED') = str(seed)\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/10000, Classification Loss: 0.4412, Contrastive Loss: 0.7366\n",
      "Epoch 2000/10000, Classification Loss: 0.3134, Contrastive Loss: 0.6338\n",
      "Epoch 3000/10000, Classification Loss: 0.1759, Contrastive Loss: 0.4489\n",
      "Epoch 4000/10000, Classification Loss: 0.0852, Contrastive Loss: 0.2450\n",
      "Epoch 5000/10000, Classification Loss: 0.0396, Contrastive Loss: 0.1304\n",
      "\n",
      "Breaking because patience = 196 and Loss = 0.06566528975963593\n",
      "\n",
      "Best Performance (on Test) -- F1: 0.6571 @ epoch 1000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        59\n",
      "           1       0.58      0.53      0.55        34\n",
      "\n",
      "    accuracy                           0.69        93\n",
      "   macro avg       0.66      0.65      0.66        93\n",
      "weighted avg       0.68      0.69      0.68        93\n",
      "\n",
      "\n",
      "KNN Pred:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        59\n",
      "           1       0.61      0.56      0.58        34\n",
      "\n",
      "    accuracy                           0.71        93\n",
      "   macro avg       0.69      0.68      0.68        93\n",
      "weighted avg       0.70      0.71      0.71        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# data = load_breast_cancer()\n",
    "# X = data.data\n",
    "# y = data.target\n",
    "\n",
    "X, y = fetch_data(\"saheart\", return_X_y=True)\n",
    "if y.max() != 1 or y.min() != 0:\n",
    "    for wanted, actual in enumerate(np.unique(y)):\n",
    "        y[y==actual] = wanted\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, embedding_dim)\n",
    "        self.fc3 = nn.Linear(embedding_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        embedding = self.relu(self.fc2(x))\n",
    "        output = torch.sigmoid(self.fc3(embedding))\n",
    "        return embedding, output\n",
    "\n",
    "# # Function to compute contrastive loss using the entire dataset\n",
    "# def contrastive_loss(embeddings, labels, margin=1.0, k=5):\n",
    "#     batch_size = embeddings.size(0)\n",
    "#     loss = 0.0\n",
    "    \n",
    "#     # Compute pairwise distances for all samples\n",
    "#     distances = torch.cdist(embeddings, embeddings)  # Compute all pairwise distances\n",
    "    \n",
    "#     for i in range(batch_size):\n",
    "#         anchor_label = labels[i]\n",
    "#         anchor_distances = distances[i]\n",
    "\n",
    "#         # Get indices of same-class and different-class samples\n",
    "#         same_class_mask = (labels == anchor_label)\n",
    "#         different_class_mask = (labels != anchor_label)\n",
    "\n",
    "#         # Extract distances to same-class and different-class neighbors\n",
    "#         same_class_distances = anchor_distances[same_class_mask]\n",
    "#         different_class_distances = anchor_distances[different_class_mask]\n",
    "\n",
    "#         # Sort distances and pick top-k\n",
    "#         positive_top_k = torch.sort(same_class_distances)[0][:k]  # Closest same-class points\n",
    "#         negative_top_k = torch.sort(different_class_distances)[0][:k]  # Closest different-class points\n",
    "\n",
    "#         # Compute contrastive loss\n",
    "#         positive_loss = torch.mean(positive_top_k)  # Minimize distances to same-class neighbors\n",
    "#         negative_loss = torch.mean(torch.relu(margin - negative_top_k))  # Maximize distances to different-class neighbors\n",
    "        \n",
    "#         loss += positive_loss + negative_loss\n",
    "    \n",
    "#     return loss / batch_size\n",
    "\n",
    "\n",
    "def contrastive_loss(embeddings, labels, margin=1, k=5):\n",
    "    # Compute all pairwise distances\n",
    "    distances = torch.cdist(embeddings, embeddings)  # (N, N) distance matrix\n",
    "\n",
    "    # Create masks for same-class and different-class pairs\n",
    "    labels_exp = labels.view(-1, 1)  # Reshape for broadcasting\n",
    "    same_class_mask = labels_exp == labels_exp.T  # (N, N)\n",
    "    different_class_mask = ~same_class_mask  # Inverse mask\n",
    "\n",
    "    # Set diagonal to False (ignore self-pairs)\n",
    "    same_class_mask.fill_diagonal_(False)\n",
    "    different_class_mask.fill_diagonal_(False)\n",
    "\n",
    "    # Extract distances for same-class and different-class\n",
    "    same_class_distances = distances.clone()\n",
    "    same_class_distances[~same_class_mask] = float('inf')  # Mask out non-same-class distances\n",
    "\n",
    "    different_class_distances = distances.clone()\n",
    "    different_class_distances[~different_class_mask] = float('inf')  # Mask out non-different-class distances\n",
    "\n",
    "    # Get top-k closest distances for same-class and different-class\n",
    "    positive_top_k, _ = torch.topk(same_class_distances, k, largest=False, dim=1)  # (N, k)\n",
    "    negative_top_k, _ = torch.topk(different_class_distances, k, largest=False, dim=1)  # (N, k)\n",
    "\n",
    "    # Compute loss\n",
    "    positive_loss = positive_top_k.mean()\n",
    "    negative_loss = torch.relu(margin - negative_top_k).mean() / margin\n",
    "    total_loss = positive_loss + negative_loss#torch.relu((margin + negative_top_k) - positive_top_k.mean()).mean()/margin#\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = X_train.shape[1]\n",
    "embedding_dim = 64\n",
    "model = SimpleNN(input_dim, embedding_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop (without batching for now)\n",
    "num_epochs = 10000\n",
    "print_every = int(num_epochs/10)\n",
    "best_score = -1\n",
    "best_epoch = -1\n",
    "patience_init = int(print_every/5)\n",
    "\n",
    "weight_on_cl = 0.2\n",
    "k = 3\n",
    "margin = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    embeddings, outputs = model(X_train_tensor)\n",
    "    y_train_tensor_unsq = y_train_tensor.view(-1, 1)\n",
    "\n",
    "    # Compute losses\n",
    "    class_loss = criterion(outputs, y_train_tensor_unsq)\n",
    "    contrast_loss = contrastive_loss(embeddings, y_train_tensor, margin=margin, k=k) # torch.Tensor([0])#\n",
    "    loss = class_loss + weight_on_cl*contrast_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % print_every == 0 and epoch + 1 >= print_every:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Classification Loss: {class_loss.item():.4f}, Contrastive Loss: {contrast_loss.item():.4f}\")\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, test_outputs = model(X_test_tensor)\n",
    "            test_predictions = (test_outputs.numpy() > 0.5).astype(int)\n",
    "            # accuracy = np.mean(test_predictions == y_test.reshape(-1, 1))\n",
    "            # print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "            f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_epoch =  epoch + 1\n",
    "                patience = patience_init\n",
    "            else:\n",
    "                patience -= 1\n",
    "        if loss.item() <= 0.1 or patience == 0 :\n",
    "            print(f\"\\nBreaking because patience = {patience} and Loss = {loss.item()}\\n\")\n",
    "            break\n",
    "\n",
    "print(f\"Best Performance (on Test) -- F1: {f1:.4f} @ epoch {best_epoch}\\n\")\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_embeddings, test_outputs = model(X_test_tensor)\n",
    "    test_predictions = (test_outputs.numpy() > 0.5).astype(int)\n",
    "    # accuracy = np.mean(test_predictions == y_test.reshape(-1, 1))\n",
    "    # print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    \n",
    "\n",
    "    train_embeddings, _ = model(X_train_tensor)\n",
    "    dist = torch.cdist(test_embeddings, train_embeddings)\n",
    "    knn_pred = (y_train[dist.argsort(axis=1)[:,:k].numpy()].mean(axis=1) >= 0.5).astype(int)\n",
    "    # accuracy = np.mean(test_predictions == y_test.reshape(-1, 1))\n",
    "    # print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f'\\nKNN Pred:\\n')\n",
    "    print(classification_report(y_test, knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Epoch 2750/5000, Classification Loss: 0.0973, Contrastive Loss: 2.4133\n",
    "\n",
    "Breaking because patience = 49 and Loss = 0.09729014337062836\n",
    "\n",
    "Best Performance (on Test) -- F1: 0.6613 @ epoch 200\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.81      0.77        59\n",
    "           1       0.61      0.50      0.55        34\n",
    "\n",
    "    accuracy                           0.70        93\n",
    "   macro avg       0.67      0.66      0.66        93\n",
    "weighted avg       0.69      0.70      0.69        93\n",
    "\n",
    "\n",
    "KNN Pred:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.78      0.75        59\n",
    "           1       0.55      0.47      0.51        34\n",
    "\n",
    "    accuracy                           0.67        93\n",
    "   macro avg       0.64      0.63      0.63        93\n",
    "weighted avg       0.66      0.67      0.66        93"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
