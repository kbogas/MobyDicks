{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Signed Distance of features instead of simple distance based kernels.\n",
    "### Date: 07/8/2024\n",
    "### Status: Somewhat works. Need to work on the idea more.\n",
    "### Idea: \n",
    "The idea stemmed from thinking that instead of using a distance gramm matrix, which is agnostic of the labels, we could incorporate the labels as well.\n",
    "So we transfrom D(x,y) = -D(x,y) if y==0 else D(x,y) (with y==1).\n",
    "\n",
    "### Results:\n",
    "Seems to work on linear kernel with DT on top.\n",
    "linear signed is better on 29/63 datasets, it is worse in 24/63 and they tied the rest.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINS\n",
    "                  DT  linear_svm  poly_svm  linear_signed_  linear_orig_\n",
    "DT               0.0        42.0      41.0            47.0          45.0\n",
    "linear_svm      19.0         0.0      26.0            33.0          34.0\n",
    "poly_svm        19.0        26.0       0.0            32.0          34.0\n",
    "linear_signed_  14.0        29.0      28.0             0.0          29.0\n",
    "linear_orig_    14.0        28.0      27.0            23.0           0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_state = 42\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.84      0.85       212\n",
      "           1       0.91      0.92      0.91       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.88      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 29 328]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "kernel = 'linear'\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=random_state) # RandomForestClassifier(random_state=random_state)#\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "    \n",
    "    \n",
    "    train_2_train = pairwise_kernels(X_train, X_train, metric=kernel) #* y_train \n",
    "    \n",
    "    \n",
    "    #train_2_train = np.einsum('ij,j->ij',train_2_train, y_train)\n",
    "    test_2_train = pairwise_kernels(X_test, X_train, metric=kernel) #* y_train\n",
    "    \n",
    "    #test_2_train = np.einsum('ij,j->ij',test_2_train, y_train)\n",
    "    \n",
    "    cur_clf = clone(clf)\n",
    "    cur_clf.fit(train_2_train, y_train)\n",
    "    y_pred = cur_clf.predict(test_2_train)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    \n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.84      0.85       212\n",
      "           1       0.91      0.92      0.92       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 27 330]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_2_train = pairwise_kernels(X_train, X_train, metric=kernel) #* y_train \n",
    "    \n",
    "    y_train_repeated = np.repeat(y_train.reshape(1,-1), repeats=[len(train_2_train)], axis=0)\n",
    "    \n",
    "    train_2_train = train_2_train * y_train_repeated\n",
    "    \n",
    "    #train_2_train = np.einsum('ij,j->ij',train_2_train, y_train)\n",
    "    test_2_train = pairwise_kernels(X_test, X_train, metric=kernel) #* y_train\n",
    "    \n",
    "    y_train_test_repeated = np.repeat(y_train.reshape(1,-1), repeats=[len(test_2_train)], axis=0)\n",
    "    \n",
    "    test_2_train = test_2_train * y_train_test_repeated\n",
    "    \n",
    "    #test_2_train = np.einsum('ij,j->ij',test_2_train, y_train)\n",
    "    \n",
    "    cur_clf = clone(clf)\n",
    "    cur_clf.fit(train_2_train, y_train)\n",
    "    y_pred = cur_clf.predict(test_2_train)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    \n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orig results\n",
    "\n",
    "As proof of concept it is a bit better than default linear kernel + dt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it for multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.84      0.85       212\n",
      "           1       0.91      0.92      0.91       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 28 329]]\n",
      "\n",
      "\n",
      "\n",
      "signed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.84      0.85       212\n",
      "           1       0.91      0.92      0.92       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 27 330]]\n",
      "\n",
      "\n",
      "\n",
      "signed_reduced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.82      0.81       212\n",
      "           1       0.89      0.88      0.89       357\n",
      "\n",
      "    accuracy                           0.86       569\n",
      "   macro avg       0.85      0.85      0.85       569\n",
      "weighted avg       0.86      0.86      0.86       569\n",
      "\n",
      "[[174  38]\n",
      " [ 42 315]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class KernelBased(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 strategy='signed', \n",
    "                 metric='linear', \n",
    "                 clf=DecisionTreeClassifier(max_depth=None, random_state=random_state)):\n",
    "        \n",
    "        self.available_strategies = ['signed', 'orig', 'signed_reduced']\n",
    "        \n",
    "        self.clf = clf\n",
    "        self.strategy = strategy\n",
    "        if self.strategy not in self.available_strategies:\n",
    "            raise NotImplementedError(f\"Available strategies are: {self.available_strategies}. Was given {self.strategy}\")\n",
    "        self.metric = metric\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        y[y==0] = -1\n",
    "        if set(y.tolist()) != set([-1,1]):\n",
    "            raise AttributeError(f\"Y is expected to be [-1,1] only but contains: {set(y)}\")\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y.reshape(1,-1)\n",
    "        \n",
    "        X_tr = self.transform(X)\n",
    "            \n",
    "        self.clf.fit(X_tr, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_tr = self.transform(X)\n",
    "        return self.clf.predict(X_tr)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X_tr = self.transform(X)\n",
    "        return self.clf.predict_proba(X_tr)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_2_train = pairwise_kernels(X, self.X_train, metric=self.metric)\n",
    "        if self.strategy == 'signed':\n",
    "            y_train_repeated = np.repeat(self.y_train, repeats=[X.shape[0]], axis=0)\n",
    "            X_2_train = X_2_train * y_train_repeated\n",
    "        # In this case we simply keep the min, max and mean distance to each label\n",
    "        # In total this will have 6 features (min, max, mean to class -1 and the same to class 1)\n",
    "        if self.strategy == 'signed_reduced':\n",
    "            pos_tr = X_2_train[:, self.y_train.flatten() == 1]\n",
    "            neg_tr = X_2_train[:, self.y_train.flatten() == -1]\n",
    "            feats = []\n",
    "            for tr in [pos_tr, neg_tr]:\n",
    "                for aggr in [np.min, np.max, np.mean]:\n",
    "                    feats.append(aggr(tr, axis=1))\n",
    "            X_2_train = np.vstack(feats).T\n",
    "            \n",
    "        return X_2_train\n",
    "\n",
    "y[y==0] = -1\n",
    "for strategy in ['orig', 'signed', 'signed_reduced']:\n",
    "    clf = KernelBased(strategy= strategy, metric='poly')\n",
    "    print(strategy)\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=cv)\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Reduced does not seem to work as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "wdbc (1/64)\n",
      "vote (2/64)\n",
      "tokyo1 (3/64)\n",
      "tic_tac_toe (4/64)\n",
      "threeOf9 (5/64)\n",
      "spectf (6/64)\n",
      "spect (7/64)\n",
      "sonar (8/64)\n",
      "saheart (9/64)\n",
      "profb (10/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prnn_synth (11/64)\n",
      "prnn_crabs (12/64)\n",
      "postoperative_patient_data (13/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pima (14/64)\n",
      "parity5 (15/64)\n",
      "mux6 (16/64)\n",
      "monk3 (17/64)\n",
      "monk2 (18/64)\n",
      "monk1 (19/64)\n",
      "molecular_biology_promoters (20/64)\n",
      "lupus (21/64)\n",
      "labor (22/64)\n",
      "irish (23/64)\n",
      "ionosphere (24/64)\n",
      "hungarian (25/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_votes_84 (26/64)\n",
      "horse_colic (27/64)\n",
      "hepatitis (28/64)\n",
      "heart_statlog (29/64)\n",
      "heart_h (30/64)\n",
      "heart_c (31/64)\n",
      "haberman (32/64)\n",
      "glass2 (33/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german (34/64)\n",
      "diabetes (35/64)\n",
      "crx (36/64)\n",
      "credit_g (37/64)\n",
      "credit_a (38/64)\n",
      "corral (39/64)\n",
      "colic (40/64)\n",
      "cleve (41/64)\n",
      "bupa (42/64)\n",
      "buggyCrx (43/64)\n",
      "breast_w (44/64)\n",
      "breast_cancer_wisconsin (45/64)\n",
      "breast_cancer (46/64)\n",
      "breast (47/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomed (48/64)\n",
      "backache (49/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "australian (50/64)\n",
      "appendicitis (51/64)\n",
      "analcatdata_lawsuit (52/64)\n",
      "analcatdata_japansolvent (53/64)\n",
      "analcatdata_fraud (54/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung9302 (55/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung8092 (56/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_creditscore (57/64)\n",
      "analcatdata_boxing2 (58/64)\n",
      "analcatdata_boxing1 (59/64)\n",
      "analcatdata_bankruptcy (60/64)\n",
      "analcatdata_asbestos (61/64)\n",
      "analcatdata_aids (62/64)\n",
      "            model      rank\n",
      "0              DT  2.064516\n",
      "3      linear_svm  3.032258\n",
      "4        poly_svm  3.161290\n",
      "1    linear_orig_  3.354839\n",
      "2  linear_signed_  3.387097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2921602/822336845.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import re\n",
    "from torch import rand\n",
    "import cached_path\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "model_names = [\n",
    "    \"DT\",\n",
    "    'linear_svm',\n",
    "    'poly_svm',\n",
    "    'linear_orig_',\n",
    "    'linear_signed_',\n",
    "    #'poly_orig_',\n",
    "    #'poly_signed_',\n",
    "]\n",
    "\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "set_seeds(random_state)\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][1:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "    y[y==0] = -1\n",
    "\n",
    "    \n",
    "        # train_X, test_X, train_y, test_y = train_test_split(\n",
    "        #     X, y, stratify=y, test_size=0.2, random_state=random_state\n",
    "        # )\n",
    "    for model_name in model_names:\n",
    "        #print(model_name)\n",
    "        if \"DT\" in model_name:\n",
    "            clf = DecisionTreeClassifier(\n",
    "                random_state=random_state\n",
    "            )\n",
    "        elif 'svm' in model_name:\n",
    "            if 'linear' in model_name:\n",
    "                clf = SVC()\n",
    "            else:\n",
    "                clf = SVC(kernel='poly')\n",
    "        else: \n",
    "            details = model_name.split('_')\n",
    "            metric, strategy = details[0], details[1]\n",
    "            clf = KernelBased(strategy=strategy, metric=metric)\n",
    "        model = clf\n",
    "        time_s = time.time()\n",
    "\n",
    "        y_pred = cross_val_predict(model, X, y, cv=cv).astype(int)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, model_name, time_end, acc, prec, rec, f1, sup))\n",
    "        #print(res[-1])\n",
    "\n",
    "res = pd.DataFrame(res, columns=['dataset', 'model', 'time', 'acc', 'pr', 'rec', 'f1', 'sup'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "                  DT  linear_svm  poly_svm  linear_signed_  linear_orig_\n",
      "DT               0.0        42.0      41.0            47.0          45.0\n",
      "linear_svm      19.0         0.0      26.0            33.0          34.0\n",
      "poly_svm        19.0        26.0       0.0            32.0          34.0\n",
      "linear_signed_  14.0        29.0      28.0             0.0          29.0\n",
      "linear_orig_    14.0        28.0      27.0            23.0           0.0\n"
     ]
    }
   ],
   "source": [
    "#  res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False))\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "\n",
    "score_to_use = 'f1'\n",
    "\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[score_to_use]\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1][score_to_use] > cur_df.loc[m2][score_to_use]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][score_to_use] < cur_df.loc[m2][score_to_use]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = np.array(model_names)[order_of_models], index=np.array(model_names)[order_of_models]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('prime')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4fa59517bfe49ac29cd98422e2726afe900359f15de8a790b285c6b6179cda3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
