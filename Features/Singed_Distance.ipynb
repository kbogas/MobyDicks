{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Signed Distance of features instead of simple distance based kernels.\n",
    "### Date: 07/8/2024\n",
    "### Status: Somewhat works. Need to work on the idea more.\n",
    "### Idea: \n",
    "The idea stemmed from thinking that instead of using a distance gramm matrix, which is agnostic of the labels, we could incorporate the labels as well.\n",
    "So we transfrom D(x,y) = -D(x,y) if y==0 else D(x,y) (with y==1).\n",
    "\n",
    "### Results:\n",
    "Seems to work on linear kernel with DT on top.\n",
    "linear signed is better on 29/63 datasets, it is worse in 24/63 and they tied the rest.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINS\n",
    "                  DT  linear_svm  poly_svm  linear_signed_  linear_orig_\n",
    "DT               0.0        42.0      41.0            47.0          45.0\n",
    "linear_svm      19.0         0.0      26.0            33.0          34.0\n",
    "poly_svm        19.0        26.0       0.0            32.0          34.0\n",
    "linear_signed_  14.0        29.0      28.0             0.0          29.0\n",
    "linear_orig_    14.0        28.0      27.0            23.0           0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_state = 42\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.84      0.86       212\n",
      "           1       0.91      0.93      0.92       357\n",
      "\n",
      "    accuracy                           0.90       569\n",
      "   macro avg       0.89      0.89      0.89       569\n",
      "weighted avg       0.90      0.90      0.90       569\n",
      "\n",
      "[[178  34]\n",
      " [ 24 333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "kernel = 'linear'\n",
    "\n",
    "clf = RandomForestClassifier(random_state=random_state)# DecisionTreeClassifier(random_state=random_state) \n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "    \n",
    "    \n",
    "    train_2_train = pairwise_kernels(X_train, X_train, metric=kernel) #* y_train \n",
    "    \n",
    "    \n",
    "    #train_2_train = np.einsum('ij,j->ij',train_2_train, y_train)\n",
    "    test_2_train = pairwise_kernels(X_test, X_train, metric=kernel) #* y_train\n",
    "    \n",
    "    #test_2_train = np.einsum('ij,j->ij',test_2_train, y_train)\n",
    "    \n",
    "    cur_clf = clone(clf)\n",
    "    cur_clf.fit(train_2_train, y_train)\n",
    "    y_pred = cur_clf.predict(test_2_train)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    \n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.84      0.85       212\n",
      "           1       0.91      0.92      0.92       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 27 330]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_2_train = pairwise_kernels(X_train, X_train, metric=kernel) #* y_train \n",
    "    \n",
    "    y_train_repeated = np.repeat(y_train.reshape(1,-1), repeats=[len(train_2_train)], axis=0)\n",
    "    \n",
    "    train_2_train = train_2_train * y_train_repeated\n",
    "    \n",
    "    #train_2_train = np.einsum('ij,j->ij',train_2_train, y_train)\n",
    "    test_2_train = pairwise_kernels(X_test, X_train, metric=kernel) #* y_train\n",
    "    \n",
    "    y_train_test_repeated = np.repeat(y_train.reshape(1,-1), repeats=[len(test_2_train)], axis=0)\n",
    "    \n",
    "    test_2_train = test_2_train * y_train_test_repeated\n",
    "    \n",
    "    #test_2_train = np.einsum('ij,j->ij',test_2_train, y_train)\n",
    "    \n",
    "    cur_clf = clone(clf)\n",
    "    cur_clf.fit(train_2_train, y_train)\n",
    "    y_pred = cur_clf.predict(test_2_train)\n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    \n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "TRAIN score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.76      0.85       212\n",
      "           1       0.88      0.98      0.93       357\n",
      "\n",
      "    accuracy                           0.90       569\n",
      "   macro avg       0.92      0.87      0.89       569\n",
      "weighted avg       0.91      0.90      0.90       569\n",
      "\n",
      "[[162  50]\n",
      " [  6 351]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "kernel = 'euclidean'\n",
    "\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('sc', StandardScaler()),\n",
    "#     ('clf', RandomForestClassifier(random_state=random_state))\n",
    "# ])\n",
    "clf = RandomForestClassifier(random_state=random_state)# RandomForestClassifier(random_state=random_state)#\n",
    "\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_2_train = pairwise_distances(X_train, X_train, metric=kernel) #* y_train \n",
    "    \n",
    "    # To counter the effect of zeros we sort them by closest to furthest and remove the zero\n",
    "    # Resulting at train_num-1 features.\n",
    "    # At test time, we remove the furthest value as we calculate will have the least impact\n",
    "    train_sort_neighbors_per_sample = np.argsort(train_2_train, axis=1)\n",
    "    \n",
    "    train_2_train = train_2_train[np.arange(len(train_2_train))[:,None],train_sort_neighbors_per_sample]\n",
    "    \n",
    "    sign_matrix = y_train.reshape(-1,1) @ y_train.reshape(1,-1)\n",
    "    sign_matrix = sign_matrix[np.arange(len(sign_matrix))[:,None], train_sort_neighbors_per_sample]\n",
    "    train_2_train_signed = train_2_train * sign_matrix\n",
    "    train_2_train_signed = train_2_train_signed[:,1:]\n",
    "    \n",
    "    #train_2_train = np.einsum('ij,j->ij',train_2_train, y_train)\n",
    "    test_2_train = pairwise_distances(X_test, X_train, metric=kernel) #* y_train\n",
    "    test_sort_neighbors_per_sample = np.argsort(test_2_train, axis=1)\n",
    "    \n",
    "    test_2_train = test_2_train[np.arange(len(test_2_train))[:,None],test_sort_neighbors_per_sample]\n",
    "    \n",
    "    test_sign_matrix_pos = np.ones(len(X_test)).reshape(-1,1) @ y_train.reshape(1,-1)\n",
    "    test_sign_matrix_pos = test_sign_matrix_pos[np.arange(len(test_sign_matrix_pos))[:,None], test_sort_neighbors_per_sample]\n",
    "    \n",
    "    test_2_train_pos = test_2_train * test_sign_matrix_pos\n",
    "    test_2_train_pos = test_2_train_pos[:,:-1]\n",
    "    \n",
    "    test_sign_matrix_neg = -test_sign_matrix_pos\n",
    "    test_sign_matrix_neg = test_sign_matrix_neg[np.arange(len(test_sign_matrix_neg))[:,None], test_sort_neighbors_per_sample]\n",
    "    test_2_train_neg = test_2_train * test_sign_matrix_neg\n",
    "    test_2_train_neg = test_2_train_neg[:,:-1]\n",
    "    \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    train_2_train_signed = sc.fit_transform(train_2_train_signed)\n",
    "    test_2_train_pos = sc.transform(test_2_train_pos)\n",
    "    test_2_train_neg = sc.transform(test_2_train_neg)\n",
    "    \n",
    "    cur_clf = clone(clf)\n",
    "    cur_clf.fit(train_2_train_signed, y_train)\n",
    "    print(f'TRAIN score: {cur_clf.score(train_2_train_signed, y_train)}')\n",
    "    y_pred_pos = cur_clf.predict_proba(test_2_train_pos)\n",
    "    y_pred_neg = cur_clf.predict_proba(test_2_train_neg)\n",
    "    \n",
    "    # ## MLE ##\n",
    "    \n",
    "    means = np.mean(train_2_train_signed, axis=0)\n",
    "    # covs = np.cov(treain_2_train_signed, rowvar=False)\n",
    "    \n",
    "    from sklearn.covariance import ShrunkCovariance\n",
    "    covs = ShrunkCovariance().fit(train_2_train_signed).covariance_\n",
    "\n",
    "    \n",
    "    from scipy.stats import multivariate_normal\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    g = multivariate_normal(means, covs, allow_singular=True)\n",
    "    # pos_likelihood = g.pdf(test_2_train_pos)\n",
    "    # neg_likelihood = g.pdf(test_2_train_neg)\n",
    "    pos_likelihood = MinMaxScaler().fit_transform(g.logpdf(test_2_train_pos).reshape(-1,1)).ravel()\n",
    "    neg_likelihood = 1 - pos_likelihood #MinMaxScaler().fit_transform(g.logpdf(test_2_train_neg).reshape(-1,1)).ravel()\n",
    "    \n",
    "    y_pos = y_pred_pos[:, 1] #* pos_likelihood**(1)\n",
    "    y_neg = y_pred_neg[:, 0] #* neg_likelihood**(1)\n",
    "    \n",
    "    y_pred = (y_pos>y_neg).astype(int)#(pos_likelihood > neg_likelihood).astype(int)#\n",
    "    #y_pred = (( y_pred_pos[:,1] + y_pred_neg[:,0] ) / 2 > 0.5).astype(int)\n",
    "    y_pred[y_pred == 0] = -1\n",
    "    \n",
    "    y_pred_all.extend(y_pred.tolist())\n",
    "    y_true_all.extend(y_test.tolist())\n",
    "    #break\n",
    "    \n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "print(confusion_matrix(y_true_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0570956 , 0.0413995 , 0.61852362, 0.31178119, 0.0058888 ,\n",
       "       0.19066083, 0.01238385, 0.64921265, 0.15513445, 0.17577428,\n",
       "       0.01060588, 0.        , 0.18315931, 0.62984629, 0.05460237,\n",
       "       0.69545459, 0.18102912, 0.47647135, 0.01413328, 0.69930682,\n",
       "       0.81231982, 0.70744076, 0.03683333, 0.58260724, 0.0490715 ,\n",
       "       0.00806122, 0.57369119, 0.00547379, 0.17756392, 0.1445992 ,\n",
       "       0.08514906, 0.03574965, 0.67359731, 0.63696139, 0.8610784 ,\n",
       "       0.71543777, 0.01871419, 0.97888008, 0.0362172 , 0.01251845,\n",
       "       0.45841842, 0.01173448, 0.02356715, 0.00880145, 0.05592427,\n",
       "       0.55942778, 0.00776406, 0.00632291, 0.04300332, 0.11211373,\n",
       "       0.02441662, 0.00221053, 0.63271704, 0.01884269, 0.14759646,\n",
       "       1.        , 0.88122381])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99540797, 0.99435922, 0.69734925, 0.99594029, 0.99689406,\n",
       "       0.99762642, 0.93392378, 0.99394281, 0.96407388, 0.97577406,\n",
       "       0.91546816, 0.68053271, 0.99902761, 0.99869118, 0.98341443,\n",
       "       1.        , 0.98398718, 0.9893637 , 0.99149974, 0.83366953,\n",
       "       0.9974062 , 0.99732452, 0.9880731 , 0.99659903, 0.99477408,\n",
       "       0.94584995, 0.86094965, 0.9989683 , 0.99854147, 0.98507962,\n",
       "       0.99451148, 0.        , 0.99721974, 0.99836353, 0.98790375,\n",
       "       0.99842164, 0.99969731, 0.79497702, 0.99596382, 0.9974311 ,\n",
       "       0.92900833, 0.99780531, 0.91915389, 0.99736412, 0.99517583,\n",
       "       0.98356341, 0.994431  , 0.98822936, 0.98181233, 0.97204107,\n",
       "       0.90911988, 0.95914144, 0.9989318 , 0.9908018 , 0.97348481,\n",
       "       0.99900543])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MinMaxScaler().fit_transform(g.logpdf(test_2_train_neg).reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,  -2,  -3,  -4,  -5,  -6,  -7,  -8,  -9, -10, -11, -12, -11,\n",
       "       -12, -11, -10, -11, -10,  -9, -10,  -9,  -8,  -7,  -6,  -5,  -4,\n",
       "        -3,  -2,  -1,  -2,  -1,  -2,  -1,   0,  -1,  -2,  -1,   0,  -1,\n",
       "         0,   1,   2,   3,   4,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "        11,  12,  13,  14])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[np.argsort(MinMaxScaler().fit_transform(g.logpdf(test_2_train_neg).reshape(-1,1)).ravel())].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.59203022e-03, 5.64077654e-03, 3.02650747e-01, 4.05971228e-03,\n",
       "       3.10594358e-03, 2.37358105e-03, 6.60762172e-02, 6.05718851e-03,\n",
       "       3.59261217e-02, 2.42259377e-02, 8.45318365e-02, 3.19467291e-01,\n",
       "       9.72394159e-04, 1.30882246e-03, 1.65855725e-02, 0.00000000e+00,\n",
       "       1.60128197e-02, 1.06362981e-02, 8.50025694e-03, 1.66330467e-01,\n",
       "       2.59380273e-03, 2.67548417e-03, 1.19269045e-02, 3.40096967e-03,\n",
       "       5.22591531e-03, 5.41500513e-02, 1.39050353e-01, 1.03170450e-03,\n",
       "       1.45853408e-03, 1.49203812e-02, 5.48851512e-03, 1.00000000e+00,\n",
       "       2.78025869e-03, 1.63646830e-03, 1.20962543e-02, 1.57836084e-03,\n",
       "       3.02687510e-04, 2.05022984e-01, 4.03618308e-03, 2.56889687e-03,\n",
       "       7.09916703e-02, 2.19468745e-03, 8.08461079e-02, 2.63587704e-03,\n",
       "       4.82416715e-03, 1.64365889e-02, 5.56899897e-03, 1.17706430e-02,\n",
       "       1.81876710e-02, 2.79589345e-02, 9.08801181e-02, 4.08585619e-02,\n",
       "       1.06819518e-03, 9.19819914e-03, 2.65151888e-02, 9.94569523e-04])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -271.64454894,  -584.06452126, -1250.4935477 ,  -443.34564659,\n",
       "        -288.87215064,  -375.42861359,  -956.20760791,  -182.21457154,\n",
       "        -869.31027314,  -891.38874389, -1161.55213873, -2263.88407504,\n",
       "        -243.83669496,  -222.65561582,  -274.61962639,  -234.37189194,\n",
       "        -225.55639964,  -197.9112646 ,  -184.94666406, -1513.21466802,\n",
       "        -268.89681838,  -166.49057214,  -227.6879882 ,  -195.97248631,\n",
       "        -170.13695055,  -838.51204727, -1348.15354725,  -295.38035694,\n",
       "        -189.20687169,  -285.55756852,  -631.15579001, -6058.24209626,\n",
       "        -174.61712439,  -235.47903693,  -207.23073964,  -185.51451219,\n",
       "        -268.48024637, -1572.3783444 ,  -181.38308691,  -180.70004561,\n",
       "       -1048.9685156 ,  -196.19490552, -1049.31080593,  -521.14951977,\n",
       "        -177.6645638 ,  -933.34018606,  -170.43469876,  -221.74239957,\n",
       "        -315.50474965,  -423.18294719, -1201.66088008,  -523.16737809,\n",
       "        -226.41102509,  -209.15194856,  -349.33479797,  -249.78536458])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.logpdf(test_2_train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[np.argsort(g.logpdf(test_2_train_pos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78932739, 0.55871272, 0.36605594, 0.63513232, 0.76806183,\n",
       "       0.68416197, 0.43180609, 0.95288367, 0.45562246, 0.44932564,\n",
       "       0.38396286, 0.22545396, 0.82861844, 0.86402175, 0.78550683,\n",
       "       0.84374722, 0.85882745, 0.91408081, 0.94562508, 0.32027954,\n",
       "       0.79291522, 1.        , 0.85508631, 0.91852311, 0.98815231,\n",
       "       0.46471476, 0.34792276, 0.76052888, 0.93475873, 0.77199856,\n",
       "       0.53805559, 0.        , 0.97440919, 0.8419235 , 0.89388349,\n",
       "       0.94414568, 0.79346424, 0.3111515 , 0.95514057, 0.95701181,\n",
       "       0.40891397, 0.91800895, 0.40883371, 0.58969114, 0.9655235 ,\n",
       "       0.43783064, 0.98721216, 0.86568242, 0.73872872, 0.64859542,\n",
       "       0.37570886, 0.58862767, 0.85731994, 0.88993829, 0.70630004,\n",
       "       0.81961059])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of new data point: 0.04655707891050999\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "\n",
    "# Example training data (replace with your actual data)\n",
    "train_2_train_signed = np.random.randn(100, 3)  # Random dataset of 100 samples, 3 features\n",
    "\n",
    "# Fit the distribution\n",
    "means = train_2_train_signed.mean(axis=0)\n",
    "covs = np.cov(train_2_train_signed, rowvar=False)\n",
    "dist = multivariate_normal(means, covs, allow_singular=True, seed=42)\n",
    "\n",
    "# Example new data point\n",
    "new_data = np.array([0.5, -0.1, 0.3])\n",
    "\n",
    "# Estimate the likelihood of the new data point\n",
    "likelihood_new_data = dist.pdf(new_data)\n",
    "\n",
    "print(f\"Likelihood of new data point: {likelihood_new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "means = train_2_train_signed.mean(axis=0)\n",
    "covs = np.cov(train_2_train_signed, rowvar=False)\n",
    "dist = multivariate_normal(means, covs, allow_singular=True, seed=42)\n",
    "dist.pdf(train_2_train_signed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.cdf(train_2_train_signed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -6.45166418,  -6.54944005,  -3.36453994, -21.15466003,\n",
       "          4.23468848, -14.28697818,  -9.2110485 ,  -6.81244769,\n",
       "         -7.39745569,   1.32512641]),\n",
       " array([27.1185828 , 37.95120517, 43.71151935, 45.71114032, 51.56299342,\n",
       "        55.59994035, 58.17270808, 63.39988965, 65.28784134, 68.31131046]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2_train_neg.mean(axis=0)[:10], means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00     191.0\n",
      "           1       0.00      0.00      0.00     322.0\n",
      "\n",
      "    accuracy                           0.00     513.0\n",
      "   macro avg       0.00      0.00      0.00     513.0\n",
      "weighted avg       0.00      0.00      0.00     513.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00     191.0\n",
      "           1       0.00      0.00      0.00     322.0\n",
      "\n",
      "    accuracy                           0.00     513.0\n",
      "   macro avg       0.00      0.00      0.00     513.0\n",
      "weighted avg       0.00      0.00      0.00     513.0\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [0,1]:\n",
    "    print(col)\n",
    "    p = (train_2_train[:,col] >  3.403).astype(int)\n",
    "    p[p==0] = -1\n",
    "    print(classification_report(y_train, p))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.75, 'x[0] <= 3.403\\ngini = 0.467\\nsamples = 513\\nvalue = [191, 322]'),\n",
       " Text(0.25, 0.25, 'gini = 0.0\\nsamples = 322\\nvalue = [0, 322]'),\n",
       " Text(0.375, 0.5, 'True  '),\n",
       " Text(0.75, 0.25, 'gini = 0.0\\nsamples = 191\\nvalue = [191, 0]'),\n",
       " Text(0.625, 0.5, '  False')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(cur_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orig results\n",
    "\n",
    "As proof of concept it is a bit better than default linear kernel + dt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it for multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.84      0.85       212\n",
      "           1       0.91      0.92      0.91       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 28 329]]\n",
      "\n",
      "\n",
      "\n",
      "signed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.84      0.85       212\n",
      "           1       0.91      0.92      0.92       357\n",
      "\n",
      "    accuracy                           0.89       569\n",
      "   macro avg       0.89      0.88      0.88       569\n",
      "weighted avg       0.89      0.89      0.89       569\n",
      "\n",
      "[[178  34]\n",
      " [ 27 330]]\n",
      "\n",
      "\n",
      "\n",
      "signed_reduced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.82      0.81       212\n",
      "           1       0.89      0.88      0.89       357\n",
      "\n",
      "    accuracy                           0.86       569\n",
      "   macro avg       0.85      0.85      0.85       569\n",
      "weighted avg       0.86      0.86      0.86       569\n",
      "\n",
      "[[174  38]\n",
      " [ 42 315]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class KernelBased(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 strategy='signed', \n",
    "                 metric='linear', \n",
    "                 clf=DecisionTreeClassifier(max_depth=None, random_state=random_state)):\n",
    "        \n",
    "        self.available_strategies = ['signed', 'orig', 'signed_reduced']\n",
    "        \n",
    "        self.clf = clf\n",
    "        self.strategy = strategy\n",
    "        if self.strategy not in self.available_strategies:\n",
    "            raise NotImplementedError(f\"Available strategies are: {self.available_strategies}. Was given {self.strategy}\")\n",
    "        self.metric = metric\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        y[y==0] = -1\n",
    "        if set(y.tolist()) != set([-1,1]):\n",
    "            raise AttributeError(f\"Y is expected to be [-1,1] only but contains: {set(y)}\")\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y.reshape(1,-1)\n",
    "        \n",
    "        X_tr = self.transform(X)\n",
    "            \n",
    "        self.clf.fit(X_tr, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_tr = self.transform(X)\n",
    "        return self.clf.predict(X_tr)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X_tr = self.transform(X)\n",
    "        return self.clf.predict_proba(X_tr)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_2_train = pairwise_kernels(X, self.X_train, metric=self.metric)\n",
    "        if self.strategy == 'signed':\n",
    "            y_train_repeated = np.repeat(self.y_train, repeats=[X.shape[0]], axis=0)\n",
    "            X_2_train = X_2_train * y_train_repeated\n",
    "        # In this case we simply keep the min, max and mean distance to each label\n",
    "        # In total this will have 6 features (min, max, mean to class -1 and the same to class 1)\n",
    "        if self.strategy == 'signed_reduced':\n",
    "            pos_tr = X_2_train[:, self.y_train.flatten() == 1]\n",
    "            neg_tr = X_2_train[:, self.y_train.flatten() == -1]\n",
    "            feats = []\n",
    "            for tr in [pos_tr, neg_tr]:\n",
    "                for aggr in [np.min, np.max, np.mean]:\n",
    "                    feats.append(aggr(tr, axis=1))\n",
    "            X_2_train = np.vstack(feats).T\n",
    "            \n",
    "        return X_2_train\n",
    "\n",
    "y[y==0] = -1\n",
    "for strategy in ['orig', 'signed', 'signed_reduced']:\n",
    "    clf = KernelBased(strategy= strategy, metric='poly')\n",
    "    print(strategy)\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=cv)\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Reduced does not seem to work as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "wdbc (1/64)\n",
      "vote (2/64)\n",
      "tokyo1 (3/64)\n",
      "tic_tac_toe (4/64)\n",
      "threeOf9 (5/64)\n",
      "spectf (6/64)\n",
      "spect (7/64)\n",
      "sonar (8/64)\n",
      "saheart (9/64)\n",
      "profb (10/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prnn_synth (11/64)\n",
      "prnn_crabs (12/64)\n",
      "postoperative_patient_data (13/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pima (14/64)\n",
      "parity5 (15/64)\n",
      "mux6 (16/64)\n",
      "monk3 (17/64)\n",
      "monk2 (18/64)\n",
      "monk1 (19/64)\n",
      "molecular_biology_promoters (20/64)\n",
      "lupus (21/64)\n",
      "labor (22/64)\n",
      "irish (23/64)\n",
      "ionosphere (24/64)\n",
      "hungarian (25/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_votes_84 (26/64)\n",
      "horse_colic (27/64)\n",
      "hepatitis (28/64)\n",
      "heart_statlog (29/64)\n",
      "heart_h (30/64)\n",
      "heart_c (31/64)\n",
      "haberman (32/64)\n",
      "glass2 (33/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german (34/64)\n",
      "diabetes (35/64)\n",
      "crx (36/64)\n",
      "credit_g (37/64)\n",
      "credit_a (38/64)\n",
      "corral (39/64)\n",
      "colic (40/64)\n",
      "cleve (41/64)\n",
      "bupa (42/64)\n",
      "buggyCrx (43/64)\n",
      "breast_w (44/64)\n",
      "breast_cancer_wisconsin (45/64)\n",
      "breast_cancer (46/64)\n",
      "breast (47/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomed (48/64)\n",
      "backache (49/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "australian (50/64)\n",
      "appendicitis (51/64)\n",
      "analcatdata_lawsuit (52/64)\n",
      "analcatdata_japansolvent (53/64)\n",
      "analcatdata_fraud (54/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung9302 (55/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_cyyoung8092 (56/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kbougatiotis/miniconda3/envs/prime/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analcatdata_creditscore (57/64)\n",
      "analcatdata_boxing2 (58/64)\n",
      "analcatdata_boxing1 (59/64)\n",
      "analcatdata_bankruptcy (60/64)\n",
      "analcatdata_asbestos (61/64)\n",
      "analcatdata_aids (62/64)\n",
      "            model      rank\n",
      "0              DT  2.064516\n",
      "3      linear_svm  3.032258\n",
      "4        poly_svm  3.161290\n",
      "1    linear_orig_  3.354839\n",
      "2  linear_signed_  3.387097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2921602/822336845.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import re\n",
    "from torch import rand\n",
    "import cached_path\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "number_of_cv_folds = 5\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "model_names = [\n",
    "    \"DT\",\n",
    "    'linear_svm',\n",
    "    'poly_svm',\n",
    "    'linear_orig_',\n",
    "    'linear_signed_',\n",
    "    #'poly_orig_',\n",
    "    #'poly_signed_',\n",
    "]\n",
    "\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "set_seeds(random_state)\n",
    "\n",
    "path_to_data_summary = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/pmlb/all_summary_stats.tsv\"\n",
    "dataset_df = pd.read_csv(cached_path.cached_path(path_to_data_summary), sep=\"\\t\")\n",
    "\n",
    "classification_datasets = dataset_df[\n",
    "    # (dataset_df[\"n_binary_features\"] == dataset_df[\"n_features\"])\n",
    "    (dataset_df[\"task\"] == \"classification\")\n",
    "    & (dataset_df[\"n_classes\"] == 2)\n",
    "    & (dataset_df[\"n_features\"] <= 100)\n",
    "    & (dataset_df[\"n_instances\"] <= 1000)\n",
    "][\"dataset\"]\n",
    "\n",
    "print(len(classification_datasets))\n",
    "\n",
    "res = []\n",
    "for dataset_index, classification_dataset in enumerate(classification_datasets[::-1][1:]):\n",
    "    \n",
    "    print(f\"{classification_dataset} ({dataset_index + 1}/{len(classification_datasets) + 1})\")\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    if y.max() != 1 or y.min() != 0:\n",
    "        for wanted, actual in enumerate(np.unique(y)):\n",
    "            y[y==actual] = wanted\n",
    "    y[y==0] = -1\n",
    "\n",
    "    \n",
    "        # train_X, test_X, train_y, test_y = train_test_split(\n",
    "        #     X, y, stratify=y, test_size=0.2, random_state=random_state\n",
    "        # )\n",
    "    for model_name in model_names:\n",
    "        #print(model_name)\n",
    "        if \"DT\" in model_name:\n",
    "            clf = DecisionTreeClassifier(\n",
    "                random_state=random_state\n",
    "            )\n",
    "        elif 'svm' in model_name:\n",
    "            if 'linear' in model_name:\n",
    "                clf = SVC()\n",
    "            else:\n",
    "                clf = SVC(kernel='poly')\n",
    "        else: \n",
    "            details = model_name.split('_')\n",
    "            metric, strategy = details[0], details[1]\n",
    "            clf = KernelBased(strategy=strategy, metric=metric)\n",
    "        model = clf\n",
    "        time_s = time.time()\n",
    "\n",
    "        y_pred = cross_val_predict(model, X, y, cv=cv).astype(int)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        (prec, rec, f1, sup) = precision_recall_fscore_support(\n",
    "            y, y_pred, average=\"binary\"\n",
    "        )\n",
    "        time_end = time.time() - time_s\n",
    "        res.append((classification_dataset, model_name, time_end, acc, prec, rec, f1, sup))\n",
    "        #print(res[-1])\n",
    "\n",
    "res = pd.DataFrame(res, columns=['dataset', 'model', 'time', 'acc', 'pr', 'rec', 'f1', 'sup'])\n",
    "# res.sort_values('f1', ascending=False)\n",
    "\n",
    "# Step 2: Sort each group by 'f1'\n",
    "sorted_df = res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Assign ranks within each group\n",
    "sorted_df['rank'] = sorted_df.groupby('dataset').cumcount() + 1\n",
    "\n",
    "# Step 4: Calculate mean rank for each model across all datasets\n",
    "mean_ranks = sorted_df.groupby('model')['rank'].mean().reset_index().sort_values(by='rank')\n",
    "\n",
    "print(mean_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINS\n",
      "                  DT  linear_svm  poly_svm  linear_signed_  linear_orig_\n",
      "DT               0.0        42.0      41.0            47.0          45.0\n",
      "linear_svm      19.0         0.0      26.0            33.0          34.0\n",
      "poly_svm        19.0        26.0       0.0            32.0          34.0\n",
      "linear_signed_  14.0        29.0      28.0             0.0          29.0\n",
      "linear_orig_    14.0        28.0      27.0            23.0           0.0\n"
     ]
    }
   ],
   "source": [
    "#  res.groupby('dataset').apply(lambda x: x.sort_values(by='f1', ascending=False))\n",
    "wins_score = np.zeros((len(model_names), len(model_names)))\n",
    "\n",
    "score_to_use = 'f1'\n",
    "\n",
    "for classification_dataset in res['dataset'].unique():\n",
    "    cur_df = res[res['dataset'] == classification_dataset]\n",
    "    # print(classification_dataset)\n",
    "    # print(cur_df.sort_values('f1', ascending=False)[['model', 'time', 'acc', 'f1']])\n",
    "    # print()\n",
    "    cur_df = cur_df.set_index('model')\n",
    "    score_metric = cur_df[score_to_use]\n",
    "    for i, m1 in enumerate(model_names):\n",
    "        for j, m2 in enumerate(model_names[i:]):\n",
    "            if cur_df.loc[m1][score_to_use] > cur_df.loc[m2][score_to_use]:\n",
    "                wins_score[i, j+i] += 1\n",
    "            elif cur_df.loc[m1][score_to_use] < cur_df.loc[m2][score_to_use]:\n",
    "                wins_score[j+i, i] += 1\n",
    "            else:\n",
    "                pass\n",
    "order_of_models = wins_score.mean(axis=1).argsort()[::-1]\n",
    "wins_score = wins_score[order_of_models, :][:, order_of_models]\n",
    "print('WINS')\n",
    "print(pd.DataFrame(wins_score, columns = np.array(model_names)[order_of_models], index=np.array(model_names)[order_of_models]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise signing of the gramm matrix\n",
    "\n",
    "\n",
    "1. For the train gramm matrix, sign it based on the pairwise KNOWN labels with -1 for different and + 1 with same.\n",
    "2. Do the same at test time, by creating two X_test_to_train distance matrices where we assume different labels for each test sample. e.g. test_sample_1 being of label 1 or -1, test_sample_2 being of label 1 or 1\n",
    "3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0, -0.5, +0.5, -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2438466, 0.2438466, 0.2438466])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [[+0.0, -0.5, +0.3], \n",
    "           [-0.5, +0.0, -0.7], \n",
    "           [+0.3, +0.5, +0.0]]\n",
    " \n",
    "X_tr = np.array(X_train)\n",
    "\n",
    "means = np.mean(X_tr, axis=0)\n",
    "stds = np.cov(X_tr, rowvar=False)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "g = multivariate_normal(means, stds, allow_singular=True, seed=42)\n",
    "g.pdf(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06666667,  0.        , -0.13333333])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.pdf(np.array([[+0.2, -0.8, +0.4], [-0.2, +0.8, -0.4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[0, 0.5, 0.3], \n",
    "           [0.5, 0, 0.7], \n",
    "           [0.3, 0.5, 0]] - > X_train * y_train [1,-1,1] - >\n",
    " \n",
    "X_train = [[+0.0, -0.5, +0.3], \n",
    "           [-0.5, +0.0, -0.7], \n",
    "           [+0.3, +0.5, +0.0]] \n",
    " \n",
    "X_train = [[1, -1, +1], -> 1\n",
    "           [-1, 1, -1], -> -1\n",
    "           [1, -1, 1]] -> 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test =  [[0.2, 0.8, 0.4]] * y_train  = [[+0.2, -0,8, +0.4]] \n",
    "\n",
    "# if test label 1\n",
    "X_test =  [[+0.2, -0.8, +0.4]]\n",
    "\n",
    "X_test_1 = [1,-1,1], - > proba_pos = 0.6\n",
    "# if test label -1 \n",
    "X_test =  [[-0.2, +0.8, -0.4]]\n",
    "\n",
    "X_test__1 = [-1,1,-1]  - > proba_pos = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(f_test | l_test=1, X), p(f_test | l_test=-1, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
