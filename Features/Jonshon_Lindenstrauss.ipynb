{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: What is the effect of the Random Projections in terms of accuracy\n",
    "### Date: 28/8/2024\n",
    "### Status: It seems to work with kNN based things.. It did not work with DT as a classifier. For kNN, in dataset 1 we have the same performance while with dataset 2 we have a very small increase in average F1 score.\n",
    "\n",
    "### Idea: \n",
    "Following [Johnson-Lindenstrauss](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma), check whether the reduced dimensionality of the random (or Gaussian projections) help.\n",
    "i.e. transform  NxF to NxF' with F' << F and check a classifier on the transformed data.\n",
    "\n",
    "### Results:\n",
    "Tried with 2 different datasets from UCI.\n",
    "1. TCGA RNA sequences for cancer types with 4 classes, 801 x 20.5K features\n",
    "2. Farm Ads with precomputed BoW represenentations with 2 classes, 4K x 55K features\n",
    "\n",
    "The results are (with eps=0.1):\n",
    "1. 20.5K features -> 5.7K (72% reduction) features but **accuracy drops from 0.97 avg to 0.93**\n",
    "2. 55K features -> 7K  features (87% reduction) features but **accuracy drops from 0.86 avg to 0.78**\n",
    "\n",
    "Not much difference when using Gauss or Sparse. \n",
    "\n",
    "Also, changing eps=0.5 did not improve greatly results. For the 2nd dataset the change was: 55K features -> 27.5K  features (50% reduction) features but **accuracy drops from 0.86 avg to 0.80**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/Johnson_Lindenstrauss/TCGA-PANCAN-HiSeq-801x20531/data.csv\", index_col=0)\n",
    "labels = pd.read_csv(\"../data/Johnson_Lindenstrauss/TCGA-PANCAN-HiSeq-801x20531/labels.csv\", index_col=0)\n",
    "labels = labels.values.ravel()\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BRCA': 300, 'KIRC': 146, 'LUAD': 141, 'PRAD': 136, 'COAD': 78})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_svmlight_file\n",
    "# import numpy as np\n",
    "\n",
    "# X, labels = load_svmlight_file(\"../data/Johnson_Lindenstrauss/Farm_Ads/farm-ads-vect\")\n",
    "# print(X.shape, np.bincount((labels + 1 /2).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "labels_ohe = ohe.fit_transform(labels.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22867,  5920,   331,   165])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "\n",
    "johnson_lindenstrauss_min_dim(1000, eps=[0.05, 0.1, 0.5, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((801,), (801, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, labels_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 20531)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "\n",
    "random_state = 42\n",
    "number_of_cv_folds = 5\n",
    "\n",
    "max_depth = None\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "cv = StratifiedKFold(number_of_cv_folds, random_state=random_state, shuffle=True)\n",
    "clf = KNeighborsClassifier()#DecisionTreeClassifier(random_state=random_state, max_depth=max_depth)\n",
    "y_pred = cross_val_predict(clf, X, labels, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.99      1.00      1.00       300\n",
      "        COAD       1.00      1.00      1.00        78\n",
      "        KIRC       1.00      1.00      1.00       146\n",
      "        LUAD       1.00      0.99      0.99       141\n",
      "        PRAD       1.00      1.00      1.00       136\n",
      "\n",
      "    accuracy                           1.00       801\n",
      "   macro avg       1.00      1.00      1.00       801\n",
      "weighted avg       1.00      1.00      1.00       801\n",
      "\n",
      "[[300   0   0   0   0]\n",
      " [  0  78   0   0   0]\n",
      " [  0   0 146   0   0]\n",
      " [  2   0   0 139   0]\n",
      " [  0   0   0   0 136]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(labels, y_pred))\n",
    "print(confusion_matrix(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 5730)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "\n",
    "sp = GaussianRandomProjection(eps=0.1)#SparseRandomProjection(eps=0.1) #GaussianRandomProjection(eps=0.1)#SparseRandomProjection(eps=0.1)\n",
    "X_tr = sp.fit_transform(X)\n",
    "print(X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.99      1.00      1.00       300\n",
      "        COAD       1.00      1.00      1.00        78\n",
      "        KIRC       1.00      1.00      1.00       146\n",
      "        LUAD       1.00      0.99      0.99       141\n",
      "        PRAD       1.00      1.00      1.00       136\n",
      "\n",
      "    accuracy                           1.00       801\n",
      "   macro avg       1.00      1.00      1.00       801\n",
      "weighted avg       1.00      1.00      1.00       801\n",
      "\n",
      "[[300   0   0   0   0]\n",
      " [  0  78   0   0   0]\n",
      " [  0   0 146   0   0]\n",
      " [  2   0   0 139   0]\n",
      " [  0   0   0   0 136]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=random_state, max_depth=max_depth)\n",
    "y_pred = cross_val_predict(clf, X_tr, labels, cv=cv)\n",
    "\n",
    "print(classification_report(labels, y_pred))\n",
    "print(confusion_matrix(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbougatiotis/.local/lib/python3.9/site-packages/sklearn/utils/_array_api.py:245: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_tr)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# y_pred = cross_val_predict(clf, X_tr, labels, cv=cv)\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(labels, y_pred))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2406\u001b[0m     {\n\u001b[1;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2431\u001b[0m ):\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \n\u001b[1;32m   2434\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2542\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class AMPClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, tau=None, alpha=1.0, n_iter=100):\n",
    "        \"\"\"\n",
    "        AMP Classifier model for multi-label classification\n",
    "        \n",
    "        Parameters:\n",
    "        tau : float, optional\n",
    "            Threshold parameter for AMP (used in the denoising function). If not provided, \n",
    "            will be calculated based on sparsity.\n",
    "        alpha : float, default=1.0\n",
    "            Regularization parameter or step size in the AMP updates.\n",
    "        n_iter : int, default=100\n",
    "            Maximum number of iterations for AMP.\n",
    "        \"\"\"\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha\n",
    "        self.n_iter = n_iter\n",
    "        self.w_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the AMP model using the training data.\n",
    "        \n",
    "        Parameters:\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples, num_labels)\n",
    "            The target labels, where each sample has multiple possible labels.\n",
    "        \n",
    "        Returns:\n",
    "        self : object\n",
    "            Fitted model.\n",
    "        \"\"\"\n",
    "        N, F = X.shape  # N: samples, F: features\n",
    "        try:\n",
    "            num_labels = y.shape[1]\n",
    "        except IndexError:\n",
    "            self.ohe = OneHotEncoder(sparse_output=True)\n",
    "            y = self.ohe.fit_transform(y)\n",
    "            num_labels = y.shape[1]\n",
    "        \n",
    "        if self.tau is None:\n",
    "            self.tau = np.sqrt(2 * np.log10(F / np.sum(y == 1)))  # rough estimate of tau if not provided\n",
    "        \n",
    "        # Initialize a weight vector for each label\n",
    "        self.w_ = np.zeros((F, num_labels))\n",
    "        \n",
    "        # Fit a model for each label (each column in y)\n",
    "        for label in range(num_labels):\n",
    "            z = y[:, label].copy()  # residuals initialized to current label\n",
    "            w_label = np.zeros(F)  # weight vector for current label\n",
    "            \n",
    "            def eta(x, beta):\n",
    "                \"\"\" Soft-thresholding function (denoiser) \"\"\"\n",
    "                return np.sign(x) * np.maximum(np.abs(x) - beta, 0)\n",
    "            \n",
    "            # AMP iterations for each label\n",
    "            for _ in range(self.n_iter):\n",
    "                sigma = np.linalg.norm(z, 2) / np.sqrt(N)\n",
    "                w_label = eta(w_label + self.alpha * np.dot(X.T, z), self.tau * sigma)\n",
    "                tmp = np.sum(np.abs(w_label) > 0)\n",
    "                z = y[:, label] - np.dot(X, w_label) + (tmp / N) * z\n",
    "            \n",
    "            # Store the learned weights for this label\n",
    "            self.w_[:, label] = w_label\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate predictions using the learned weight vectors.\n",
    "        \n",
    "        Parameters:\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        \n",
    "        Returns:\n",
    "        y_pred : array-like of shape (n_samples, num_labels)\n",
    "            Predicted labels for each sample and each class.\n",
    "        \"\"\"\n",
    "        if self.w_ is None:\n",
    "            raise ValueError(\"The model hasn't been fitted yet. Call 'fit' first.\")\n",
    "        \n",
    "        # Predict for each label: dot product of features and weight vectors\n",
    "        y_pred = np.dot(X, self.w_)\n",
    "        \n",
    "        # Convert the raw scores into binary predictions (multi-label classification)\n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "clf = AMPClassifier()\n",
    "clf.fit(X_tr, labels_ohe)\n",
    "y_pred = clf.predict(X_tr)\n",
    "# y_pred = cross_val_predict(clf, X_tr, labels, cv=cv)\n",
    "\n",
    "print(classification_report(labels, y_pred))\n",
    "print(confusion_matrix(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8549502274769487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  1.15369285, 267.61490118, 252.03338899, ..., 728.92657365,\n",
       "        281.47053641,   2.53523689]),\n",
       " array([-88575312.2677997 , -87686369.84175786, -84373283.46993884,\n",
       "        -87188346.02393809, -88531106.9072353 , -89058297.28556229,\n",
       "        -88277831.38255385, -88665547.8816896 , -88280182.94745857,\n",
       "        -86470703.22650869, -89068670.3158362 , -88559922.58457267,\n",
       "        -89737698.72558923, -86435388.07338746, -86607723.79332666,\n",
       "        -88524937.66440934, -89450529.69394025, -88927268.33438596,\n",
       "        -88656126.03028932, -88733767.39472853, -86035167.86968236,\n",
       "        -87521744.7832485 , -88705389.64801903, -85369588.45955047,\n",
       "        -86469816.82697816, -90346467.9579527 , -88977780.75086026,\n",
       "        -87241083.49768144, -89383127.24808352, -87834080.51246548,\n",
       "        -87432119.43620768, -85550987.61031185, -88102034.67967495,\n",
       "        -88828102.47490762, -88903387.64785887, -86532356.48268251,\n",
       "        -88405443.72629297, -90102986.42972265, -88576940.65114602,\n",
       "        -88782792.25554855, -88188785.49536411, -87598479.10496522,\n",
       "        -89955854.02891955, -88089675.89231658, -87891263.12865683,\n",
       "        -88070731.22324015, -86709735.04571149, -87352941.96819463,\n",
       "        -88247637.5628682 , -89424843.06002696, -87388480.82537407,\n",
       "        -88035051.73780803, -87153453.07864112, -87282089.57228768,\n",
       "        -87514660.24395558, -87609137.60905722, -86895429.3614665 ,\n",
       "        -90449474.49156678, -88444094.62767607, -88861349.92134002,\n",
       "        -88329335.18550089, -89642334.42670211, -89588303.99673852,\n",
       "        -87860459.45358497, -87141038.49995504, -89269504.69151305,\n",
       "        -89384912.9341812 , -87111492.25701472, -87996859.54064547,\n",
       "        -89060204.01186085, -88375406.70038636, -89820164.93835819,\n",
       "        -89340830.14498734, -87695625.39022143, -86910744.29596654,\n",
       "        -88210537.81048957, -89328984.49109098, -87113634.17092124,\n",
       "        -88388015.6148709 , -89742417.59088306, -87579661.6648194 ,\n",
       "        -88292809.0500765 , -86110730.7404153 , -87324023.57395042,\n",
       "        -88610401.95523173, -89095421.27279416, -87419060.23511869,\n",
       "        -87397958.98116957, -87282836.29976037, -87550166.84205589,\n",
       "        -88117823.4410988 , -87835053.64378025, -89061341.6564268 ,\n",
       "        -88601154.52250803, -88827542.0906293 , -87457651.78141111,\n",
       "        -89904128.34156309, -86916126.3909289 , -88621247.50435024,\n",
       "        -89144513.33508463, -88566967.91594933, -87919211.3535252 ,\n",
       "        -89840384.37666585, -88176034.29611869, -88214587.36994188,\n",
       "        -87860475.24169952, -88774920.32890508, -89852015.68414322,\n",
       "        -88283679.21056326, -89971570.79358019, -87273672.27275915,\n",
       "        -89228243.94041663, -89961355.51497231, -89063991.31587787,\n",
       "        -88682337.75207838, -87380611.8618518 , -87778339.94820674,\n",
       "        -87887702.52245092, -88528296.0718223 , -88420945.85144411,\n",
       "        -89412302.60073224, -88067194.4092083 , -89386649.88990206,\n",
       "        -85628189.22808388, -89415813.90799966, -89891316.40877889,\n",
       "        -88641148.10009196, -87866632.79567234, -87978220.02525471,\n",
       "        -86807843.5069247 , -90261568.70436166, -88078370.96884155,\n",
       "        -86928320.97638628, -88447313.00840032, -87407628.41434133,\n",
       "        -86804093.66809037, -88825074.77358797, -88998946.63843295,\n",
       "        -89000512.79805441, -88042377.29073742, -88493727.2817939 ,\n",
       "        -87583409.64252587, -88871658.28902581, -87518986.24376197,\n",
       "        -90284037.39132465, -88062059.67268161, -88284624.46945366,\n",
       "        -88829452.64513437, -88864685.71217138, -87306927.42595416,\n",
       "        -89559402.405066  , -89640807.6863279 , -87400579.29683566,\n",
       "        -88031913.44061694, -88909961.04084897, -89265345.88269223,\n",
       "        -87389115.42750683, -88044523.75824298, -88929976.51218103,\n",
       "        -90451149.33052205, -88232612.2241103 , -88652818.11124036,\n",
       "        -86696871.28811441, -89471027.56250896, -85288709.31138723,\n",
       "        -90287071.98769459, -88252347.11418724, -88528412.42805165,\n",
       "        -89705853.54966502, -87198676.09928045, -89703908.7752935 ,\n",
       "        -89972870.3288662 , -87563074.64675853, -89175530.1291079 ,\n",
       "        -88714843.75156029, -87398686.69665453, -88100841.44828317,\n",
       "        -90066466.31825422, -88108897.54142812, -89306822.3686175 ,\n",
       "        -88584060.23569013, -89207818.78666656, -88395513.80672508,\n",
       "        -89856528.86435997, -86195713.88545488, -89818070.73911518,\n",
       "        -89941741.11140314, -89863251.87905584, -89129521.4039993 ,\n",
       "        -88911438.65411356, -91185954.49615912, -89099874.5655198 ,\n",
       "        -89088850.00547919, -87754214.96758457, -90303888.3828868 ,\n",
       "        -89871356.55399834, -87749858.16130537, -87790076.12535606,\n",
       "        -87098740.3336087 , -89705851.80457278, -89427921.7485056 ,\n",
       "        -86261662.57203652, -87778258.73355937, -89408235.61612265,\n",
       "        -88264666.05880912, -86984660.82757428, -87143905.16655192,\n",
       "        -86612969.68831664, -88420544.84881295, -89991800.48238687,\n",
       "        -89621452.62458703, -89041416.78217651, -88032226.61391039,\n",
       "        -87165587.50608753, -89016175.30146182, -89485466.2248717 ,\n",
       "        -87076994.45915385, -88873643.8794294 , -91630058.21663259,\n",
       "        -88675640.92875807, -87498996.04670653, -90073437.15216205,\n",
       "        -87848506.31417853, -87731892.7554107 , -90010273.18901767,\n",
       "        -89304574.04220133, -87504036.09208748, -88057278.45225072,\n",
       "        -89853593.84834045, -89011489.94305441, -89382718.87433875,\n",
       "        -87304359.43284662, -87514140.6511849 , -86616434.26736093,\n",
       "        -87909677.60033765, -89216680.22013372, -89469592.4544903 ,\n",
       "        -89775337.55652365, -89699146.2751828 , -89092290.78691676,\n",
       "        -88715962.58099209, -89416338.31435643, -87975700.0474134 ,\n",
       "        -90315242.0471378 , -89554211.98936512, -89640946.85320517,\n",
       "        -88080081.19459133, -89741622.22540808, -88627838.00570041,\n",
       "        -89067231.08483875, -85744152.37377249, -87831186.9238656 ,\n",
       "        -90647893.84102114, -89249892.74023029, -88541353.1604446 ,\n",
       "        -86913891.82739224, -87544483.61337818, -87976448.80557525,\n",
       "        -89568953.46213633, -89151049.57410474, -89530364.11306836,\n",
       "        -90015141.61583355, -88677046.98820402, -89341730.96566787,\n",
       "        -89617550.63501534, -87350099.98049074, -89807449.83202137,\n",
       "        -86246272.71658538, -88635326.84247856, -88352143.10463735,\n",
       "        -88504759.27434504, -87656470.65250282, -88140230.50147533,\n",
       "        -88212560.98702328, -88411132.97001329, -89530774.90675089,\n",
       "        -89449845.96449736, -86315545.15672742, -88346869.82699563,\n",
       "        -87099408.59336579, -88781179.16081735, -88449894.58652595,\n",
       "        -85004639.98835407, -89514775.1444928 , -88340459.59889011,\n",
       "        -88849821.73714195, -89144796.77591637, -89588026.10512958,\n",
       "        -87577721.17871276, -89356282.00759776, -88367493.83145486,\n",
       "        -88134381.3875337 , -88857954.1506615 , -88186698.5229384 ,\n",
       "        -86537539.97259903, -88125124.66075009, -88160197.732443  ,\n",
       "        -88865380.9478407 , -89515036.94372886, -90038973.62405036,\n",
       "        -89108672.1708809 , -88688421.99091549, -88029009.02378705,\n",
       "        -88483293.07585879, -87840956.69000775, -88497743.31291713,\n",
       "        -88616933.6557102 , -89751335.46840201, -85523447.30859372,\n",
       "        -89338643.97077423, -89051955.97256646, -88561586.04068433,\n",
       "        -88103451.07395461, -88533866.10263728, -88776746.48245297,\n",
       "        -87444423.0676172 , -88445400.43272632, -89354799.54741547,\n",
       "        -89893154.97551027, -88428448.58573806, -87781566.06040294,\n",
       "        -90473964.28284918, -85247014.6663521 , -87851374.99117704,\n",
       "        -87414209.53750858, -86820766.64440943, -88646700.9584051 ,\n",
       "        -88169102.68237562, -88225621.74057254, -88536550.34489565,\n",
       "        -87069199.1829844 , -87858487.08111282, -88640470.1212956 ,\n",
       "        -89320578.85208845, -89711243.84599261, -88920189.62022823,\n",
       "        -86748222.88757214, -87905344.65863496, -87747184.75631592,\n",
       "        -88077176.47999598, -89575622.13394322, -89220838.18052827,\n",
       "        -88414540.6323661 , -87447684.28185289, -88023611.38961901,\n",
       "        -89606165.61356418, -88249068.2402296 , -88830851.58905955,\n",
       "        -88598922.48209709, -88842459.41313247, -88137387.90002699,\n",
       "        -88041301.61381394, -88221256.6711032 , -89359242.81900549,\n",
       "        -90919454.6964213 , -89248980.96440001, -87348909.28385955,\n",
       "        -86697328.25392516, -87898815.33366796, -88217960.5720202 ,\n",
       "        -89224956.50921619, -89097305.7484872 , -90147751.44937386,\n",
       "        -90246147.50102113, -88348635.64188051, -89404461.19073586,\n",
       "        -89670185.98118103, -89181769.71171582, -88327445.44241095,\n",
       "        -87574462.59535064, -90143279.61833149, -88039425.36790639,\n",
       "        -88914518.57662143, -88891426.71502082, -86785679.98696554,\n",
       "        -88988782.27118759, -89410744.34753785, -86485156.44331089,\n",
       "        -88988539.58437274, -87888194.09817031, -88427439.31840378,\n",
       "        -88520526.43993784, -88173665.9718103 , -88240449.5289716 ,\n",
       "        -88771088.85452668, -87773021.53140463, -87347076.17521188,\n",
       "        -88708673.38841133, -86738919.60851456, -89363183.70577973,\n",
       "        -89861837.0115348 , -87860176.74744084, -87233429.77534476,\n",
       "        -88559011.6695626 , -89587748.48659481, -89490797.78707978,\n",
       "        -83063125.69573411, -88757549.38247329, -88637927.82338648,\n",
       "        -88952156.00350806, -88213109.28253129, -87350168.70049784,\n",
       "        -88196491.94846475, -89986983.95656943, -89124978.23725395,\n",
       "        -88958925.66297728, -84807527.16310002, -88338358.88039757,\n",
       "        -88600151.01134111, -88171113.06978756, -86560397.59824258,\n",
       "        -89591005.86639296, -87557979.89919372, -88551090.22854958,\n",
       "        -89936374.4098122 , -88498904.50777699, -87485186.20580453,\n",
       "        -85578525.62205814, -86955197.93818295, -91630720.29406995,\n",
       "        -88224889.15206385, -89266437.12131463, -88021419.1475216 ,\n",
       "        -89331620.04938978, -89733476.30633706, -88186349.72613811,\n",
       "        -89149700.63180055, -89425439.69515008, -88350246.66675816,\n",
       "        -89132615.63895127, -87156190.07007724, -89273922.96958752,\n",
       "        -87124794.56739125, -88572641.18095726, -89770352.96193321,\n",
       "        -89384009.46496265, -86829680.88381654, -87989186.14831212,\n",
       "        -90551806.96525113, -89387855.3443679 , -90360183.46826941,\n",
       "        -89766231.43524177, -88212770.9520075 , -88223451.35419768,\n",
       "        -87394572.24138044, -87988070.16544728, -88935311.70872876,\n",
       "        -89483887.1975454 , -88123360.640712  , -87907271.84065549,\n",
       "        -87439455.10894462, -88813796.7149915 , -88665054.33777836,\n",
       "        -88249045.92005712, -87689736.71549791, -89134058.40832616,\n",
       "        -89323157.89402637, -89545524.94110031, -87350802.5596522 ,\n",
       "        -89408709.61804868, -87321551.97660716, -88771094.9249586 ,\n",
       "        -89056250.90643822, -88508627.2517328 , -90006729.29005757,\n",
       "        -87659558.93930487, -87715197.12467237, -89119985.92647997,\n",
       "        -87172328.1343427 , -88873750.52372459, -87454499.05223304,\n",
       "        -89744831.00205724, -87870734.90154453, -91444019.50408603,\n",
       "        -90327176.83532144, -89178338.50912619, -86634401.28638697,\n",
       "        -88224307.0570259 , -88027970.88094072, -89327644.02292255,\n",
       "        -88659311.18894143, -88408449.47381085, -88613079.2834652 ,\n",
       "        -88097998.71379437, -87559838.1975727 , -87780120.97591168,\n",
       "        -88191381.27738047, -89155905.7948055 , -88316233.5461681 ,\n",
       "        -89203910.00030072, -88754965.91172178, -89320166.62081769,\n",
       "        -88464035.95355876, -87789004.69079769, -90313426.01397292,\n",
       "        -88822985.14476815, -87702545.02738714, -87570626.51950152,\n",
       "        -90123601.19207436, -88814332.00805424, -88791093.840285  ,\n",
       "        -88133727.76534721, -89171470.87669769, -86854710.92329608,\n",
       "        -88975464.30335428, -85609759.81279321, -87749598.7776034 ,\n",
       "        -87464136.77927098, -87898195.90714695, -89288204.905984  ,\n",
       "        -89517006.96716703, -89611378.59235889, -88706231.8809018 ,\n",
       "        -90625653.83671312, -88086622.34839033, -88470979.64753237,\n",
       "        -88162413.13334572, -88683165.28734806, -89209492.69464667,\n",
       "        -87989840.2894182 , -87569439.44691607, -85970967.51442355,\n",
       "        -85014988.92069101, -90271777.32029134, -87928501.28565519,\n",
       "        -88220654.82126987, -88915237.74842647, -90160492.08536987,\n",
       "        -88479413.51653206, -88398879.70864171, -87172405.27888046,\n",
       "        -90228273.36235076, -87761267.89376305, -87152855.54754171,\n",
       "        -88734384.89707802, -88892977.66226058, -88483194.81608182,\n",
       "        -89356301.83257824, -87647308.04957634, -89480334.27972227,\n",
       "        -90384768.21267824, -88865188.1329468 , -89407436.10510197,\n",
       "        -89749962.31297413, -89190037.52213116, -90522089.71148609,\n",
       "        -86335681.90111694, -87172956.8752365 , -87232139.07699353,\n",
       "        -88127626.19107696, -90578756.91782387, -86405095.95998988,\n",
       "        -87844186.89387047, -89583462.19697885, -88580893.93349446,\n",
       "        -87620761.3413409 , -87952484.85327323, -88988520.19943342,\n",
       "        -88679119.96119356, -88662989.50840469, -86098589.17841646,\n",
       "        -88522731.27176857, -89100150.41794972, -89704113.07743523,\n",
       "        -90140846.46923034, -89452956.40336935, -88830375.36000286,\n",
       "        -87498031.76811089, -85822480.27876967, -89908206.93665458,\n",
       "        -89284302.33096102, -89105454.82556348, -86833614.7771246 ,\n",
       "        -88834299.46958424, -86709695.43457665, -88564310.04757474,\n",
       "        -90051540.66783166, -87827385.90435463, -88400586.04808335,\n",
       "        -88201156.05864502, -88871493.15469095, -89119393.76485787,\n",
       "        -86742138.13194105, -87102746.27773128, -87687919.81684475,\n",
       "        -88689726.38367595, -89338803.4213938 , -88764035.58420852,\n",
       "        -88572105.57565804, -89889967.65903491, -89079800.32959959,\n",
       "        -87947931.70134795, -90136736.95921806, -86867977.69374616,\n",
       "        -86641800.86091651, -86735833.37674703, -88326688.78875385,\n",
       "        -89864633.24282224, -88869920.95779216, -85286526.07075378,\n",
       "        -87320602.77919425, -86089969.16708466, -88055206.23389892,\n",
       "        -86906896.81909984, -88322286.54922356, -89664716.49548475,\n",
       "        -90171074.12753296, -89267828.18159154, -89421871.83836602,\n",
       "        -87035315.2808294 , -88729698.99893638, -88875402.26415935,\n",
       "        -88036380.3124303 , -88593937.98310588, -86308546.29033323,\n",
       "        -88412806.44432521, -87261839.80000323, -90402634.41310245,\n",
       "        -91095152.96237256, -88081458.70979545, -89995631.14764147,\n",
       "        -89050422.745934  , -86881029.53620858, -87745445.17724553,\n",
       "        -88527915.48506509, -89494670.75289014, -89091322.78602913,\n",
       "        -88637026.37705158, -87802801.67287846, -88339517.89652666,\n",
       "        -88245276.15761848, -89494759.80637296, -89471175.6767338 ,\n",
       "        -83903756.79250057, -89731421.00247271, -90527010.9899486 ,\n",
       "        -89715825.4367185 , -88824496.72540458, -88812378.97910877,\n",
       "        -86754508.34953621, -89364273.9590001 , -88155472.81161383,\n",
       "        -88530981.70462911, -87313047.20511335, -88845725.43090338,\n",
       "        -90165153.23089935, -88098140.11651404, -86746654.44724266,\n",
       "        -89884841.17783108, -88889984.73575677, -87802612.84672372,\n",
       "        -89168803.39017463, -87447566.9044285 , -88338207.76121159,\n",
       "        -86534021.57665808, -87974370.39810927, -89906652.57114352,\n",
       "        -89049818.45624465, -86257550.18838885, -90582697.41508344,\n",
       "        -87901177.71956801, -87160798.90573296, -87433105.56975046,\n",
       "        -84667609.27322869, -88830633.53949721, -89913134.50701158,\n",
       "        -89554193.5956249 , -89369830.17813449, -88591231.40747677,\n",
       "        -88470586.69703548, -89292183.3299613 , -89308469.32957041,\n",
       "        -88320328.5608418 , -89289393.16787136, -88733611.99254413,\n",
       "        -90957199.48557724, -89777848.78348053, -88421247.44960351,\n",
       "        -88401426.60010017, -88624491.27742411, -88911921.7853365 ,\n",
       "        -89035121.28478053, -89234519.59589808, -88865210.38023224,\n",
       "        -88519213.85148825, -90445753.4991884 , -89517461.69212724,\n",
       "        -89115159.90046227, -85585691.43119857, -89401675.09760849,\n",
       "        -89095184.49545623, -89794120.04330407, -88372281.36770612,\n",
       "        -90394577.83453228, -86975786.01059827, -88371538.20507513,\n",
       "        -88563921.99772511, -87200063.36659688, -89003013.85245267,\n",
       "        -89751868.05575494, -89858275.39092982, -87345776.90372482,\n",
       "        -89968603.41913562, -88283571.19205372, -87947597.69576652,\n",
       "        -88864358.5893476 , -90311888.90512618, -86125727.03789604,\n",
       "        -89225655.5909159 , -87580550.90749075, -86456824.51901211,\n",
       "        -88941077.11217763, -88203054.10254699, -91027916.58605964,\n",
       "        -89205198.49825887, -90118232.24098814, -88129571.48378529,\n",
       "        -90015230.75833555, -89116625.5916841 , -87448641.64117771,\n",
       "        -88756829.523284  , -90067336.41662244, -88649045.56344496,\n",
       "        -88587732.53545025, -89432157.15687016, -89070975.2321182 ,\n",
       "        -88887734.27929892, -88401959.86307208, -87628273.8822081 ,\n",
       "        -87715723.60576493, -89327642.35853168, -89585182.77817635,\n",
       "        -89087671.94199498, -87133290.92350675, -88396817.88716644,\n",
       "        -89562273.28045832, -90403126.62402229, -88794155.75087711,\n",
       "        -89974412.84429401, -89247560.60876684, -87835912.02254161,\n",
       "        -89534911.57394679, -89401806.45442866, -88626057.88560681,\n",
       "        -88779525.72498524, -87478876.38848   , -89244983.17412151,\n",
       "        -87825628.94234811, -88594980.59072752, -89750964.83575483,\n",
       "        -88139414.88262802, -88449478.6073867 , -88472879.8707746 ,\n",
       "        -87536535.82746415, -89061302.5282961 , -90983585.91413492,\n",
       "        -86151168.33887403, -89692689.28670584, -89494065.42059055,\n",
       "        -90191380.25537945, -86171566.09779842, -90096685.53799194,\n",
       "        -90010262.39195968, -88405157.3546025 , -87166886.80697991,\n",
       "        -87911582.25845738, -89560430.93273227, -89947595.7841262 ,\n",
       "        -88650676.51767406, -88743932.04623128, -88916657.89967088,\n",
       "        -86738383.35591131, -88740050.50989896, -90606050.040112  ,\n",
       "        -87443859.59686263, -88811263.0128377 , -89421480.6252961 ,\n",
       "        -87010838.32418656, -89162489.08506742, -89042654.82827759,\n",
       "        -87378788.30216172, -87610895.73952746, -89234041.33893669,\n",
       "        -84950086.56314345, -87438699.09138621, -86266332.55756266,\n",
       "        -88713399.20771596, -87322135.0298572 , -87423635.01820025,\n",
       "        -88786121.7828066 , -87938006.59630196, -87733165.4714989 ,\n",
       "        -86096196.77610298, -86908761.02578752, -88280079.10692923,\n",
       "        -89380666.8537127 , -87062252.17630596, -88657006.68858196,\n",
       "        -92890630.29223433, -89211243.92433266, -89394869.81027801]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from amp_git import amp, opt_tuning_param\n",
    "x = np.zeros(X.shape[1])\n",
    "# opt tuning param needs eps = (num_of_important_feats/ num_feats) ratio essentially. We don't know it, so we approximate\n",
    "alpha = opt_tuning_param(np.sqrt(X_tr.shape[1]) / X_tr.shape[1])\n",
    "print(alpha)\n",
    "amp(labels_ohe[:,1], X, x, labels_ohe[:,1], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 78.0000\n",
      "F: 1114.4428631736528\n",
      "MSE: 1361377892.7352\n",
      "F: 19560319851.92451\n",
      "MSE: 22415565626531308.0000\n",
      "F: 3.221069389072009e+17\n",
      "MSE: 369179859682820584636416.0000\n",
      "F: 5.305044669418644e+24\n",
      "MSE: 6080244326068743996957901455360.0000\n",
      "F: 8.737196176926924e+31\n",
      "MSE: 100139196059712648329824470211888152576.0000\n",
      "F: 1.4389813210045208e+39\n",
      "MSE: 1649252566495405438679869078818703840200622080.0000\n",
      "F: 2.3699447670856223e+46\n",
      "MSE: 27162531108531707306498053044844918763854520121294848.0000\n",
      "F: 3.903204382956379e+53\n",
      "MSE: 447356039462941187953522984687498685625022780199115471978496.0000\n",
      "F: 6.428421736534364e+60\n",
      "MSE: 7367775309463332144461656359893684565101016425588171869009425203200.0000\n",
      "F: 1.058735386832278e+68\n"
     ]
    }
   ],
   "source": [
    "from amp_git import soft_thresh, opt_tuning_param\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def avg_frob_vector_norm(x_new, x):\n",
    "    return np.sqrt(((x_new - x)**2).sum() / len(x))\n",
    "\n",
    "\n",
    "def amp_loc(y, A, x, z, alpha):\n",
    "    '''Approximate message passing (AMP) iteration \n",
    "       with soft-thresholding denoiser.\n",
    "    \n",
    "    Inputs\n",
    "        y: measurement vector (length M 1d np.array)\n",
    "        A: sensing matrix     (M-by-N 2d np.array)\n",
    "        x: signal estimate    (length N 1d np.array)\n",
    "        z: residual           (length M 1d np.array)\n",
    "        alpha: threshold tuning parameter\n",
    "        \n",
    "    Outputs\n",
    "        x: signal estimate\n",
    "        z: residual\n",
    "        \n",
    "    Note \n",
    "        Need to initialise AMP iteration with \n",
    "        x = np.zeros(N)\n",
    "        z = y\n",
    "    '''\n",
    "    \n",
    "    M = len(y)\n",
    "    \n",
    "    # Estimate vector\n",
    "    theta = alpha*np.sqrt(LA.norm(z)**2/M) # alpha*tau\n",
    "    # Calculate residual with the Onsager term\n",
    "    b = LA.norm(x,0)/M\n",
    "    z = y - A@x + b*z\n",
    "    x  = soft_thresh_loc(x + A.T@z, theta)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # L = theta*(1 - b) # The last L is the actual lambda of the LASSO we're minimizing\n",
    "\n",
    "    return (x, z)\n",
    "\n",
    "\n",
    "def soft_thresh_loc(x, L):\n",
    "    '''Soft-thresholding function.\n",
    "\n",
    "    x is the signal, L is the threshold lambda\n",
    "    x = sign(x)(abs(x)-lambda)_+\n",
    "    ()_+ is the element-wise plus operator which equals\n",
    "    the +ve part of x if x>0, otherwise = 0.'''\n",
    "    diff = np.absolute(x)-L\n",
    "    mask = diff>0\n",
    "    diff[~mask] = 0\n",
    "    return diff\n",
    "\n",
    "def oamp(y, H, sigma_w=1, n_iter=1, strategy='lmmse'):\n",
    "    M, N = H.shape\n",
    "    # Nx1\n",
    "    x = np.zeros(N)\n",
    "    # Nx1\n",
    "    u = np.ones_like(x)\n",
    "    eye = np.eye(N=N)\n",
    "    \n",
    "    # W_hat is MxN\n",
    "    if strategy == 'llmse' or (strategy == 'pinv' and M >=N):\n",
    "        augm = H.T@H\n",
    "    elif strategy == 'pinv':\n",
    "        if M < N:\n",
    "            W_hat = H.T@np.linalg.pinv(H@H.T)\n",
    "        else:\n",
    "            W_hat = np.linalg.pinv(H.T@H) @ H.T\n",
    "    \n",
    "    elif strategy == 'MF':\n",
    "        W_hat = H.T\n",
    "    for i in range(n_iter):\n",
    "        if (strategy == 'llmse'):\n",
    "            W_hat = LA.pinv(augm + eye*(sigma_w/u)) @ H.T\n",
    "        # scalar\n",
    "        tau_val = N/np.trace(W_hat @ H)\n",
    "        tau_sq = u * (tau_val - 1)\n",
    "        diff = (y - H @ x)\n",
    "        resid = x + tau_val * W_hat @ diff\n",
    "        mse = np.abs(diff).sum()\n",
    "        print(f'MSE: {mse:.4f}')\n",
    "        x_mmse = soft_thresh_loc(resid, np.sqrt(tau_sq))\n",
    "        # conditional variance \n",
    "        u_mmse = np.sum(np.square(x_mmse - resid))/len(x_mmse - 1)\n",
    "        u_hat = 1/(1/u_mmse - 1/tau_sq)\n",
    "        x_hat = u_hat * (x_mmse/u_mmse - resid/tau_sq)\n",
    "        f = avg_frob_vector_norm(x_hat, x)\n",
    "        print(f)\n",
    "        # if f <= 1e-6:\n",
    "        #     break\n",
    "        x = x_hat\n",
    "    return x_hat\n",
    "\n",
    "\n",
    "def amp(y, H, n_iter=1, alpha=1, strategy='onsager'):\n",
    "    M, N = H.shape\n",
    "    # Nx1\n",
    "    x = np.zeros(N)\n",
    "    # Nx1\n",
    "    r = y.copy()\n",
    "    for i in range(n_iter):\n",
    "        if (strategy == 'onsager'):\n",
    "            onsager_term = 0 \n",
    "        else:\n",
    "            onsager_term = 0\n",
    "        diff = (y - H @ x)\n",
    "        mse = np.abs(diff).sum()\n",
    "        print(f'MSE: {mse:.4f}')\n",
    "        r_new = diff + onsager_term\n",
    "        u = x + H.T@r_new\n",
    "        x_new = soft_thresh_loc(u, alpha)\n",
    "        f = avg_frob_vector_norm(x_new, x)\n",
    "        print(f'F: {f}')\n",
    "        # if f <= 1e-6:\n",
    "        #     break\n",
    "        x = x_new\n",
    "    return x_new\n",
    "\n",
    "cur_y = labels_ohe[:, 1]\n",
    "z = cur_y.copy()\n",
    "x = np.zeros(X_tr.shape[1])#np.random.random(X_tr.shape[1]) #\n",
    "n_iter = 10\n",
    "\n",
    "\n",
    "w = amp(cur_y, X_tr, strategy='pinv', n_iter=10, alpha=1)\n",
    "\n",
    "# alpha = opt_tuning_param(np.sqrt(X_tr.shape[1]) / X_tr.shape[1])\n",
    "# alpha = 2\n",
    "# print('a: ', alpha)\n",
    "\n",
    "# for n in range(n_iter):\n",
    "#     (x_new, z_new) = amp_loc(cur_y, X_tr, x, z, alpha)\n",
    "#     f = avg_frob_vector_norm(x_new, x)\n",
    "#     x = x_new\n",
    "#     z = z_new\n",
    "#     print(x_new[0], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.23034724e-18,  1.27723718e-19,  1.14242742e-19,  8.20938294e-19,\n",
       "        2.95397364e-19,  2.39996942e-19,  1.23485410e-18,  9.80221434e-19,\n",
       "        2.12106480e-19, -8.39483270e-19,  1.67088623e-19,  1.01209601e-18,\n",
       "        1.76190711e-19, -3.44193162e-19,  5.43417958e-19,  3.13809163e-19,\n",
       "       -8.26327376e-19, -1.73330321e-19,  4.38758931e-19,  3.31613812e-19,\n",
       "        2.54988970e-19,  2.11285917e-19,  4.12978193e-20,  8.25207787e-20,\n",
       "       -4.02516995e-19,  4.06724707e-21, -2.00995984e-06,  1.53357135e-18,\n",
       "       -8.33806329e-20, -9.68305897e-20,  2.56712505e-19, -1.72249299e-19,\n",
       "        3.85606786e-19,  5.53922324e-19,  2.13889881e-19,  2.91470737e-19,\n",
       "        7.17729315e-19,  2.58438107e-20,  4.59612981e-19,  3.34515976e-19,\n",
       "        2.15626133e-19,  8.23234961e-20,  2.71477782e-19,  3.61889450e-19,\n",
       "        2.77702730e-19,  5.10022402e-19,  3.01118558e-19, -2.00995984e-06,\n",
       "        1.59139624e-19,  1.13861411e-21,  1.71308278e-19,  1.77080344e-19,\n",
       "        2.35568631e-19,  3.70845748e-19, -2.00995984e-06, -1.71939623e-19,\n",
       "        2.33683900e-19, -2.00995984e-06,  1.36620045e-19,  1.73520159e-19,\n",
       "        2.41938749e-19,  1.03711905e-19,  2.74911202e-19,  1.34051029e-19,\n",
       "        2.28734878e-19, -2.00995984e-06,  4.13414117e-19,  2.18195356e-19,\n",
       "        2.47000680e-19,  2.45610603e-19,  3.66960067e-20,  6.69785720e-20,\n",
       "       -2.82645134e-19,  5.21810346e-20,  6.48981093e-20,  2.17112163e-19,\n",
       "        3.75306320e-19,  5.12348227e-19,  2.48240211e-19, -2.00995984e-06,\n",
       "        2.97707679e-19,  3.31987698e-19,  3.58557773e-19,  1.99096066e-19,\n",
       "        2.81954438e-19,  1.54983041e-19,  2.09540152e-19,  1.15849540e-19,\n",
       "        1.17657757e-19,  9.97091782e-20,  3.24842926e-19,  3.03570529e-19,\n",
       "        2.81305308e-19,  2.64208105e-19,  2.26832983e-19,  1.46956908e-19,\n",
       "       -2.00995984e-06,  6.55099335e-19,  4.94501805e-19,  1.24394005e-19,\n",
       "        2.94322856e-19,  2.21336575e-19, -8.17663900e-20,  4.67572940e-19,\n",
       "        2.57652699e-19,  1.58144732e-19,  1.56442188e-19, -2.00995984e-06,\n",
       "        4.85300248e-19,  4.74217269e-19,  3.32571274e-19,  2.88811558e-19,\n",
       "       -1.76362765e-19,  2.37787543e-19,  4.61378185e-19,  3.71276296e-19,\n",
       "        7.11288473e-20,  7.25681415e-20,  5.09029578e-19,  1.50340076e-19,\n",
       "        2.78118181e-19, -1.68248537e-21,  1.08718829e-19,  1.79286021e-19,\n",
       "        5.67878102e-19,  5.12307695e-19,  2.29206785e-19,  3.37200900e-19,\n",
       "        1.24733046e-19,  2.05604013e-19, -2.00995984e-06,  2.23955842e-19,\n",
       "       -2.00995984e-06,  2.57728386e-19,  3.37646027e-19,  5.23583821e-19,\n",
       "        4.69834452e-19,  2.29186932e-19,  4.98641017e-19, -2.00995984e-06,\n",
       "        1.51929090e-19,  3.27438618e-19,  3.37524845e-19,  2.08404847e-19,\n",
       "        3.68881815e-19, -2.00995984e-06,  4.22905187e-19,  2.60175600e-19,\n",
       "        1.59005207e-19,  1.50527019e-19,  4.03903608e-19,  1.00181602e-19,\n",
       "        3.30548404e-19,  2.06567678e-19,  3.82759424e-19,  5.28240228e-19,\n",
       "        4.92720885e-19,  4.22325334e-19,  1.68512407e-19,  3.13398055e-20,\n",
       "        3.87342211e-19,  1.85923835e-19,  9.15068553e-20,  3.10615419e-19,\n",
       "        5.40538956e-19, -2.01963178e-19, -2.00995984e-06,  2.35713594e-19,\n",
       "        2.10852810e-19,  2.90591031e-19,  4.91356451e-19,  3.97022292e-19,\n",
       "        4.08847459e-19,  3.57897890e-19,  3.75390692e-19,  2.00803884e-19,\n",
       "        1.69545763e-19,  1.31116606e-19,  3.51214271e-19,  3.76734447e-19,\n",
       "       -2.00995984e-06,  1.42225435e-20,  1.01073613e-19,  3.80484884e-19,\n",
       "        9.35193857e-20,  1.86999480e-19,  4.15432851e-19, -7.07148434e-20,\n",
       "        3.67906362e-19,  1.81626529e-19,  1.95624906e-19,  5.64285243e-19,\n",
       "        4.85821785e-19,  3.07021319e-19,  1.79334825e-19,  1.24849885e-19,\n",
       "        1.70759030e-19,  4.30830818e-20,  1.97688722e-19,  2.17778664e-19,\n",
       "        4.35409263e-19, -1.26433523e-19,  3.39967923e-19,  3.05537771e-19,\n",
       "        3.03018179e-19,  4.03898231e-19,  2.64479420e-19,  4.76967437e-19,\n",
       "        2.96360822e-19,  2.86725202e-19,  3.05898835e-19,  7.88826025e-19,\n",
       "        1.66469271e-19,  4.66198166e-19,  3.86743332e-19,  3.16293807e-19,\n",
       "        3.72894054e-20,  3.02249728e-20,  6.20612934e-20,  4.45243820e-19,\n",
       "        2.68947023e-19,  1.49326780e-20,  1.66316863e-19,  7.05427898e-20,\n",
       "        2.89569049e-19,  3.75826409e-19,  2.77340838e-19,  5.18296483e-19,\n",
       "        3.97885455e-19,  3.03893543e-19,  1.11720668e-19,  2.29754378e-19,\n",
       "       -2.00995984e-06, -1.69421065e-20,  1.94365110e-19,  3.35490808e-19,\n",
       "        1.91173020e-19, -2.00995984e-06,  6.52139269e-19,  2.59548597e-19,\n",
       "        3.11632851e-19, -2.06006436e-19,  2.14784063e-19,  4.46128696e-19,\n",
       "        1.49361935e-19,  6.99418431e-20,  1.13661234e-19,  3.22410601e-19,\n",
       "        3.17364386e-19, -2.00995984e-06,  1.74887281e-19,  3.59389297e-19,\n",
       "       -2.00995984e-06,  1.09336733e-19,  4.46287515e-19,  2.76614780e-19,\n",
       "        4.12376005e-19,  3.46331423e-19,  2.42488824e-19,  3.92501750e-19,\n",
       "       -2.00995984e-06, -2.00995984e-06,  3.91793684e-19, -2.00995984e-06,\n",
       "       -2.00995984e-06,  4.18282075e-19,  3.26450965e-19,  2.13582170e-19,\n",
       "        4.52295328e-19,  2.97455389e-19,  2.01923473e-19,  3.59364481e-19,\n",
       "       -2.00995984e-06,  2.22865618e-19,  1.15503985e-19,  4.95390197e-20,\n",
       "        4.05703966e-19,  1.13568279e-19,  3.30762644e-19,  4.62278778e-19,\n",
       "        1.98192061e-19,  2.08146766e-19,  1.02277574e-19, -1.82723370e-19,\n",
       "        3.11306115e-19,  1.44670994e-19,  6.38475899e-20,  5.49551502e-19,\n",
       "       -5.07806178e-20,  1.47280749e-19,  3.07880346e-19,  3.22439139e-20,\n",
       "        6.13499181e-20,  2.63323022e-19,  1.54891638e-19,  4.18519476e-19,\n",
       "        4.25284572e-19,  3.45290003e-19,  3.67710320e-19,  4.32602225e-19,\n",
       "        1.25863802e-19,  1.43607653e-19, -2.00995984e-06,  3.10284960e-19,\n",
       "        3.83973932e-19,  3.49947857e-19,  1.56989574e-19,  2.80985189e-19,\n",
       "       -2.00995984e-06,  2.79611862e-19,  1.67825434e-19,  2.06374532e-19,\n",
       "       -2.00995984e-06,  1.18948572e-19,  4.82782310e-19,  4.90542505e-19,\n",
       "        4.76181409e-19,  2.01988407e-19,  1.14029949e-19,  6.60545078e-20,\n",
       "        4.88456356e-20, -2.00995984e-06,  2.00863855e-19,  1.55114149e-19,\n",
       "        3.74631754e-19,  2.30861973e-20,  3.24923162e-19,  3.84465690e-19,\n",
       "        2.08712971e-19,  3.49624430e-19,  2.55601291e-19,  5.37072655e-19,\n",
       "        5.01395528e-20,  1.07783081e-19,  4.43428365e-19,  4.27533676e-19,\n",
       "        5.32049187e-19,  5.32163338e-19,  5.45858968e-19, -2.00995984e-06,\n",
       "        4.97482964e-19,  2.10191143e-19,  2.37253184e-19,  3.06982442e-19,\n",
       "        1.65973790e-19,  6.13912771e-20,  6.86084280e-20,  1.80054885e-19,\n",
       "        3.18179986e-19,  5.35099002e-20,  1.06822828e-19,  1.44250786e-19,\n",
       "        1.96299575e-19, -2.00995984e-06, -2.00995984e-06,  5.37820427e-20,\n",
       "        9.97482625e-20,  5.39406959e-19,  3.60049387e-19,  1.71547333e-19,\n",
       "        3.41065178e-19, -2.00995984e-06,  3.91512856e-20, -2.00995984e-06,\n",
       "        3.57103383e-19,  2.69839964e-19,  3.54866687e-19,  1.26253818e-19,\n",
       "        5.24209376e-19,  5.77525096e-20,  3.83712956e-19, -2.00995984e-06,\n",
       "        1.87162848e-19,  2.42890213e-20,  2.14691006e-19,  5.26884272e-19,\n",
       "        1.13714173e-19,  3.41472565e-19,  3.49826262e-19, -2.00995984e-06,\n",
       "        1.62502113e-19,  1.91761559e-19, -2.00995984e-06, -2.00995984e-06,\n",
       "        4.84542550e-19,  3.39445507e-19,  3.88820383e-19, -2.00995984e-06,\n",
       "        3.79649018e-19, -4.48058922e-19,  2.46089955e-19,  3.87704516e-19,\n",
       "        1.26046195e-19,  1.46147615e-19,  4.57364704e-19,  2.23471941e-19,\n",
       "        2.94342605e-19,  4.71121959e-19,  5.18668714e-19,  2.39702776e-19,\n",
       "       -2.00995984e-06,  2.72431935e-19,  2.18518474e-19,  2.51653158e-19,\n",
       "        2.63162962e-19,  2.55821734e-19, -1.26805134e-19,  4.42577196e-19,\n",
       "       -2.56721293e-19,  1.06071851e-19,  3.33099015e-19,  2.76273362e-19,\n",
       "        2.08153384e-19,  2.30161351e-19, -2.00995984e-06,  2.31940823e-19,\n",
       "        2.15236945e-19,  2.49342842e-19,  2.34210814e-19, -1.79903098e-19,\n",
       "        1.41229923e-19,  1.27570069e-19,  6.97455945e-20, -5.37282759e-20,\n",
       "        1.75145569e-19,  5.48050169e-19,  2.48772501e-20,  2.12724797e-19,\n",
       "        5.32961568e-19,  6.91059771e-20,  4.44175309e-20, -2.00995984e-06,\n",
       "        3.57044446e-19,  1.57603549e-19,  7.37013790e-20,  1.98464410e-19,\n",
       "        9.77926007e-20,  2.79062408e-19,  3.65000476e-19,  3.21732933e-19,\n",
       "        2.30370628e-19,  2.60377432e-19,  1.75530208e-19,  1.59339801e-19,\n",
       "       -2.00995984e-06,  5.15986994e-19,  5.09028751e-19,  5.26202675e-20,\n",
       "       -3.88650811e-20,  3.57947728e-19,  1.36772660e-19,  2.79937151e-19,\n",
       "        2.34482336e-19,  1.72830704e-19,  4.22843149e-19,  2.80271125e-19,\n",
       "        1.41389362e-19,  4.89375560e-19,  3.53287185e-19, -8.62319245e-20,\n",
       "        2.61898410e-19,  1.04338908e-19,  3.60183183e-19, -8.85546477e-20,\n",
       "       -2.00995984e-06,  5.10807189e-19, -2.00995984e-06,  1.50253222e-19,\n",
       "        4.98991741e-19,  5.09577585e-19,  5.30060077e-19,  1.92210305e-19,\n",
       "        2.49822607e-19, -2.00995984e-06,  7.00468950e-20,  5.58295215e-19,\n",
       "        4.09002349e-19,  2.16210950e-19,  1.57769813e-19, -3.66656078e-20,\n",
       "        2.82446817e-19,  2.20450147e-19,  3.76737342e-19,  3.04531092e-19,\n",
       "        6.33827041e-19, -3.40450997e-20,  3.45720137e-19,  2.37695726e-19,\n",
       "        4.73456676e-19,  3.25069987e-19, -2.00995984e-06,  3.14154098e-19,\n",
       "        7.03417849e-20, -2.00995984e-06, -8.37032334e-20,  2.47877285e-19,\n",
       "        5.02658633e-19,  3.06389353e-19,  4.46546009e-19,  4.10413106e-19,\n",
       "        3.76415982e-19, -2.00995984e-06,  1.36317297e-19, -2.00995984e-06,\n",
       "        5.98071435e-19,  2.53144978e-19,  1.63760927e-19,  2.88446151e-20,\n",
       "        2.92859935e-20,  2.39967370e-19, -2.00995984e-06,  3.01812563e-19,\n",
       "        4.41381404e-19,  2.79571744e-19,  7.15514332e-19,  2.90948373e-19,\n",
       "        2.67889266e-19,  4.16355985e-19,  1.46413036e-19,  2.88400243e-19,\n",
       "        3.92264763e-19,  2.50115326e-19,  2.14449055e-19,  8.19789754e-20,\n",
       "        2.64969938e-19,  4.67444727e-19,  3.69217650e-19,  3.52134095e-19,\n",
       "        1.66489537e-19,  3.80834368e-19, -2.00995984e-06, -2.00995984e-06,\n",
       "        3.97064892e-19,  3.53283463e-19,  3.03877206e-19,  2.76786213e-19,\n",
       "        2.95690599e-19,  3.13777317e-19,  1.39482504e-19, -2.00995984e-06,\n",
       "        1.28462390e-19,  1.27881709e-19, -2.00995984e-06,  1.19482104e-19,\n",
       "        1.78846168e-19,  4.44555399e-19,  2.13068077e-19,  2.32635655e-19,\n",
       "        2.27809677e-19,  3.44551744e-19, -6.73136835e-20,  3.39487745e-19,\n",
       "        4.78655506e-19, -2.00995984e-06,  5.82563039e-19,  1.56462867e-19,\n",
       "        3.34972579e-19,  2.95071868e-19,  3.55007307e-19,  4.13202359e-19,\n",
       "        4.29902722e-19, -2.00995984e-06,  3.94452656e-19,  2.76352150e-19,\n",
       "        1.13144246e-19,  4.02155775e-19,  4.63491217e-19,  1.88292364e-19,\n",
       "        6.32696802e-19,  4.27223897e-19, -2.00995984e-06,  2.62981810e-19,\n",
       "        2.85241654e-19,  4.45051294e-19,  3.72411394e-19,  3.69539630e-19,\n",
       "        3.36822155e-19, -7.52734357e-22,  2.74212855e-19,  2.71969954e-19,\n",
       "        2.78389703e-19,  1.18124959e-19,  5.34574156e-19,  5.01524258e-19,\n",
       "        4.15797224e-19, -2.00995984e-06,  2.78294991e-19,  4.87610977e-19,\n",
       "       -2.00995984e-06,  3.42874636e-20, -2.00995984e-06,  5.40646076e-19,\n",
       "        3.61686377e-19,  2.91709379e-20,  2.51302847e-19,  9.21851434e-21,\n",
       "       -8.31812824e-21, -2.00995984e-06, -2.19561135e-20,  9.55947819e-20,\n",
       "        5.24787369e-19,  5.73384643e-19,  5.53391274e-19,  1.43957551e-19,\n",
       "        1.91984898e-19,  2.24693687e-19,  5.62718149e-19, -2.00995984e-06,\n",
       "        1.28414724e-19, -5.92112426e-20,  4.08690502e-19,  1.00594882e-19,\n",
       "        5.90052643e-19, -2.00995984e-06,  1.29203544e-19,  3.20747554e-19,\n",
       "       -5.42489861e-20,  2.93780639e-19, -2.00995984e-06,  4.64062773e-19,\n",
       "        3.00644170e-19, -1.10037769e-19,  3.84055823e-19,  1.16500117e-19,\n",
       "        2.46467356e-19, -9.88044494e-20,  1.67094206e-19,  3.27450095e-19,\n",
       "        8.21961103e-20,  4.91184811e-19,  2.84964135e-19,  8.91972894e-20,\n",
       "        1.07269816e-19,  3.29940012e-19, -2.00995984e-06, -4.27693736e-21,\n",
       "        2.60739944e-19,  4.51239432e-19, -6.60602205e-20,  1.41239435e-19,\n",
       "        3.96976384e-19, -2.85865348e-20,  4.36701733e-19,  2.43394587e-19,\n",
       "        2.28993786e-19,  3.28543732e-19,  4.25605105e-19, -3.76412674e-20,\n",
       "        4.88129619e-19,  2.95857276e-19, -2.00995984e-06,  4.36570624e-19,\n",
       "       -2.00995984e-06,  5.64690975e-19,  4.12597690e-19,  1.12495323e-19,\n",
       "        2.81151246e-19,  2.00684977e-19,  3.95860931e-19,  3.05309883e-19,\n",
       "        5.01748734e-19,  1.05494479e-19, -2.00995984e-06,  5.88221368e-19,\n",
       "        1.76082557e-19, -2.00995984e-06,  5.57747208e-19,  4.46292892e-19,\n",
       "        4.30407302e-19,  2.71184546e-19, -2.00995984e-06,  5.71292704e-19,\n",
       "        4.57999074e-19,  4.89904335e-19,  3.01672769e-19,  1.56159912e-19,\n",
       "        3.59473669e-19,  4.34999808e-19,  7.84448049e-19,  3.48602861e-19,\n",
       "        4.31668959e-19,  3.85249444e-19,  9.31827232e-20,  2.73733090e-19,\n",
       "        5.51121904e-19,  1.95962396e-19,  1.66121442e-19,  5.79563269e-19,\n",
       "        7.03765265e-21,  3.88809629e-19,  5.12385450e-19,  4.73905835e-19,\n",
       "       -2.00995984e-06, -2.00995984e-06,  3.06038887e-19,  4.30080979e-19,\n",
       "        1.64330182e-19,  4.63870893e-19,  2.94968471e-19,  2.06058135e-19,\n",
       "        9.78033541e-20,  1.08805683e-19,  8.83566413e-20,  2.09314745e-19,\n",
       "        4.79516188e-19,  3.03019058e-19,  5.32367238e-19,  2.48191407e-19,\n",
       "        1.88448287e-19,  1.78307880e-19,  1.53443244e-19,  2.25239213e-19,\n",
       "        3.42740632e-19, -2.00995984e-06,  3.35614058e-19,  2.98887239e-19,\n",
       "        2.46632999e-19,  4.51156714e-19,  3.46688766e-19,  5.01128349e-19,\n",
       "        2.28894110e-19,  3.75129923e-19,  1.24273134e-19,  3.17466129e-19,\n",
       "        3.83080577e-19,  2.35783698e-19,  1.76842943e-20,  1.14696864e-19,\n",
       "        3.36669127e-19, -5.40012455e-20,  2.07344401e-19,  1.60331591e-19,\n",
       "       -2.00995984e-06,  3.46383536e-19,  4.93938909e-19,  5.18630664e-19,\n",
       "        3.43126926e-19,  6.49072703e-19,  1.03550605e-19,  1.53187646e-19,\n",
       "        2.46208241e-20,  2.63797203e-19, -2.37309846e-20,  6.70020432e-20,\n",
       "       -1.06957142e-19, -2.00995984e-06, -5.49210704e-20,  1.08994901e-19,\n",
       "        5.20639885e-19,  3.08733170e-19,  2.59953915e-19, -1.89995115e-20,\n",
       "        2.95469328e-19,  3.84016738e-19,  4.61309425e-19, -2.00995984e-06,\n",
       "        4.01023468e-19,  3.31593133e-19,  1.09386364e-19,  2.55326667e-19,\n",
       "        1.78793435e-19,  1.90396711e-19,  6.04470504e-20,  2.73476871e-19,\n",
       "        3.13015070e-19,  4.62051303e-19, -2.00995984e-06, -2.00995984e-06,\n",
       "        2.10700686e-19,  3.17094311e-19,  2.90946305e-19,  9.78579480e-20,\n",
       "        3.04677503e-19,  1.75938008e-19,  5.45939204e-21,  3.26485758e-19,\n",
       "       -8.28925964e-20,  1.11646428e-19,  1.31435691e-19,  3.41206626e-19,\n",
       "        4.21775258e-19,  4.12083183e-19,  2.76902743e-19,  2.54262913e-19,\n",
       "        1.94232761e-19,  2.80214464e-19,  3.29880455e-19,  1.03408123e-19,\n",
       "        3.79129135e-19, -5.20627478e-20,  4.44989255e-19,  2.34385762e-19,\n",
       "        5.17517692e-19,  2.46687593e-19,  5.33912825e-19, -1.57764022e-20,\n",
       "        4.79779231e-19,  5.42405075e-20, -2.00995984e-06, -5.25276233e-20,\n",
       "        2.44194057e-19])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090.80570721447"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
